\section{Overview}

\todo[inline]{just an overview over the structure of the discussion; delete
subsection(s), so 6.1. will be "Open Scienc"}

\subsection{Intro}

Human brain mapping studies have traditionally averaged \ac{fmri} data across
participants.
%
However, data need to be assessed on the level of individual persons in order to
advance the field towards a clinical application.
% functional localizer
An established method to characterize the topography (i.e. the location, size,
and shape) of functional areas on the level of individuals are functional
localizers.
% contra localizers
However, traditional localizer paradigms employ selectively sampled, tightly
controlled stimuli, rely heavily on a participant's compliance, and can usually
map just one domain of brain functions.


\subsection{Naturalistic stimuli as functional localizer?}

\todo[inline]{Maybe, mention here that annotations are bottleneck and stuff}

% movies & narratives
Naturalistic stimuli like movies and auditory narratives \citep[cf.][for
reviews]{jaaskelainen2021movies, jaaskelainen2020neural} provide a time-locked
event structure that samples a broad range of brain
states ranging from low-level
perception (e.g., luminance) to high-level cognition (e.g., social cognition)
%
A localizer based on naturalistic stimuli could
%
a) provide higher external validity because they resemble how we perceive
the real world outside of the laboratory during everyday life more close and,
%
b) potentially map a variety of brain functions.

%
Therefore, the goal of this thesis was---while following the principles of open,
transparent, and reproducible science---to explore whether a movie and the
movie's audio-description could, in principle, substitute a traditional
localizer paradigm.

% PPA as proof of concept
As a proof of concept, we focused on the \ac{ppa}, a ``classic'' higher visual
area.
%
The \ac{ppa} exhibits increased hemodynamic activity when participants view
photos of landscapes, buildings or landmarks, compared to, e.g., photos of faces
or tools \citep[e.g.,][for reviews]{epstein2014neural, aminoff2013role}.
%
Moreover, results of \citep{aziz2008modulation} that compared hemodynamic
activity levels in the \ac{ppa} correlated with different categories
presented in spoken sentences suggest that activity level of the  \ac{ppa}
are modulated by semantic scene-related information.
%
The the movie's and audio-description's potential to substitute a
visual localizer were asssessed in two ways.


\subsubsection{First approach: \ac{glm} $t$-contrasts}

\todo[inline]{Somehow better prime that stimuli need(ed) to be annotated}

% similarity
Similarly to traditional localizers, we model hemodynamic responses correlating
with the temporal structure the paradigm in order to create \ac{glm}
$t$-contrasts that aimed at localizing the \ac{ppa}.
%
Differently localizer paradigms that employ blocks of stimuli, we created
\ac{glm} $t$-contrasts based on modeled hemodynamic responses correlating
annotated stimulus features embedded in the movie \citep{haeusler2016cutanno}
and audio-description \citep{haeusler2021speechanno}.


\subsubsection{Second approach: estimation from ref}

\todo[inline]{When SRM study is written, revise general intro \& here
accordingly}

%
In order to address the practical and monetary constraints of a clinical
context, we estimate localizer results of participants from results of
participants in a \textit{reference group}.
%
This is based on a super awesome functional alignment using naturalistic fMRI
data (to create the common functional space and align a left-out subject).
%
Mention partial alignment.



\subsection{Open Science}

\paragraph{\citet{halchenko2021datalad}}





\section{Open Science}

On a metalevel, this dissertation aimed to meet both the requirements of open,
shared, accessible, and transparent science \citep[cf.][]{watson2015will,
fecher2014open} as well as the requirements of a reproducible and replicable
research project.

\todo[inline]{points have to be the same as the subsections' names}
%
Over the course of the present project, affected stages were
% data-related
a) acquiring open data (assessing their quality, processing it),
%
b) providing open data (creation, description, and storage of data),
%
c) use open-source software to implement and automatize every step via code,
% publishing shit
d) publication of data, materials and results.



\subsection{Acquiring open data}

\todo[inline]{Define "open data" here (includes preprocessed data \& results)}

\subsubsection{Raw data: example, pro \& cons}

\paragraph{example}

The current thesis capitalized on publicly and freely available
%
\ac{fmri} data \citep{hanke2014audiomovie, hanke2016simultaneous,
sengupta2016extension},
%
subject-specific \acp{roi} \citep{sengupta2016extension} and
%
stimulus annotations \citep{haeusler2016cutanno}
%
that are part of the \textit{studyforrest} project
(\href{www.studyforrest.org}{\url{studyforrest.org}}).


\paragraph{pro}

%
Consequently, already existing raw and preprocessed data as well as results from
previous analyses enabled us shift time and resources to subsequent stages of
the project.

%
The current use case highlights the utility of openly shared datasets.
%
Open data allow easy access to data which benefits, e.g., researchers that enjoy
minor funding to generate new findings, or students that are eager to learn
hands-on with "real-world" data.

\paragraph{con}
%
However, the current project also highlighted an issue that is often overlooked
when "free data are so near and just need to be picked up to be analyzed":
%
standards (quality, formats, parameters) and open sciences practices (e.g.,
documenting) might vary across scientific field, or within scientific fields
depending on a working group's knowledge and rigor.
% check the data
Hence, dataset consumers need to assume that everything that is not explicitly
stated in the description of a dataset has not been considered by a dataset's
creators.
% laugh with many, don't trust any
Even if the data a from a renowned source, researchers should consider
themselves to be obliged to test and validate a dataset's quality according to
their standards and specific use cases.


\subsubsection{preprocessed data \& results: example, pro \& cons}

% what does RSC do?
% ``Whereas the PPA is assumed to be more involved in landmark recognition by
% processing basal perceptual features that constitute a scene, the RSC (i.e.
% ventral precuneus and posterior cingulate region) exhibits stronger responses
% when the scenes are familiar to the participants suggesting the RSC might be
% more concerned with localizing, i.e. orienting, the observer in space [e.g.
% Epstein \& Vass, 2016]'' [response to reviewer \#2].

% medial parietal cortex: anterior-posterior gradient
% ``Similarly to the parahippocampal cortex \citep{aminoff2013role}, the medial
% parietal cortex exhibits a posterior-anterior gradient from being more
% involved in perceptual processes to being more involved in memory related
% processes
% \citep{chrastil2018heterogeneity, hassabis2009construction,
% silson2019posterior, steel2021network}'' \citep{haeusler2022processing}.

% future studies
% ``Future, complementary studies using specifically designed paradigms could
% investigate where in the posterior-anterior axis of the parahippocampal and
% medial parietal cortex auditory semantic information is correlated with
% increased hemodynamic activity:

% we hypothesize
% we hypothesize that the auditory perception of spatial information (compared
% to non-spatial information) is correlating with clusters in the middle of
% possibly overlapping clusters correlating with visual perception (peak
% activity more posterior) and scene construction from memory (peak activity
% more anterior)'' \citep{haeusler2022processing}.


% problem of preprocessed data
Moreover, choices made during data collection and preprocessing -- despite being
state-of-the-art at the time of being published -- might not be optimal for
every use case or made obsolete by more advanced methods.

%
However, the extent of raw data and decisions made during preprocessing of
published data influence the subsequently performed analyses.

\paragraph{example}
%
For example, like the \ac{ppa}, the \ac{rsc} and \ac{opa} have repeatedly shown
increased hemodynamic activity in studies investigating visual spatial
perception and navigation \citep{chrastil2018heterogeneity, bettencourt2013role,
dilks2013occipital, epstein2019scene}.
%
Nevertheless, we and \citet{sengupta2016extension} chose the \ac{ppa} among
three possible candidates because it was the first area to be discovered as a
visual ``scene-selective'' region, is the most reliably activated region across
studies that investigate visual scene perception.

%
``We assumed that results (at least of the audio-visual stimulus) could also
yield significant clusters in the \ac{rsc} and \ac{opa} but did not explicitly
hypothesize that fact''.
%
``Apart from the PPA, results show significantly increased activity in the
ventral precuneus and posterior cingulate region (referred to as ``retrosplenial
complex'', RSC) of the medial parietal cortex, and in the superior lateral
occipital cortex (referred to as ``occipital place area'', OPA) for both
naturalistic stimuli.

%
''We believe that a detailed discussion of the RSC Activation in RSC and OPA was
out of scope of the current study, results are an incentive for further
studies''.


\paragraph{pro \& con (= opportunity costs)}
%
In the context of open science, this was kind of an limitation / aftereffect of
coverage of mask for functional areas \citet{sengupta2016extension}, and the
non-algorithmic procedure of \citet{sengupta2016extension} based on subjective
decision that is hard to replicate \& to amply to the other functional areas
\citep[cf. algorithmic procedure in, e.g.,][]{julian2012algorithmic}.

% tell me about opportunity costs without saying opportunity costs
Hence, researchers need to weigh the costs and benefits of one path (e.g.,
preprocessing the same data differently than the preprocessing performed as part
of an open dataset) relative to an alternative path (e.g., using the
preprocessed data and performing new analyses), and choose the path with the
greater net return.



\subsection{Providing open data}

"It is more blessed to give than to receive"

%
Another subgoal of the current project was to provide open data by extending the
studyforrest dataset.
%
Therefore, data were not collected for mere internal purposes but collected,
described, stored and published in a manner that allows convenient re-use by
third parties.


\subsubsection{Example: Annotation}

\todo[inline]{mention "prohibitively difficult"}.

% additional effort 1
Creating a publication-worthy annotation of speech in
\citep{haeusler2021speechanno} led to additional work beyond the necessities to build the \ac{glm} in \citep{haeusler2022processing}.

% additional effort 2
The published annotation provides, among others, time-stamps of phonemes, words
and sentences of all speakers, a grammatical tagging, and an annotation of
syntactic dependencies and semantics in a standardized manner.
%
Consequently, it widens the ``annotation bottleneck''
\citep{aliko2020naturalistic} of two naturalistic stimuli and provide a
headstart for independent research that wish to model hemodynamic brain
responses that correlated with different aspects of spoken language under more
real-life like conditions.


\subsubsection{Pros \& Cons}


\paragraph{Pro}

\todo[inline]{focus on immediate benefits}
% better organized, better documented

The following three advantages of creating a dataset supposed to be published
became apparent over the course of the thesis.
%
First, documenting every step and justifying every step by weighting pros and
cons of alternative [mutual exclusive] procedural paths leads to better
understanding, avoids tricking oneself into performing unnecessary statistical
tests, hypothesizing after the results are known \citep[a.k.a. ``HARKing'';
cf.][]{kerr1998harking}, and therefore supports following general good
scientific practices.
%
Second, a researcher who records all changes to data and code from the start to
the final results can restore a particular state of data and code and trace,
identify and correct errors more easily [similar: Klein, 2018. A practical guide
for transparency in psychological science].
%
Third, tracking and documenting every step increases reliability of results and
can be seen as a "lab protocol" containing information / templates for writing
scientific articles.


\subsubsection{Cons}
%
However, some disadvantages were of creating open data:
%
a) materials and code requires a considerable about of time and effort with
little, immediate rewards, b) and dread of being ``scooped''
\citep[cf.][]{laine2017afraid}.

%
Dataset creators need to anticipate which people might use the data for which
purpose, collect the data according to best practices, convert data into a
standardized format (considering, e.g., naming conventions, folder structure,
separating raw from analyzed data), and create metadata.

% data analysis & automatization
The data, materials and code need to be documented more rigorously, and coverage
of procedures need to exceed the coverage given in method sections of regular
articles.
%
Data need to be of quality and in a state worthy to be published and documented
for other readers, analyses pipelines needed to be in a state to be automatized,
every processing step documented, saved, protocolled, and shared to allow
reproducibility of results and facilitate replicability of finding.

%
Publishing data (or merely using open data) is associated with the risk that
other working groups, possibly having more funding and ``people and brain
power'' at disposal, are using the same data for a similar research question at
the same time.
%
Hence, there is the concern that someone else might ``claim priority, usually
through publishing, to a research idea or result you yourself have been working
on'' \citep{laine2017afraid}.
%
On the one hand, being second in the ``competitive race in the sciences'' leads
to diminished opportunities to publish own results because high impact journals
favour novel findings.
%
The risk, and therefore stress, is aggravated in case of researchers that are
early in their scientific career \citep[cf.][]{toribio2021early}, created and
curate the published dataset, pre-registered studies based on open data, or have
to stick to inflexible project plans.
%
On the other hand one advantage of publishing a dataset with an assigned DOI is
that it might get re-used and cited in another study.
%
In case of a dataset creator's fear of being superseded / outrun, ``concerns can
be alleviated by delaying the sharing or using a data-sharing repository with an
embargo period'' \citep{nichols2017best}.



\subsection{Use open-source software to implement \& automatize all steps}

\paragraph{Open-source software}

All analyses steps were implemented in open-source software packages that
provide a solid documentation and a broad basis of developers and maintainers.
%
By this means, we thrived to ensure long-term software support, and avoid the
trap of creating a "paywall" for rerunning analyses on originally open data.
%
We benefited from established free software, like Python or FSL
\citep[\href{https://www.fmrib.ox.ac.uk/fsl}{FMRIB's Software
Library;}][]{smith2004fsl} that have been developed and debugged over years by
an collaborative effort,
%
but also from software packages that emerged during current years like
%
DataLad
\citep[\href{www.datalad.org}{\url{datalad.org}};][]{halchenko2021datalad} or
%
BrainIAK
\citep[\href{https://brainiak.org}{\url{brainiak.org}};][]{kumar2020brainiak,
kumar2020brainiaktutorial}.


\paragraph{All steps (in custom code) need automatization, too}

In order to facilitate transparency of materials and procedures, code and data
are version-controlled, and changes made to code and data were protocolled and
documented.

In order to facilitate reproducibility, all stages ranging from downloading data
to plotting figures are implemented in code that can be rerun from the command
line.


\paragraph{Contra: it's fucking annoying}

%
In order to allow reproducibility every processing step needs to be designed and
tested to be run and automatically and reliably.

%
Every change made to data, materials or code, and command line invocations need
to be tracked via a version control system \citep[e.g.,][]{halchenko2021datalad}
to allow other researchers to inspect a study's full history.


\paragraph{Pro: but some benefits, too}

\todo[inline]{smooth phrasings!}

The extra time and effort spend on inspecting data and testing code as benefits
for both the creators of the analyses pipelines as well as the target audience.
%
Shared code helps independent researchers to assess and rerun code in order to
validate results.
%
Shared code can adjusted and extended  as part of their own data analysis.

%
The creators can tracking the development of code from start to current state,
document every step extensively, automatize the stuff which lead to easier
tracing, identifying and correcting bugs.
%
Tracking and documenting every step increases reliability of results and can be
seen as a "lab protocol" containing information / templates for writing
scientific articles.

%
Ultimately, leads to higher confidence in one's own work and the reliability of
results.

%
Last, automating recurring tasks gives yourself the possibility of reusing
certain data, code, documents, etc. in the future.



\subsection{Publication of data, materials and results}


\subsubsection{Definition of open access}

Because ``nature abhors a paywall'' \citep{dupre2020nature}, publications
describing generated data, the reasoning of methodological choices, analysis
steps, and results \citep{haeusler2021speechanno, haeusler2022processing} have
been published in a peer-reviewed, open-access journal.
%
Unthresholded statistical maps of all computed statistical t-contrasts are
additionally published at Neurovault (neurovault.org).


% publication: findable, accessible, interoperable, reusable
In the stage of preparing a publication, a researcher needs to facilitate
discovery by humans and web bots (e.g., via extensive description and
machine-readable metadata), ensure long-term curation [e.g., maintenance],
availability [e.g., accessibility], and choose an appropriate data host.
% legal issues
Finally, a researcher need to resolve legal issues that raise during due to the
publication of data, materials and code (e.g. statement of agreement / consent,
anonymization, intellectual property rights, use license).

% conclusion
In summary, we re-used existing data as a foundation for a new investigation in
order to generate novel findings encourage further studies, and illustrate the
benefits of publicly and freely available datasets.


\subsubsection{Pros \& Cons}


\paragraph{Cons}

As usually, time and effort (more severe in case of publishing data than in case
of merely publishing a paper plus code)

\paragraph{Pros from creator}



\todo[inline]{My super interesting papers might get cited more often because,
yeah, open access that gets, on average, cited more often [REFERENCE?]}

``greater potential impact of a work when it may be cited not just for its
scientific findings but also when its data is reused in other works''
\citep{nichols2017best}.



\paragraph{Pros from readers}

\todo[inline]{better understanding (than from a method section), step-by-step
guide; learning via reading or "trying it yourself"}

...enables independent researchers to validate current results and use written
code to replicate current findings in prospective studies, all created data,
code, analysis steps, and results are published as version-controlled DataLad
\citep[\href{www.datalad.org}{datalad.org};][]{halchenko2021datalad} datasets.


%
From the perspective of reader, open access journals provides low-cost access to
information.

% readers get a better understanding
A ``transparent and complete reporting of all facets of a study, allowing a
critical reader to evaluate the work and fully understand its strengths and
limitations'' \citep{nichols2017best}.
%
It helps readers to take a look at the methods in more detail it is conveyed in
a often limited method section of a regular study.
%
``This also facilitates subsequent research efforts by other investigators, who
can exactly follow (or carefully manipulate) each aspect of a study''
\citep{nichols2017best}.
%
Open materials facilitate tracking (and understanding!) the process (esp.
analyzes) in detail (pipelines are often far easier to understand by reading the
code step-by-step than just reading the method section).

%
Interesting to students how can not just read a method section but also take a
look at the code and follow step by step every command.
%
Fully transparent studies that also include the input data can serve as an
``education playground'' by enabling (undergraduate) student to trace the
progress of real world project, to learn coding and data analysis.



\subsection{Personal assessment}

\todo[inline]{a.k.a. summary of my life's story}

\subsubsection{DataLad (tied the project together)}

\todo[inline]{from downloading to publishing and getting downloaded}


%
Another goal was to provide all data and code documented, version-controlled,
automatized processing (from downloading to plotting) in order to allow  he
reproducibility of current results and to facilitate the replicability of
findings on other datasets.
%
DataLad \citet{halchenko2021datalad} was the technical groundwork for the
"actual" thesis.
%
DataLad provides a free and open-source software solution that manages
provenance, distribution, and version-control of code and data
\citep{halchenko2021datalad}.

%
Without DataLad (still in its "infancy"? alpha, beta-stadium?) that would not
have been possible (at least is see no competitive software solution)
%




\subsubsection{Acquiring open data (assessing their quality, processing it)}

\todo[inline]{Covid-Pandemic has impressively shown that collecting data based
on human subjects" can go dormant for almost 1.5 years; plan of the project was
adjusted accordingly; and I am so lucky that I could fall back on open data}

\todo[inline]{Caveat of data re-use: know your data! I could write that I pulled
my hair out while searching for inconsistencies in the timings, and found that
the audio track of the audio-description is essentially unsystematically
shifted; similar cases stay probably undiscovered in non-open datasets; vice
versa, a point for less error-prone open science}

\todo[inline]{not relevant in my case: participants' consent, anonymization,
most legal issues}

%
For me, it was not "3rd party" data but I was involved in the data collection
process and hence somewhat familiar with the data (provenience, location,
quality, accessibility, storage format, performed preprocessing steps).



\subsubsection{Providing open data (creation, description, and storage of data)}

\todo[inline]{it is/was somewhere between "stupid" and "brave" to mess with
someone like Haxby's group; also, }

\todo[inline]{cf. "my precious" of Susanne and Lisa"}




\subsubsection{Use open-source software to implement and automatize every step
via code}

\subsubsection{Publication of data, materials and results}

\todo[inline]{choosing the data host was easy because filtered based on DataLad
support (and Michael knows everything anyway)}

\todo[inline]{mention "open paper"? speech anno paper is on github;
ppa paper is not a public github repository (yet)}

\todo[inline]{three open access paper are published}



\subsubsection{Valid for all steps}

%
Following the practices of open and reproducible science was not mandatory for
submitting the thesis but required additional work and time.

%
Standards to follow are not yet fully established and corresponding software
tools are still emerging.
%
Since the best practices are not yet part of a graduate or PhD curriculum,
learning about the principles and standards and applying the corresponding
procedures and necessary tools was based on self-initiative and self-learning.

Data and code need to be of quality and in a state worthy to be published and
documented for other readers, analyses pipelines needed to be in a state to be
automatized, every processing step documented, saved, protocolled, and shared to
allow reproducibility of results and facilitate replicability of finding.

%
Automatization of downloading, processing \& analyzing, creating figures,
results.
%
Which takes fucking time!






%
However, over the course of generating the dataset it became apparent that there
is no such thing as a ``perfect'' annotation:
%
As in human language in general, an annotation of speech will always contain
ambiguities.
%
Additionally, there is a trade-off that needed to be balanced between a) doing
the ``mere minimum'' and putting time and effort in creating additional
information that might not be fruitful, and b) providing a sound/substantial
groundwork for potential use-cases that needed to be anticipated.
%
Any further processing step might be based on a decision that might not match
the requirement of a specific use case.
%
For example, an annotation of semantics might be based on a current state-of-the
art language model that might be superseded by future language models.
%
Therefore, the published annotation does not only comprise the final outcome but
also the raw data and documented code that can automatically be rerun step by
step to reproduce the final outcome of both the annotation and its validation
analysis, all freely accessible in a version-controlled dataset.


Open-source software (the more neuro-specific the better) and open data
allowed me to go far beyond what would have been possible without open
data [kind of not true because I used "in-house data"].
%
The thesis makes me appreciate open source neuro-software as well as the data
more

%
Anything that is not 100\% automatized is not 100\% reproducible, hard to
extend, sadly because automatization takes a long time for some stuff or is not
possible for some stuff.

%
Automating recurring tasks gives yourself the possibility of reusing
certain data, code, documents, etc. in the future.

\todo[inline]{I cannot remember one clear case which made me
glad having documented, version-controlled, and automatized stuff; maybe,
materials are a little better organized or my code was a little better to grasp
after not having taken a look at it for a longer time...}

%
Lastly, I feel more confident about my work now compared to the dilettantish
procedures experienced (and followed) in, uhm, another lab in Magdeburg.
%
Similarly, the extra time and effort spend on inspecting data and testing code
leads to higher confidence in one's own work and the reliability of results.


\subsubsection{Questionable, immediate benefits; gambling}

In summary, perceived immediate benefits are pretty low...


\todo[inline]{80\% of PhD students leave science anyway}

% no incentive
``Current incentives do not justify spending large amounts of time preparing
data for sharing, as institutional promotion panels or grant reviewers currently
do not adequately reward such efforts'' \citep{nichols2017best}.
%
``The weight that OS currently has for researchers’ career advancement is rather
small, despite'' \citep{toribio2021early}.
%
At the same time, they might feel that investing additional effort in making
research open (i.e., transparent and reproducible) is unrewarded [Nicholas et
al., 2017], such as conducting replication studies that might not be considered
for publication in high-impact journals'' \citep{toribio2021early}.
%
``As long as scientists are being evaluated on traditional journal metrics,
there are few incentives from a career perspective to fully commit to OS''
\citep{toribio2021early}.


%
``Thus, while conducting OS may initially require more work in the short term,
it can greatly benefit one’s career in the long term'' \citep{toribio2021early}.
%
``OA publications have been found to receive more citations than paywalled
publications [Piwowar et al., 2018] and can therefore aid ECRs’ career
advancement'' \citep{toribio2021early}.
%
``Similarly, open data can be highly beneficial to promote new collaborations
and increase the number of citations and the confidence that the field has in
the findings [Popkin, 2019]'' \citep{toribio2021early}.
%
Currently, playing be the old rules is the ``smarter way'' than gambling getting
cited when data or code get re-used, imo.


\subsubsection{But, probably, it needs to be done}

Open sciences makes researchers accountable to collect, document, process and
store data and materials according to best practices.
%
Published data and analysis pipelines allow external persons to check the data
and analyses for undiscovered errors, and replicate the results step by step.
%
Varying parameters and running different statistics on the data allows
inspection of robustness of results.

%
``As scientists, we are supposed to be objective arbiters of evidence and
theory, but we are not infallible and must be ready to accept criticism and
revise our claims when errors are discovered'' \citep{nichols2017best}.
%
``However, we need to develop a culture of constructive criticism, which
recognizes that errors are an inevitable part of scientific progress and
protects individual researchers from inappropriately harsh consequences when
honest mistakes are discovered'' \citep{nichols2017best}.

%
``We see no better way to advance understanding on a contested finding than to
have as many researchers as possible puzzling over the data at hand''
\citep{nichols2017best}

%
Benefits are increased robustness and reliability of science when all steps are
openly documented and data are openly available.
%
Multiple datasets can be combined to perform unanticipated use cases, and
extensively and openly documented results of multiple studies facilitate
performing meta-analyses to strengthen the claims of individual studies.
%
Thus, open transparent science is the way to make knowledge and technologies
widely accessible, and increase reproducibility of study results and
replicability of scientific findings while increasing trust of the public into
scientific process and its results.
%
Open science promises increased efficiency (time and financial expense) of
making scientific progress, make advance, and promotes innovation.


\subsection{Call to action: educate, incentivize, coerce}

\paragraph{Guidelines \& tools}

\todo[inline]{need to be established; and not change all the fucking time, so as
soon as you have done it, the procedure is not obsolete already again}
%
``OS still requires the establishment of clear guidelines for transparency and
openness of research at the international level.
%
Examples for guidelines for OA publishing [Nosek et al., 2015; Schiltz, 2018],
and collaborations [Gold et al., 2019] are already existing, and their use
should be promoted by governments and funding agencies, as well as integrated in
the training of ECRs by academic institutions.
%
Organizations and/or regulators in charge of overviewing the open scholarly
system need to be established [cf. Nicholas et al., 2019, 2020]''
\citep{toribio2021early}.


\paragraph{Education}

\todo[inline]{Breed open science enthusiast in (under)graduate curriculi}

%
``It is necessity to promote further training on the benefits and risks of OS
practices [cf. Schönbrodt, 2019].
%
Promoting training would not only increase the knowledge of ECRs about specific
OS practices but also could foster its implementation among ECRs.
%
It would be highly beneficial to introduce these training schemes in the
curriculum of undergraduates programs.
%
Courses should cover the benefits and risks of OS practices, together with a
guideline on how to implement them [cf. Farnham et al., 2017]''
\citep{toribio2021early}.


\paragraph{Carrots...}

\todo[inline]{Start with incentives to foster self-learning and applying the
principles "voluntarily"}

%
More incentives to conduct open science project needs to be established.
%
``Extra efforts may not be valued appropriately by a scientific community who
assesses research based on journal impact metrics and number of publications
[Moher et al., 2018]'' \citep{toribio2021early}.
%
``Individual incentives for researchers should be introduced through, for
example, professional recognition or the allocation of extra funding [Kidwell et
al., 2016; Fecher et al., 2015; Ali-Khan et al., 2018].


\paragraph{...and sticks}

\todo[inline]{later, convince the remaining insurgents by force}
%
``Funding agencies already require publication of findings in OA
schemes and data-sharing plans [Neylon, 2017]'' \citep{toribio2021early}.
%
``Compulsory requirements from funders, which might only lead researchers to
show minimal compliance [Neylon, 2017]'' \citep{toribio2021early}.




\section{Naturalistic stimuli as functional localizer?}

\todo[inline]{cf. 1.3 \& 1.3.5}

\todo[inline]{this is more about the general aims}


\subsection{Intro: localizer is standard, but problematic}

\todo[inline]{it is reliable, but construct?}

\todo[inline]{ecologically validity?}

\todo[inline]{boring, compliance, inefficient}

\todo[inline]{Therefor: naturalistic stimulus}


\subsection{Evaluation in two ways: direct modeling \& estimation}

\todo[inline]{maybe, cite \citet{bartels2004mapping}, and a study that did GLM +
naturalistic speech paradigm}





\subsection{Results: direct modeling works moderately}

\todo[inline]{literature says it is impossible (but Alexander Hut!). But: how
"prohibitive" is it? How naive was it to do it? What did take the most time?}

\todo[inline]{yes, you can analyze data from naturalistic stimuli based on
stimulus annotation despite people saying it is not possible}


\subsubsection{Speech Anno}


% what we did in 1 sentence
In \citep{haeusler2021speechanno}, we created and validated an annotation of
speech occurring in the movie and its audio-description.
% validation analysis
We validated the annotation's quality \citep{haeusler2021speechanno} and
performed a canonical \ac{glm} analysis by contrasting regressors correlating
with speech-related events to a regressor correlating with events without
speech.
% results
As hypothesized, results revealed statistically significant increased
hemodynamic activity in a bilateral cortical network known to be involved in the
perception of speech \citep[e.g.,][]{friederici2011brain, wilson2008beyond}.

% conclusion
These results (group-level) encouraged us to a) use the annotation as the
groundwork for \citep{haeusler2022processing}, b) publish the annotation as an
extension of the studyforrest project.


\subsubsection{PPA paper}

\todo[inline]{cf. \citep{haeusler2022processing}'s discussion regarding
neuroscout / modeling and the new, corresponding paper
\citep{delavega2022neuroscout}}

\todo[inline]{mih: worth stating again somewhere in the discussion that the
studyforrest dataset is not for this (diverse), but it is a small dataset, which
limits the generality}


% study in one sentence
The goal \citep{haeusler2022processing} was to explore whether an
audio-visual and an exclusively auditory naturalistic stimulus could be used in
order to localize the \ac{ppa} as it was previously identified in the same set
of participants by a traditional block-design functional localizer that employed
static pictures \citep{sengupta2016extension}.



\paragraph{Method}

% method
We took advantage of three fMRI acquisitions and two stimulus annotations that
are part of the open-data resource
\href{http://www.studyforrest.org}{studyforrest.org} to operationalize the
perception of spatial information embedded in an audio-visual movie and an
auditory narrative, and compare current results to a previous report of a
conventional, block-design localizer.


% AV operationalization
For the model-based mass-univariate statistical analysis (i.e.\ac{glm}) of the
movie's data, we operationalized the perception of visual spatial information
based on an annotation of movie cuts and depicted locations
\citep{haeusler2016cutanno}.
% AD operationalization
For the \ac{glm} of the audio-description's data, we extended the annotation of
speech \citep{haeusler2021speechanno} by further annotating nouns that the
narrator uses to describe the movie's absent visual content.


\paragraph{Results (generally)}

% group results: AV \& AD
On a group-average level, findings demonstrate that increased activation in the
\ac{ppa} generalizes to the perception of spatial information embedded in the
audio-visual movie and the audio-description.
% individual AD
On an individual level, semantic spatial information occurring in the
audio-description is correlated with significant activity in the anterior part
of the \ac{ppa} bilaterally in nine individuals and unilaterally in one
individual.

% results
``The present study offers evidence that a model-driven GLM analysis based on
annotations can be applied to a naturalistic paradigm to localize concise
functional areas and networks correlating with specific perceptual processes --
an analysis approach that can be facilitated by the neuroscout.org platform
\citep{delavega2021neuroscout}.
% interpretation
More specifically, our results demonstrate that increased activation in the PPA
during the perception of static pictures generalizes to the perception of
spatial information embedded in a movie and an exclusively auditory stimulus
\citep{haeusler2022processing}.

% conclusion 1
Results add evidence \citep[cf.][]{bartels2004mapping} that a functionally
defined region, such as the \ac{ppa}, can be localized using a model-driven
analysis that is based on a naturalistic stimulus' annotated temporal structure.


\paragraph{Results: Pro naturalistic localizer}


% localizer data
\citet{sengupta2016extension} successfully delineated the left-hemispheric
\ac{ppa} in 12 of 14 subjects and right-hemispheric \ac{ppa} in 14 of 14
subjects based on localizer data.
%
The primary movie contrast in \citet{haeusler2022processing} ``yielded bilateral
clusters in five participants, a unilateral right cluster in six participants
(of which one participant yielded a unilateral cluster in the visual localizer),
and a unilateral left cluster in one participant.
%
We find bilateral clusters for participant sub-20, whereas the block-design
localizer yielded only one cluster in the right hemisphere''
\citep{haeusler2022processing} (= i.e. 5 + 1 left-hemispheric, 5 + 6
right-hemispheric).
%
The primary audio-description contrast in \citet{haeusler2022processing}
``yielded bilateral clusters in nine participants that are within or overlapping
with the block-design localizer results.
%
In participant sub-04, two bilateral clusters are apparent, whereas block-design
localizer, and movie stimulus yielded only one cluster in the right hemisphere.
%
For another participant (sub-09) the analysis yielded one cluster in the
left-hemispheric PPA'' \citep{haeusler2022processing}; i.e. 9 + 1
left-hemispheric, 9 right-hemispheric.


% conclusion 2
Further, results suggest that a purely auditory naturalistic stimulus like an
audio-description could potentially substitute a visual localizer as a
diagnostic procedure to assess brain functions in visually impaired individuals.






\paragraph{Results: Contra naturalistic localizer}

\todo[inline]{Annotation \& modeling}

\todo[inline]{length, events, sampling}

``consistent with previous reports showing significant differences between
topographies estimated by static and dynamic localizers, especially in superior
temporal and frontal cortices (Fox et al., 2009; Pitcher et al., 2011)''
\citep{jiahui2022cross}.

%
Assumptions of the form of the HRF and modelling HRF  might be adjusted;
%
The approach is not simply transferable
%
Naturalistic stimuli are hyped, imo (a.k.a. "I want to do what I did before
using controlled experiments but simply using naturalistic stimuli").




\paragraph{Example: Reliability of audio-description as localizer}

\todo[inline]{sample more events in less time (fatigue), improve modeling,
control for alertness}


% statement
On an individual-level, we observed higher intersubject variability of responses
of the \ac{ppa} to a naturalistic auditory stimulation compared to the
audio-visual movie and visual localizer paradigms \citep[cf. Table 3
in][]{sengupta2016extension}.
% not necessarily noise
Our naturalistic auditory paradigm differs from block-design localizer paradigms
not just in the exclusively auditory stimulation but also in the accidental,
event-like presentation of spatial information, and the absence of a task which
leaves study participant naive to the investigated cognitive process.

%
Reliability could be influenced by uncontrolled situational factors like the
experimental design (stimulus type, no task), (transient) state of a participant
(e.g., alertness or engagement),  our simply our ``adventurous'' modeling
approach[?].


\paragraph{Auditory response might be too different, too}

%
``The presented evidence on the in-principle suitability of a naturally
engaging, purely auditory paradigm for localizing the PPA may offer a path to
the development of diagnostic procedures more suitable for individuals with
visual impairments or conditions like nystagmus''
\citep{haeusler2022processing}.


% conclusion 2
Further, results suggest that a purely auditory naturalistic stimulus like an
audio-description could potentially substitute a visual localizer as a
diagnostic procedure to assess brain functions in visually impaired individuals.

% our interpretation
Previous studies in the field of visual perception suggest that the \ac{ppa} can
be divided into functionally subregions that might process different stimulus
features.

%
Present results revealed that increased hemodynamic activity during auditory
stimulation is spatially restricted to the anterior \ac{ppa}.
% interpretation: aPPA vs. pPPA
Our results provide further evidence that the PPA can be divided into functional
subregions that coactivate during the perception of visual scenes.

%
We attributed the revealed pattern to different features inherent in the visual
stimuli compared to features inherent in the naturalistic auditory stimulus
[phrasing pretty similar to \citep{haeusler2022processing}].
%
However, our interpretation of the observed pattern ``can only be preliminary,
because the auditory stimulation dataset differs in key acquisition properties
(field-strength, resolution) from the datasets of the movie and visual localizer
representing a confound of undetermined impact'' [still pretty similar to
phrasing in \citep{haeusler2022processing}].

%
Our results invite further studies that investigate the properties of the
parahippocampal area in response to to a controlled paradigm (with or without
any task) investigating generalizability of findings to, well, controlled
paradigms.


\subsection{However, for now, better stick to localizer}

\todo[inline]{What does the PPA actually do? What is the psychological
construct?}

\todo[inline]{Even if the construct is "watching pics of landscapes" or "pics
with similar low-level features of landscapes"}

%
The localizer is the established method to identify the \ac{ppa}.
% usually, visual PPA works pretty well
It's a reliable methods that yields bilateral clusters of increased hemodynamic
activity in most subjects.
%
However, ``the PPA definition may depend on the type of experiment, task, and
stimuli used'' \citep{weiner2018defining}.


\todo[inline]{There might be dynamic localizers}
%
``We found more reliable estimates using the dynamic localizer than the static
localizer, consistent with previous reports on the increased power of dynamic
localizers [Fox et al., 2009; Pitcher et al., 2011]
\citep{jiahui2020predicting}.

%
``The dynamic localizer used short video clips for each category.
%
For all categories, the dynamic localizer elicited stronger and broader
category-selective activations than the static localizer, and the searchlight
analysis showed that the dynamic localizer had higher reliabilities across the
cortex, especially in regions that were selectively responsive to the target
category.
%
For example, for the face-selective topographies, the dynamic localizer
activated more areas than the static localizer (e.g., in superior temporal and
frontal cortices).
%
In the ventral temporal cortex, especially in the right hemisphere, both dynamic
and static localizers performed well in the cross-localizer-type predictions.
%
The low correlations were not because the prediction method failed but reflected
the difference in the topographies activated by different types of localizers.''
\citep{jiahui2022cross}.


\todo[inline]{But there is no localizer based on naturalistic stimuli for a
reason?}

Notably, 20 years after group-level findings of \citep{bartels2004mapping} there
might be "dynamic localizers" using video snippets
\citep{pitcher2011differential, fox2009defining} but, to my knowledge, no
localizers based on naturalistic stimuli!



\subsubsection{Transition to estimation}

%
However, we should have sampled response vector(s) that carry the spatial
response information (if you know what I mean).



\subsection{Results: estimation works amazingly}

\todo[inline]{cf. discussion of SRM part (when that version is final)}

\subsubsection{Goal of SRM study}
% goal 1: new procedure
We estimated results of a dedicated localizer \citep{sengupta2016extension} via
functional alignment from results of a reference group.


% the problem
Considering practical and monetary constraints in a clinical context, a paradigm
lasting 90 to 120 minutes is inappropriate for even an extensive individual
diagnostic procedure, we also assessed the relationship between length of
naturalistic stimulation used to align the test participant to the fixed
\ac{cfs} and the estimation performance.



\subsection{Vision: calibration scan + database}

\todo[inline]{This topic is only touched in the SRM study's discussion}


% examples of probabilistic atlasses: \citet{rosenke2021probabilistic}:
% Cortical atlases have been developed, which allow localization of visual areas
% ``in new subjects by leveraging ROI data from an independent set of typical
% participants: Frost and Goebel 2012;
% ventral temporal cortex (VTC) category selectivity: Julian et al. 2012,
% Zhen et al. 2017, Weiner et al. 2018; visual field maps: Benson et al. 2012,
% Benson and Winawer 2018; Wang et al. 2015''.


\subsubsection{Problem space}

``Identifying all of the currently known topographic regions of the human visual
system requires multiple scanning sessions'' \citep{wang2015probabilistic}.
%
``Given the expense and availability of fMRI, this is not always practical''
\citep{wang2015probabilistic}.
%
``For example, time-limitations and subject-fatigue both potentially limit the
time researchers may be able to spend with patients suffering from neurological
or neuropsychological disorders'' \citep{wang2015probabilistic}.
%
The database ``may prove especially useful for predicting functional patterns in
case no localizer data are available, saving scanning time and expenses''
\citep{rosenke2021probabilistic}


\subsubsection{Database}
%
The reference group requires a ``database of data for movies and a range of
functional localizers in a normative group of subjects''
\citep{jiahui2020predicting}.
%
``A database from a normative group could allow researchers to estimate new
subjects' functional topographies with by collecting only a movie-viewing data
set and then deriving the individualized topographies with the normative
database'' \citep{jiahui2020predicting}.

%
``Our approach has the potential to estimate an unlimited variety of functional
topographies at the individual level based on the responses to a single
naturalistic, dynamic stimulus.
%
A normative database of participants who were scanned during movie viewing and
during functional localizers for different perceptual and cognitive functions
would serve as a reference and allow projecting the data from the normative
sample into new brains' cortical anatomies'' \citep{jiahui2020predicting}.

%
``There are numerous other functional localizers in other perceptual and
cognitive domains, such as simple visual motion, biological motion, tonotopy,
voice perception, music perception, language, calculations, working memory, and
theory of mind.
%
Because naturalistic movies include people, human actions, conversations, social
interactions, background music etc., we predict that hyperalignment
transformation matrices based on these movies also will work for localizers of
functional topographies for audition, language, and social cognition''
\citep{jiahui2020predicting}.


\subsubsection{Calibration}
%
A naturalistic stimulus like a move or audio-description could be used to align
a test subject to a \ac{cfs} created from data of a normative reference group.
%
Naturalistic stimuli ``engage in parallel multiple neural systems for vision,
audition, language, person perception, social cognition, and other functions''
\citep{jiahui2020predicting} and offer higher generalizability [and provide
higher validity?] of transformations matrices.

%
``From a single movie dataset multiple functional topographies can be estimated
\citep{guntupalli2016model}, whereas different localizers are typically required
to map different functional topographies, making a thorough mapping of selective
topographies time-consuming and inefficient'' \citep{jiahui2020predicting}.
%
``Investigators would need to scan their participants only during movie viewing
and a wide range of idiosyncratic functional topographies could then be
estimated individually based on localizer data projected from the brains in the
normative sample into the new participants' cortical anatomies''
\citep{jiahui2020predicting}.



\subsubsection{Application: estimation}
%
Once a valid alignment is established, known functional properties of the
(normative) reference can then be projected into the respective individual voxel
space (s. Fig. 1 in \citep{nishimoto2016lining}) by mapping a variety $Z$-maps
created from a variety of $t$-contrast from a normative reference group onto an
individual subjects and thus potentially substitute a variety of localizers.

%
``Functional topographies could be mapped from a database containing a wide
range of perceptual and cognitive functions to new subjects based only on fMRI
data collected while watching an engaging, naturalistic stimulus and other
subjects' localizer data from a normative sample'' \citep{jiahui2020predicting}.
%
``A new subject's functional topographies could be estimated based only on that
subject's movie data and other subjects' localizer data from the normative
database that could be projected into that subject's cortical anatomy using
hyperalignment transformation matrices derived from movie data and could replace
tedious functional localizers with an engaging movie''
\citep{jiahui2020predicting}.




\subsubsection{Application: deviation}

\todo[inline]{cf. SRM discussion: quantify the deviation from the norm vs.
predict deviant pattern?}

%
That reference would enable an qualitative and quantitative description of an
individual's brain function with respect to such a norm, and consequently
progress the field towards neuroimaging studies of individual differences that
more closely resemble their psychological counterparts.


\subsubsection{Clinical application[?]}


\todo[inline]{cf. general introduction}

\todo[inline]{Merge into "Application: estimation" \& "Application: deviation"}

\todo[inline]{\citet{silva2018challenges, szaflarski2017practice}}


``In the clinical context, fMRI plays an important role for planning surgery in
patients with tumors or epilepsies, as it aids the understanding of which parts
of the brain need to be spared in order to preserve sensory, motor or cognitive
abilities'' \citep{wegrzyn2018thought}.


\paragraph{Language lateralization}

\todo[inline]{I abandoned the idea to come up with language area (asymmetry);
the topic is clinically more relevant, but problem in case of prediction (esp.
using ROI): most interesting is atypical language lateralization, and there is
usually no lateralization in naturalistic stimuli (but operationalization is
different from localizer paradigms), assumption of (strict) lateralization
probably wrong anyway; templates from papers using \ac{fmri} to localize
language areas are outsourced to separate file}

%
For example \ac{fmri} could be used as an noninvasive alternative to map
language areas and potentially assess lateralization (or hemispheric asymmetry)
of functional brain topography related to language (sub)functions, in order to
guide pre- and perioperative assessment of neurosurgery, e.g., in case of
epilepsy.






\section{Naturalistic stimuli are no panacea!}

%
Naturalistic stimuli are not a panacea but traditional paradigms and
naturalistic paradigms should be used in tandem / reciprocally to generate new
hypotheses and progress our understanding of the brain.



\subsection{Practical stuff}

\todo[inline]{Does an auditory naturalistic stimulus give too much room to
participants to do not give a shit? a.k.a. freely listening is bad? In
hindsight: it was a very stupid idea to do it}

\todo[inline]{it's not about length (hihi) but more about what is happening
(here: spatial events)}

``Natural stimuli like movies \citep{eickhoff2020towards,
hasson2008neurocinematics, sonkusare2019naturalistic} or narratives
\citep{hamilton2018revolution, honey2012not, lerner2011topographic,
silbert2014coupled, wilson2008beyond} can be used as a continuous, complex,
immersive, task-free paradigm that more closely resembles our natural dynamic
environment than traditional experimental paradigms''
\citep{haeusler2022processing}.

%
``Because naturalistic movies include people, human actions, conversations,
social interactions, background music etc., we predict that hyperalignment
transformation matrices based on these movies also will work for localizers of
functional topographies for audition, language, and social cognition''
\citep{jiahui2020predicting}
%
Some high-level cognitive processes, such as calculation, working memory, and
logical reasoning, may be less well sampled by movie viewing, and further work
is necessary to test whether hyperalignment based on movie-viewing data can be
used to estimate topographies for these other domains of high-level cognition.
'' \citep{jiahui2020predicting}.


%
Just an approximation of real life.
%
Setting is still the scanner.
%
Passive watching \& listening.



\subsection{Methodological stuff}

\todo[inline]{model-driven analyses are possible; but no simple mapping of
methods from controlled paradigms to naturalistic stimuli}



\subsection{Future studies}
%
Challenging data data analysis, but create \& share annotation.

%
Audio-description lacks visual stimulation; Sampling of "executive functions"
during movie/audio-description;
%
additionally, audio-description lacks visual stimulation

%
''Extending this approach to other populations, such as children, or other
cultural groups will present further challenges for selecting appropriate movies
and developing databases that allow adjustment for factors such as age''
\citep{jiahui2020predicting}.




\section{Conclusion}

%
In summary, naturalistic stimuli ``impose a meaningful timecourse across
subjects while still allowing for individual variation in brain activity and
behavioral responses, and lend themselves to a broader set of analyses than
either pure rest or pure event-related task designs'' \citep{finn2017can}.
%
``Naturalistic paradigms do not aim to replace the classic, controlled
neuroimaging paradigms (Sonkusare et al., 2019). Due to their complexity and
current limitations in understanding the statistical properties of different
features in naturalistic conditions, naturalistic stimuli are not optimal for
model development [see, e.g., Rust and Movshon, 2005]. Controlled experiments
are still needed for hypothesis testing and developing models, while
naturalistic stimuli are best employed to test models in ecologically valid
settings and to expand them to situations where context matters
more'' \citep{saarimaki2021naturalistic}.




\section{Some backups}


\subsection{Group-level vs individual-level analyses}

Backup of quotes for general discussion (or SRM study).  Studies that average
data across study participants may draw

\begin{itemize}

\item ``provide only an approximate view of any individual's brain organization,
    potentially obscuring meaningful individual differences in cortical
        organization'' \citep{laumann2015functional},

\item may just ``capture the common denominator of each individual cognitive
    circuit and lose a large amount of information''

\item ``obscure(s) patterns of brain organization specific to each individual''
    \citep{laumann2015functional}.

\end{itemize}


\subsection{Brain \& behavior: "fingerprints"}

\todo[inline]{reliability of differences is premise for "fingerprints"}
%
Maybe might be stable individual differences in cognitive tendencies or
cognitive abilities like susceptibility / predisposition [?] to attend to, [or]
recognize [or process] auditory spatial information.
% kanai
In case the pattern is stable within individual subjects / is ``highly
consistent across different sessions [or experiments], then they are
characteristics of the individuals and may reflect differences in their brain
function'' \citep{kanai2011structural} [on structural diffences].
%
``Individual differences in topology (i.e. location, size, shape of functional
areas) and the activity within functional areas can also be considered to be
interesting cases of inter-individual variability to understand the neural basis
of human cognition and behavior, brain-phenotype relationships'', and ``present
useful phenotypes or biomarkers \citep{glasser2016multi,
vanhorn2008individual}''


\subsubsection{Brain \& behavior: example studies}

\todo[inline]{shorten heavily or drop altogether}

\todo[inline]{cf. also \citep{gordon2017individual, gordon2017precision}}
%
For example, \citet{kong2019spatial} suggested based on resting-state functional
connectivity measures ``that individual-specific network topography (i.e.,
location and spatial arrangement) might serve as a fingerprint of human behavior
that can predict behavioral phenotypes across cognition, personality, and
emotion'' \citep{kong2019spatial} [with modest accuary, comparable to previous
reports predicting phenotypes based on connectivity strength].

%
\citep{bijsterbosch2018relationship}'s ``results indicate that spatial variation
in the topography of functional regions across individuals is strongly
associated with behaviour'' \citep{bijsterbosch2018relationship}.
%
\citet{bijsterbosch2018relationship} found ``that the spatial arrangement of
functional regions is strongly predictive of non-imaging measures of behavior
and lifestyle'' [however shape \& exact location of brain regions interacted
strongly with  modeling of brain connectivity].
%
\citet{bijsterbosch2018relationship} found ``that individual differences in the
size, shape and exact position of the brain regions [as identified by
resting-state functional connectivity measures] was strongly linked to
individual differences in behavioral tests and questionnaires [including
intelligence, life satisfaction, drug use and aggression problems]''
\citep{bijsterbosch2018relationship}.

%
``The variations in spatial topographical features captured a more direct and
unique representation of subject variability than temporal correlations between
regions defined by group parcellation approaches (coupling).
%
Hence, the cross-subject information represented in commonly adopted
'connectivity fingerprints' could largely reflect spatial variability in the
location of functional regions across individuals, rather than variability in
coupling strength (at least for methods that directly map group-level
parcellations onto individual data)'' \citep{bijsterbosch2018relationship}.

\todo[inline]{drop following paragraph; just here to better understand paragraph
above}
%
``Depending on the employed spatial alignment algorithm and the amount of
removed spatial intersubject variability, the degree to which spatial
information may influence FC estimates possibly varies considerably across
studies.
%
In recent years, significant efforts have gone into the methods that more
accurately estimate the spatial location of functional parcels in individual
subjects [Chong et al., 2017; Glasser et al., 2016; Gordon et al., 2016; Hacker
et al., 2013; Harrison et al., 2015; Varoquaux et al., 2011; Wang et al., 2015],
and into advanced hyperalignment approaches [Chen et al., 2015; Guntupalli et
al., 2016; Guntupalli and Haxby, 2017]'' \citep{bijsterbosch2018relationship}.
