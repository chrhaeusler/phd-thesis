Human brain mapping studies traditionally averaged \ac{fmri} data across
participants.
%
However, data need to be assessed on the level of individual persons in order to
advance the field towards a clinical application.
% functional localizer
A promising tool to perform that step are functional localizers [because
localizers aim to characterize the location size, and shape of functional areas
on the level of individual subject].
% contra localizers
However, traditional localizer paradigms employ selectively sampled,
tightly-controlled stimuli, rely heavily on a participant's compliance, and can
usually map just one domain of brain functions
% naturalistic stimuli could replace
Naturalistic stimuli as a localizer paradigm could provide higher ecological as
well as external validity, higher data quality due to increased compliance, and
potentially map a variety of brain functions [ranging from low-level perception
(e.g., luminance) to high-level cognition (e.g., social cognition)]
simultaneously.
% visually impaired
Lastly, an exclusively auditory stimulus like an audiobook or audio drama would
also be appropriate for visually impaired persons, e.g., suffering from
nystagmus or lack of eyesight.
% PPA as proof of concept
Focusing on the \ac{ppa} as proof of concept, this thesis' aim was [--- while
following the principles of open, transparent, and reproducible science ---] to
explore whether a movie and the movie's audio-description could, in principle,
substitute a traditional localizer paradigm.

\section{Open, transparent, and reproducible science}
% intro
The overarching goal of this dissertation was to perform all three studies under
the principles of open, accessible, shared, and transparent science.
% mention Datalad and the corresponding paper
To meet the requirements of a reproducible [and replicable] research project,
created data, written code, results are published as standardized DataLad
\citep[\href{www.datalad.org}{datalad.org};][]{halchenko2021datalad} datasets.

%
Over the course of the current thesis' project much care was taken to meet the
self-inflicted demands of open, accessible, shared, and transparent science.
%
All code is publicly available in order to improve reproducibility of current
results, and to facilitate replicability of findings on other datasets.
% automatization
Data analyses pipelines were designed in a way that enables automated processing
and implemented in freely available and, if possible, open-source software.
% my code
Custom code written by myself is written in open-source programming languages
(Python and Bash), is version-controlled, documented, and released publicly and
freely accessible.
% DataLad
All input data, custom code, analysis steps and output data are accessible in
standardized \textit{DataLad} (\href{www.datalad.org}{datalad.org}) datasets.
Since DataLad provides a free and open-source software solution that manages
provenience, distribution, and version-control of code and data
\citep{halchenko2021datalad}, all executed steps from downloading the input data
to visualizing the results can be rerun to check and validate the dissertation's
results.
%
Consequently, all analyses can be rerun and validated.


\section{Recapitulation of work packages}

%
First, we extended the studyforrest dataset (study 1).
%
Second  and similarly to traditional localizer paradigms, we modeled hemodynamic
activity based on annotated stimulus features embedded in the movie ``Forrest
Gump'' and its audio-description, and created GLM $t$-contrasts in order to
locate the \ac{ppa} (study 2).
%
Third, we estimated results of the localizer by projecting data through a
\ac{cfs} (study 3).

\todo[inline]{maybe, give an overview of how the upcoming part is structured:
study as such, study in light of open science, general assessment of open
science, conclusion on naturalistic stimuli as localizer, conclusion on
naturalistic stimuli in general}


\subsection{Speech anno}

\subsubsection{goal of speech anno}

\subsubsection{discussion of speech anno paper}

\subsubsection{speech anno paper in light of open science}

% goal of annotation
One subgoal was to extend studyforrest project
(\href{www.studyforrest.org}{\url{studyforrest.org}} with an annotation of
speech.
% annotations content
The publicly available annotation \citep{haeusler2021speechanno} provides
information about the two stimuli's time-courses that goes beyond / exceeds the
information that was necessary to perform the current thesis, and therefore
widens the ``annotation bottleneck'' and potentially lays the foundation for
independent research projects.
%
This extension is standardized and available as online repositories comprising
raw data, code, and results.
%
E.g. speech annotation: do the mere minimum (raw) or do some additional work
(semantics) that might not be ``perfect'' or do not necessarily meet the
requirements of specific use cases in terms of semantic analyses
%
\todo[inline]{I could write here that I pulled my hair out while searching for
inconsistencies in the timings, and found that the audio track of the
audio-description is essentially unsystematically shifted}

%
Annotations are hard but you can do it (cf. "bottleneck") (cf. intro).

%
Needs to be really, really good 'cause you do not know what people will use it
for.



\subsection{PPA paper}

\subsubsection{goal of PPA paper}

\subsubsection{discussion of speech anno paper}

%
Similarly to previous studies/classical localizer, we also model hemodynamic
responses based on the event structure.

%
But ``movies also simulate better the statistics of natural viewing and
listening and may provide more ecologically valid maps''
\citep{jiahui2020predicting}.

\subsubsection{Traditional GLM ``works''}
%
Despite ad hoc / exploratory approach (a.k.a. shitty modeling of subjectively
assessed events), results suggest: the response to spatial information must be
somewhere in there and is detectable.
%
In the PPA study,  I did not test the quality/reliability of individual results
depending on quantity of runs to assess naturalistic stimulus as potential
replacement.


\subsubsection{Future studies on PPA}

\todo[inline]{cf. reviewer response of PPA study}
%
We need dedicated studies; question for standard experiment is: is it due to
auditory information or due to being an naturalistic stimulus and it's "more
random sampling" and modeling of spatial information.

%
Naturalistic stimuli are not a panacea but traditional paradigms and
naturalistic paradigms should be used in tandem / reciprocially to generate new
hypotheses and progress our understanding of the brain.


\subsubsection{Future studies: other functional areas}
%
A full feature film might substitute traditional localizer paradigms dedicated
localizer by mapping a variety of brain functions beyond category-specific
visual areas.
%
Next step: other functional areas in studyforrest dataset [cf. discussion of SRM
part]; an independent dataset comprising naturalistic stimulation and (a variety
of) localizers.
%
``Future studies that aim to use a movie to localize visual areas in individual
participants should extensively annotate the content of frames (e.g., using the
open-source solution ``Pliers''\citep{mcnamara2017developing} for feature
extraction from a visual naturalistic stimulus)''
\citep{haeusler2022processing}.


\subsubsection{Future studies: inter-individual differences / variability}
%
Compared to the visual \ac{ppa}, we observe more variability of the auditory
\ac{ppa} across subjects.
%
Possible reasons are (shitty) modelling per se, individual alertness/fatigue,
attentional focus, predisposition to select/process spatial relevant
information.
%
``Divergent patterns of brain organization from the most common pattern (that
is, changes in the spatial arrangement of cortical regions) can be observed in
approximately 5â€“10\% of the healthy population [Glasser, 2016, A multi-modal
parcellation; Gordon, 2017, Individual variability], and care should
therefore be taken to avoid the undue influence of such outliers''
\citep{eickhoff2018imaging}.
%
``Topological outliers, if they do not result from artefacts, can also be
considered to be interesting cases of inter-individual variability to understand
brain-phenotype relationships [98]'' \citep{eickhoff2018imaging}.
%
``Recent studies have suggested that the topography (location and size)
of individual-specific brain parcellations is predictive of individual
differences in demographics, cognition, emotion and personality [3,5,99]''
\citep{eickhoff2018imaging}.
%
``Only by understanding the generic characteristic of topographic organization
can we start to appreciate idiosyncrasies and their relationships to
socio-demographic, cognitive or affective profiles''
\citep{eickhoff2018imaging}.

%
``Interindividual variability of functional regions in both functional and
spatial features should reflect brain function to some extent, and thus is a
rich and important source of information for revealing the neural basis of human
cognition and behavior [Kanai and Rees, 2011; Zilles and Amunts, 2013]''
\citep{zhen2015quantifying}.
%
Future studies need to elaborate on the significance of the variability of
functional regions and utilize this variability to explore the neural mechanisms
of specific behavioral or cognitive processes [Van Horn et al., 2008]''
\citep{zhen2015quantifying}.
%
Our study ``invites future work on the origin of the variability and its
relation to individual differences in behavioral performance''
\citep{zhen2015quantifying}.

% PPA
``The spatial and selectivity variability of the SSRs may likely underlie
individual differences in navigation, especially when scene perception is being
utilized'' \citep{zhen2017quantifying}.
%
For example, processing oral way description and using it for planing,
remembering, executing navigation.
%
``Future studies will be needed to elaborate on the mechanism and functional
significance of the interindividual variability of the SSRs and to utilize the
variability in understanding the neural mechanisms of scene perception [Kanai
and Rees, 2011; Van Horn et al., 2008]'' \citep{zhen2017quantifying}.
%
Hence, further studies using dedicated auditory localizer should shed light on
the inter-individual differences of persons exhibiting an auditory \ac{ppa}.


\subsubsection{PPA paper in light of open science}

% goal PPA study
A second subgoal was to use already existing data of the studyforrest project
and extend the published annotation for the specific needs of a new research
question that was investigated in study 2.
%
We analyzed \ac{fmri} data of the studyforrest unter zu Hilfenahme der
annotation of speech and thus were able to interpret the data under a new
perspective that was not foreseen during the original generation of the
studyforrest project.
%
Our results suggesting that the PPA is fucking awesome has been published
in a peer-reviewed journal \citep{haeusler2022processing}.
%
Consequently, we successfully reused existing data as a foundation for a new
investigation in order to generate novel findings that illustrate the benefits
of publicly and freely available dataset like the studyforrest project.

%
Opportunity costs [look up definition]: One example of the current thesis is the
analyses performed by \citet{sengupta2016extension} that were performed (and
published) in voxel-space (not surface-space) and resulting masks were
restricted to one scene-selective area (\ac{ppa}; no \ac{rsc}, \ac{opa} =
transverse occipital sulcus).








\subsection{SRM study}

% align left-out subject
Based on our findings in study 2 \citep{haeusler2022processing}, we assumed that
the event structure in both naturalistic stimuli would correlate, among others,
with brain responses that are similar to those correlating with the event
structure in a dedicated functional localizer.








\section{Open Science: summary, personal assessment, conclusion}

\subsection{Contra}
%
Following the guidelines was not mandatory for submitting the thesis but
constituted voluntary, additional careful work.
%
The additional benefits that go along this additional work are not immediately
visible to researchers/authors.
%
An second thing is, that these demands are not only not required but also not
standardized (yet) nor part of a curriculum or workflow taught during a
bachelor's or master's program.

%
Hence, do everything possible to make it really, really good 'cause other people
will rely on your shit.

%
You have to make your data and script extra pretty so other people can benefit
from your work but you do not benefit yourself from doing more than is necessary
for your own project.
%
Thus it is an added ``burden'' during PhD thesis.
%
People who do not give a shit about it and don't do it, do ``worse'' research
but are faster/``better''.
%
Other working groups can be faster and can use your data for similar findings


\subsection{Trustful data?}

%
Still, re-users need to check the data according to their use case! It will
never be perfect and there is no "one size fits all".

%
The unknown unknowns of dataset creators? What did they fail to consider?
Standards may vary depending on the use case. Assume that everything that is not
explicitly stated in a paper along the dataset was not done and needs to be
checked?

%
Which, consequently, is leading to opportunity costs.


\subsection{Opportunity costs: raw data}
%
The two-sided sword; balance of trust and checking, validating...
%
Can you trust published data? Balance of checking everything vs.  taking things
for granted.

%
you save time and money (especially if you do not collect the data yourself) but
you have to trust that the data are ``good'' and start at some point to reach
goals that you would not accomplished if you would have done all from scratch
(i.e. preprocessing).

%
A two-sided sword is relying and therefore trusting data which have not been
collected by yourself.
%
On the one hand, not spending time on collecting data is speeding up the process
of getting to analyze the data, and go beyond what would have been possible if
you would have collected the data yourself.
%
On the other hand, there is an hard to judge ``correct'' balance between
trusting the work of others that collected the raw data, and checking the data
and familiarize yourself with the data.
%
This essentially boils down to researchers that want to publish data to highly
take care that the dataset gets really, really good, and test and validate the
data substantially and rigorously.
%
Contingencies need to be taken care of and use-cases considered/anticipated that
go beyond the originally anticipated use-cases (``a.k.a. interessiert uns ja
nicht'').


\subsection{Opportunity costs: preprocessed data \& templates}
%
Said stuff is not just relevant for raw data but also any preprocessing steps,
(that might lead to different results based on parameters, operation system,
software version etc.) or any kind of results.


\subsection{Pro open science}

\todo[inline]{think big regarding reproducibility}
%
Why was is good for science that the data were already existing?
%
Why was is good for you that the data were already existing?

%
What was more difficult compared to when data were acquired by myself?
%
But what would not have been possible if the data would have needed to be
acquired on my own?

From introduction:
% reproducibility crisis
Over the last decade, there has been a growing awareness that results of
scientific publications are not reproducible or general scientific findings are
not replicable letting some authors speak of a ``reproducibility crisis'' or
``replication crisis'' in the sciences \citep{baker2016reproducibility,
plesser2018reproducibility, stupple2019reproducibility, nosek2022replicability}.
% reproducibility: definition
``A study is reproducible if all of the code and data used to generate the
numbers and figures in the paper are available and exactly produce the published
results'' \citep{leek2017most}.
% replicability: definition
A study is replicable if the same analysis of an equivalent experiment's data
leads to consistent results \citep{dubois2016building, leek2017most}.


\section{Conclusion: Naturalistic stimuli as functional localizer}

\subsubsection{Caveats of naturalistic stimuli}
%
Challenging data data analysis, but create \& share annotation.
%
Hence, data analysis pipelines should be implemented in common and
well-documented packages and code, and custom code shared along the paper.

%
Just an approximation of real life.
%
Setting is still the scanner.
%
Passive watching \& listening. Hence, executive functions?


\section{Conclusion: naturalistic stimuli in general)}
%
In summary, naturalistic stimuli ``impose a meaningful timecourse across
subjects while still allowing for individual variation in brain activity and
behavioral responses, and lend themselves to a broader set of analyses than
either pure rest or pure event-related task designs'' \citep{finn2017can}.
%
``Naturalistic paradigms do not aim to replace the classic, controlled
neuroimaging paradigms (Sonkusare et al., 2019). Due to their complexity and
current limitations in understanding the statistical properties of different
features in naturalistic conditions, naturalistic stimuli are not optimal for
model development [see, e.g., Rust and Movshon, 2005]. Controlled experiments
are still needed for hypothesis testing and developing models, while
naturalistic stimuli are best employed to test models in ecologically valid
settings and to expand them to situations where context matters
more'' \citep{saarimaki2021naturalistic}.
