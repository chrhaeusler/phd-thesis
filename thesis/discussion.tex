\todo[inline]{Phrasing here is still similar to phrasing in general intro}

Human brain mapping studies have traditionally averaged \ac{fmri} data across
participants.
%
However, data need to be assessed on the level of individual persons in order to
advance the field towards a clinical application.
% functional localizer
A promising tool to perform this advancement are/is functional localizers
[because localizers aim to characterize the location size, and shape of
functional areas on the level of individual subject].
% contra localizers
However, traditional localizer paradigms employ selectively sampled, tightly
controlled stimuli, rely heavily on a participant's compliance, and can usually
map just one domain of brain functions
% naturalistic stimuli could replace
Localizer paradigms based on naturalistic stimuli could provide higher
ecological as well as external validity, higher data quality due to increased
compliance, and potentially map a variety of brain functions [ranging from
low-level perception (e.g., luminance) to high-level cognition (e.g., social
cognition)] simultaneously.
% visually impaired
Lastly, an exclusively auditory stimulus like an audiobook or audio drama would
also be appropriate for visually impaired persons[, e.g., suffering from
nystagmus or lack of eyesight].

% PPA as proof of concept
Focussing on the \ac{ppa}, a ``classic'' higher-visual area,
\citep{epstein1998ppa}, the goal of this thesis was to explore whether a movie
and the movie's audio-description could, in principle, substitute a traditional
localizer paradigm.
% paragraph on open science
An additional goal of this dissertation was to perform all studies under the
principles of open, shared, and transparent science.
%
In order to enable independent researchers to validate current results and use
written code to replicate current findings in prospective studies, all created
data, code, analysis steps, and results are published as version-controlled
DataLad \citep[\href{www.datalad.org}{datalad.org};][]{halchenko2021datalad}
datasets.


\section{Recapitulation of work packages}

\todo[inline]{maybe, very short summary of parts here; momentarily it's a draft}

%
First, we extended the studyforrest dataset (study 1).
%
Second and similarly to traditional localizer paradigms, we modeled hemodynamic
activity based on annotated stimulus features embedded in the movie ``Forrest
Gump'' and its audio-description, and created \ac{glm} $t$-contrasts in order to
localize the \ac{ppa} (study 2).
%
Third, we estimated results of the localizer by projecting data through a
\ac{cfs} (study 3).

\todo[inline]{maybe, give an overview of how the remaining part of the thesis is
structured; at the moment: each study as such \& study in light of open science,
general discussion about of open science across studies}


\subsection{Speech anno}


\subsubsection{Goal of speech anno}

% what we did in 1 sentence
In study 1 \citep{haeusler2021speechanno}, we created and validated an
annotation of speech occurring in the movie and its audio-description pursuing
two goals.
% aim #1: groundwork for PPA study
The first aim was to build the groundwork that enabled us to conduct study 2.
% aim #2: extend studyforrest
The second aim was to create an exhaustive annotation of speech that
substantially exceeds the groundwork necessary to conduct study 2 in order to
extend the studyforrest dataset as a public resource for independent research.


\subsubsection{Discussion of speech anno}

% validation analysis
We validated the annotation's quality in study 1 and performed a canonical
\ac{glm} analysis by contrasting regressors correlating with speech-related
events to a regressor correlating with events without speech.
% results
As hypothesized, results revealed statistically significant increased
hemodynamic activity in a bilateral cortical network known to be involved in the
perception of speech \citep[e.g.,][]{friederici2011brain, wilson2008beyond}.
% conclusion
These results encouraged us to a) use the annotation as the groundwork for study
2, b) publish the annotation as an extension of the studyforrest project.


\subsubsection{Open science in context of speech anno}

\todo[inline]{how "personal" am I supposed to get?}


\paragraph{Intro}

% additional effort 1
Pursuing the goal of creating a publication-worthy dataset led to additional
work that goes far beyond the work that was necessary to build the \ac{glm} in
study 2.
% additional effort 2
The published annotation provides, among others, time-stamps of phonemes, words
and sentences of all speakers, a grammatical tagging, and an annotation of
syntactic dependencies and semantics.


\paragraph{The self-flagellation retrospectively}
%
Great care was taken during the initial creation and subsequent iterative
corrections in order to provide accurate information to the scientific
community.
%
However, over the course of generating the dataset it became apparent that there
is no such thing as a ``perfect'' annotation:
%
As in human language in general, an annotation of speech will always contain
ambiguities.
%
Additionally, there is a trade-off that needed to be balanced between a) doing
the ``mere minimum'' and putting time and effort in creating additional
information that might not be fruitful, and b) providing a sound/substantial
groundwork for potential use-cases that needed to be anticipated.
%
Any further processing step might be based on a decision that might not match
the requirement of a specific use case.
%
For example, an annotation of semantics might be based on a current state-of-the
art language model that might be superseded by future language models.
%
Therefore, the published annotation does not only comprise the final outcome but
also the raw data and documented code that can automatically be rerun step by
step to reproduce the final outcome of both the annotation and its validation
analysis, all freely accessible in a version-controlled dataset.


\paragraph{Conclusion}
%
In summary, the annotation provides extensive information about the time course
of stimulus features, and therefore a headstart to independent researchers that
wish to ``model hemodynamic brain responses that correlate with a variety of
aspects of spoken language ranging from a speaker's identity, to phonetics,
grammar, syntax, and semantics'' \citep{haeusler2021speechanno} under more
real-life like conditions.
%
Consequently, the outcome of study 1 contributes to the studyforrest project as
a resource for the scientific community by further widening the ``annotation
bottleneck'' \citep{aliko2020naturalistic} of two naturalistic stimuli.



\subsection{PPA paper}

\subsubsection{Recapitulation}

\paragraph{Goal of PPA paper}
% study in one sentence
The goal of study 2 \citep{haeusler2022processing} was to explore whether an
audio-visual and an exclusively auditory naturalistic stimulus could be used in
order to localize the \ac{ppa} as it was previously identified in the same set
of participants by a traditional block-design functional localizer that employed
static pictures \citep{sengupta2016extension}.


\paragraph{Method \& results of PPA paper}
% AV operationalization
For the model-based mass-univariate statistical analysis (i.e.\ac{glm}) of the
movie's data, we operationalized the perception of visual spatial information
based on an annotation of movie cuts and depicted locations
\citep{haeusler2016cutanno}.
% AD operationalization
For the \ac{glm} of the audio-description's data, we extended the annotation of
speech \citep{haeusler2021speechanno} by further annotating nouns that the
narrator uses to describe the movie's absent visual content.

% group results: AV \& AD
On a group-average level, findings demonstrate that increased activation in the
\ac{ppa} generalizes to the perception of spatial information embedded in the
audio-visual movie and the audio-description.
% individual AD
On an individual level, semantic spatial information occurring in the
audio-description is correlated with significant activity in the anterior part
of the \ac{ppa} bilaterally in nine individuals and unilaterally in one
individual.


\paragraph{Discussion \& conclusion of PPA paper}

\todo[inline]{cf. part in "in context of open science" copied from the paper}

% conclusion 1
Results add evidence \citep[cf.][]{bartels2004mapping} that a functionally
defined region, such as the \ac{ppa}, can be localized using a model-driven
analysis that is based on a naturalistic stimulus' annotated temporal structure.
% conclusion 2
Further, results suggest that a purely auditory naturalistic stimulus like an
audio-description could potentially substitute a visual localizer as a
diagnostic procedure to assess brain functions in visually impaired individuals
[phrasing pretty similar to \citep{haeusler2022processing}].


\subsubsection{Future studies: PPA}

%
Two aspect revealed by our analyses invite further investigations on the
properties of the \ac{ppa}.
%
First, the responses correlating with an auditory stimulation are spatially
restricted to the anterior \ac{ppa}, and
%
Second, we observed higher intersubject variability of responses of the \ac{ppa}
to a naturalistic auditory stimulation compared to the visual stimulation during
the localizer and movie paradigm.


\paragraph{Just anterior PPA during auditory stimulation}

% our interpretation
Previous studies in the field of visual perception suggest that the \ac{ppa} can
be divided into functionally subregions that might process different stimulus
features.

\todo[inline]{paraphrase stuff from paper here}

%
Hence, we attributed the revealed pattern to different features inherent in the
visual stimuli compared to features inherent in the naturalistic auditory
stimulus [phrasing pretty similar to \citep{haeusler2022processing}].
%
However, our interpretation of the observed pattern ``can only be preliminary,
because the auditory stimulation dataset differs in key acquisition properties
(field-strength, resolution) from the datasets of the movie and visual localizer
representing a confound of undetermined impact'' [still pretty similar to
phrasing in \citep{haeusler2022processing}.
% conclusion
Future studies could employ controlled stimuli, maybe accompanied by a task, to
investigate in detail whether the observed differential activations during
visual and auditory stimulation are replicable.


\paragraph{Interindividual variability in response to auditory stimulation}

% statement
On an individual-level, we observed higher intersubject variability of responses
of the \ac{ppa} to a naturalistic auditory stimulation compared to the
audio-visual movie and visual localizer paradigms \citep[cf. Table 3
in][]{sengupta2016extension}.
% not necessarily noise
However, the divergent pattern from the group mean in four of fourteen
individuals should not necessarily be interpreted as measurement errors,
artefacts, or ``random noise'' \todo{choose just one term} but could also be
attributed to individual differences in responses to the task free, auditory
paradigm.
%
Our naturalistic auditory paradigm differs from block-design localizer paradigms
not just in the exclusively auditory stimulation but also in the accidental,
event-like presentation of spatial information, and the absence of a task which
leaves study participant naive to the investigated cognitive process.


\paragraph{Possibly correlated factors}

\todo[inline]{rephrase in a "readable" (but still preliminary) way}

%
The revealed pattern could correlated with [influenced by] situational factors
like the experimental design (stimulus type, no task), (transient) state of a
participant (e.g., alertness or engagement),  our simply our ``adventurous''
modeling approach[?].
%
\todo{well...}
%
More stable factors might be individual differences in cognitive tendencies or
cognitive abilities like susceptibility / predisposition [?] to attend to, [or]
recognize [or process] auditory spatial information.
% Conclusion
Future studies could employ both controlled and naturalistic stimuli to
investigate whether our results that revealed higher intersubject variability in
response to auditory spatial information are a) replicable across different
experiments and paradigms, and b) reliable within subjects.


\paragraph{Brain \& behavior: intro to "fingerprints"}

\todo[inline]{following is pretty speculative 'cause reliability of differences
is premise for "fingerprints"; hence, just a draft; does it make sense to
discuss it?}

%  kanai
In case the pattern is stable within individual subjects / is ``highly
consistent across different sessions [or experiments], then they are
characteristics of the individuals and may reflect differences in their brain
function'' \citep{kanai2011structural} [on structural diffences].
%
``Individual differences in topology (i.e. location, size, shape of functional
areas) and the activity within functional areas can also be considered to be
interesting cases of inter-individual variability to understand the neural basis
of human cognition and behavior, brain-phenotype relationships'', and ``present
useful phenotypes or biomarkers \citep{glasser2016multi,
vanhorn2008individual}''
%
\todo{paraphrase}

\paragraph{Brain \& behavior: example studies}

\todo[inline]{shorten heavily or drop altogether}

%
For example, \citet{kong2019spatial} suggested based on resting-state functional
connectivity measures ``that individual-specific network topography (i.e.,
location and spatial arrangement) might serve as a fingerprint of human behavior
that can predict behavioral phenotypes across cognition, personality, and
emotion'' \citep{kong2019spatial} [with modest accuary, comparable to previous
reports predicting phenotypes based on connectivity strength].

%
\citep{bijsterbosch2018relationship}'s ``results indicate that spatial variation
in the topography of functional regions across individuals is strongly
associated with behaviour'' \citep{bijsterbosch2018relationship}.
%
\citet{bijsterbosch2018relationship} found ``that the spatial arrangement of
functional regions is strongly predictive of non-imaging measures of behavior
and lifestyle'' [however shape \& exact location of brain regions interacted
strongly with  modeling of brain connectivity].
%
\citet{bijsterbosch2018relationship} found ``that individual differences in the
size, shape and exact position of the brain regions [as identified by
resting-state functional connectivity measures] was strongly linked to
individual differences in behavioral tests and questionnaires [including
intelligence, life satisfaction, drug use and aggression problems''
\citep{bijsterbosch2018relationship}.

%
``The variations in spatial topographical features captured a more direct and
unique representation of subject variability than temporal correlations between
regions defined by group parcellation approaches (coupling).
%
Hence, the cross-subject information represented in commonly adopted
'connectivity fingerprints' could largely reflect spatial variability in the
location of functional regions across individuals, rather than variability in
coupling strength (at least for methods that directly map group-level
parcellations onto individual data)'' \citep{bijsterbosch2018relationship}.

\todo[inline]{drop following paragraph; just here to better understand paragraph
above}
%
``Depending on the employed spatial alignment algorithm and the amount of
removed saptial intersubject variability, the degree to which spatial
information may influence FC estimates possibly varies considerably across
studies.
%
In recent years, significant efforts have gone into the methods that more
accurately estimate the spatial location of functional parcels in individual
subjects [Chong et al., 2017; Glasser et al., 2016; Gordon et al., 2016; Hacker
et al., 2013; Harrison et al., 2015; Varoquaux et al., 2011; Wang et al., 2015],
and into advanced hyperalignment approaches [Chen et al., 2015; Guntupalli et
al., 2016; Guntupalli and Haxby, 2017]'' \citep{bijsterbosch2018relationship}.


\subsubsection{Conclusion on future PPA studies}

\todo[inline]{draft; clean \& rephrase!}

%
In summary, our results invite further studies that investigate the properties
of the parahippocampal area in response to
%
a) in response to an auditory naturalistic stimulation (with or without a
simultaneous task to attend to spatial information, or with subsequent memory
task),
%
b) in response to a controlled paradigm (with or without any task).
%
The respective paradigms could elaborate whether interindividual variability of
responses in the parahippocampal area is related to cognitive processes like
``auditory scene perception'' [is that a valid term?], and to degree auditory
spatial information is utilitized for, e.g., spatial orientation, way finding or
[planing, remembering, executing] navigation.


\subsubsection{Future studies: other scene-selective areas}

\todo[inline]{imo, RSC and OPA do not need to be discussed in general
discussion; could be shortly discussed in "open science in general" (->
opportunity costs)}


\subsubsection{Future studies: other functional areas (studyforrest dataset)}

\todo[inline]{imo, a side note; not necessarily needed to be discussed; hence,
draft}

The visual localizer performed by \citet{sengupta2016extension} employed images
from six categories (houses, landscapes, faces, bodies without heads, small
objects, and scrambled images).
%
As a results, the corresponding dataset provides subject-specific \acp{roi}
masks for higher visual areas besides the \ac{ppa}:
%
the fusiform face area (FFA) \citep{kanwisher1997ffa} and the occipital face
area (OFA) \citep{pitcher2011occipitalfacearea},
%
the extrastriate body area (EBA) \citep{downing2001bodyarea},
%
and the lateral occipital complex (LOC) \citep{malach1995loc}.
%
Future studies (e.g., a master's thesis or part of a PhD project) could adjust
our extension of the annotation of speech created in study 2 and the
corresponding analysis pipeline in order to explore hemodynamic responses
correlating with auditory information related to faces, body parts or small
objects.


\subsubsection{Open science in context of PPA paper}

% goal PPA study
Under the perspective of an open science project, the goal of study 2 was to use
three \ac{fmri} datasets \citep{hanke2014audiomovie, hanke2016simultaneous,
sengupta2016extension}, two stimulus annotations \citep{haeusler2021speechanno,
haeusler2016cutanno}, as well as previously published results
\citep{sengupta2016extension} for a new research question.


% skipped work
On the one hand, the availability of the \ac{fmri} data and the subject-specific
\acp{roi} enabled us to shift our focus from acquiring the raw data to
subsequent stages of a research project.
% example of skipped work
For example, the annotations that were created in a "general purpose state"
could be extended immediately to match the needs of study 2, followed by writing
the scripts that preprocessed and statistically analyzed the data.
% additional work
On the other hand, pursueing the goal of an open science project lead to
additional work.
% example of additional work
For example, code needed to be in a state worthy to be published and documented
for other readers, analyses pipelines needed to be in a state to be automatized,
every processing step documented, saved, protocolled, and shared to allow
reproducibility of results and facilitate replicability of finding.

\todo[inline]{shorten results/findings}

% results
Our results have been published in a peer-reviewed, open-access journal
%
``offer evidence that a model-driven GLM analysis based on annotations can be
applied to a naturalistic paradigm to localize concise functional areas and
networks correlating with specific perceptual processes''
\citep{haeusler2022processing},
%
``demonstrate that increased activation in the PPA during the perception of
static pictures generalizes to the perception of spatial information embedded in
a movie and an exclusively auditory stimulus \citep{haeusler2022processing}, and
%
``provide further evidence that the PPA can be divided into functional
subregions that coactivate during the perception of visual scenes''
\citep{haeusler2022processing}

% conclusion
In summary, we reused existing data as a foundation for a new investigation in
order to generate novel findings encourage further studies, and illustrate the
benefits of publicly and freely available datasets.


\subsection{SRM study}

\todo[inline]{following parts are an old draft}

\subsubsection{Transition from study 2 to study 3}
%
Despite exploratory approach in study 2 (a.k.a. shitty modeling of subjectively
assessed events), results suggest:
%
the response to spatial information must be somewhere in within the response
time series and is detectable.
%
Hence, we might be able to use the response patterns measured during the
presentation of the audio-description in order to generate a \ac{cfs} [needs to
be defined above in overview] in study 3, and align an ``unknown'' test
participant to that \ac{cfs}.

% align left-out subject
Based on our findings in study 2 \citep{haeusler2022processing}, we assumed that
the event structure in both naturalistic stimuli would correlate, among others,
with brain responses that are similar to those correlating with the event
structure in a dedicated functional localizer.

% summary of study 2
Results of study 2 suggest that a naturalistic stimulus might provide an
engaging, task-free paradigm to localize brain functions in individual subjects.


\subsubsection{Goal of SRM study}
% the problem
Considering practical and monetary constraints in a clinical context, a paradigm
lasting 90 to 120 minutes is inappropriate for even an extensive individual
diagnostic procedure.

% goal 1: new procedure
The first goal was to assess a procedure to estimate results of a dedicated
localizer \citep{sengupta2016extension} based on data acquired during
naturalistic stimulation.
%
Following leave-one-subject out cross-validation, we estimated (i.e. predicted)
the results of the visual localizer experiment ($Z$-values of voxels within a
\ac{roi}) of a left-out test participant based on localizer results of a
reference group.

% goal 2: partial alignment
The second goal was to assessed the relationship between length of
naturalistic stimulation used to align the test participant to the fixed
\ac{cfs} and the estimation performance.
%
Lastly, the estimation performance of our new procedure based on \ac{fa} was
compared an estimation performance based on \ac{aa}.


\paragraph{Hypotheses}
%
We hypothesized that increased quantity of data used to calculate the
transformation matrices of the left-out subjects for a \ac{fa} would to increase
prediction performance.
%
Further, we hypothesized that \ac{fa} would eventually perform
``better'' than an estimation based on \ac{aa}.


\subsubsection{Discussion of SRM study}

\todo[inline]{...to be written}


\subsubsection{Future studies on SRM / functional alignment}

\todo[inline]{...to be written}


\subsubsection{Open science in context of SRM study}

\todo[inline]{...to be written}




\section{Open Science: Conclusions across the whole project}

\todo[inline]{cf. what is now written in the parts of each study}



\subsection{Contra}

\subsubsection{Intro: not required / established and still emerging (standards)}

%
Following the guidelines was not mandatory for submitting the thesis but
constituted voluntary, additional careful work.
%
The standards [cf. introduction] to follow are still emerging.
%
Guidelines are not [yet] part of a curriculum, neither in a bachelor's/master's
program nor PhD program.
%
Therefore following the guidelines is self-imposed and need to be learned based
on a PhD student's self-initiative and self-teaching.

Open data was originally collected for internal purposes of an organization.
Since use by third parties was often not considered, there is often a lack of
context, metadata and a suitable structure to interpret and reuse the data.
interpret and reuse the data.

%
You need to take extra care to everything really, really good 'cause other
people will rely on your shit and, possible with another focus and corresponding
demands.
% example: code
For example, code needs to be documented in an extent and clarity so other helps
not just the creator (and supervisor) but also "third-party persons".
%
Standardized format for everybody (but not necessarily of immediate benefit for
current researcher / research project

OS practices generally require more work and time.
%
Preparing data or code for others to access requires considerably more time than
its preparation for personal use.
%
These extra efforts may not be valued appropriately by a scientific community
who assesses research based on journal impact metrics and number of publications
(Moher et al., 2018).
%
As long as scientists are being evaluated on traditional journal metrics, there
are few incentives from a career perspective to fully commit to OS.

%
Efforts and contributions to achieving Open Data goals (e.g., transparency,
innovation, economic growth) are not sufficiently recognized (nice to have but
not mandatory).

%
Test works flows, automatization takes time (no human input)
%
This additional work feels like a burden and does not contribute to the
immediate benefits of the PhD project.

Learning about the issues, the principles, and procedures takes time.

Open and reproducible research means you need to guarantee the accuracy of the
methods used and to document all stages of the scientific process to ensure its
transparency and traceability.

%
Affected procedures involve collecting, describing, storing, processing,
analyzing, archiving and accessing data, and describing \& documenting all these
activities, using the appropriate (software) tools.

%
Affected procedures in publishing data:
%
legal issues concerning collecting, processing and publishing personal data
(statement of agreement, anonymization, licensing issues intellectual property
rights, legal right of use, security issues,)

%
data management: standardized format, make data findable (metadata), accessible,
and reusable for others

%
which people might wish to use your data for which purpose?

%
where do deposit the data (findable, accessible, persistent / long-term
storage?)



\subsubsection{Creating data}


\subsubsection{Processing data}

%
It is important that researchers come to an agreement on common data analysis
methods which go further than explanations provided in the methodological
sections of articles.

%
Organize data, files and folders: apply file naming conventions, construct
folder trees with a consistent, scalable structure, separate raw data from
analyzed data, etc.
%
Learn the basics of version control even if your actual research does not
require coding skills.
%
Being able to restore a particular version of a document written over a period
of several years can be highly valuable.
%
Automate certain recurring tasks.
%
You will be able to increase the reliability of your results and make writing
scientific articles easier because you can vary parameters more easily.
%
take part in a research project with other laboratories; use public datasets if
these exist.

%
Automate your processing and workflows: design scripts to process your data and
manage your workflow steps.
%
For example, avoid using spreadsheets for large datasets.
%
Document your code and data:
%
what is clear when working may be less clear two months later even when you are
the author.
%
This is more a question of explaining the end-use of your functionalities rather
than describing how they work.


\subsubsection{Publishing data and / or results}

The aim of findable principle's is to facilitate the discovery of data by
humans and computer systems and requires the description and indexing of data
and metadata.

The Accessible principle encourages the long-term storage of data and metadata
and facilitating their access and/or downloading by specifying the conditions of
access (open or restricted) and use (license).

TO CHOOSE THE RIGHT DATA WAREHOUSE YOU SHOULD CHECK:
%
the warehouse's conditions of use including licenses, the types and formats of
data accepted, whether it is possible to deposit several versions of a dataset,
the guarantees offered in terms of archiving and long-term access.


\paragraph{Data leeching}
%
Publishing data comes with the thread that other working groups (possibly more
money, brain and people power) use your data for similar project and eventually
winning the "race of scientific competition" by preempt parts of your project
making own analyses \& results "obsolete".
%
However, ECRs might also see risks associated with OS. While ECRs seem to a have
a positive opinion on receiving open data, they are somewhat wary of supplying
it, with the fear of being scooped as main reason (Nicholas et al., 2019).
%
Despite the available tools to avoid this risk (e.g., time stamped DOIs), it is
difficult to counter this fear.
%
The damage that scooping entails for ECRs, generally with none or only a couple
of publications, could be relatively higher than when it affects an established
researcher with a long publication list.
%
This might be especially critical for ECRs pursuing their PhD, as they often
need a certain number of first authorship articles to be able to defend their
dissertation. Other negative factors that can be crucial when considering OS are
flexibility and time.
%
Some OS practices (e.g., preregistrations) can reduce the flexibility of the
researcher to look at new unexpected findings or tweak their methods halfway.
%
Although these practices are intended to reduce the researcher’s degrees of
freedom when performing confirmatory research (Nosek et al., 2018), ECRs might
perceive them as an obstacle under the pressure of conducting innovative
research [Florez, 2021].


\subsubsection{But: Nobody really gives a shit about it}

%
Automatized creating (complex) figures without human intervention / finalization
from numeric results. [limited software packages]
%
People who do not give a shit about it and don't do it, do ``worse'' research
but are faster/``better''.

Retrospectively, I cannot remember one case which made me glad having
documented, version-controlled, automatized stuff (maybe, materials a little
better organized or  my code was a little cleaner, I don't know)

Benefits like: accessible can positively influence its impact. For example,
sharing data and code can bring recognition and citations from replication
studies or meta-analyses of published and unpublished data, whereas the
citations of OA articles have been reported to be 18\% higher than those of
non-OA articles (Piwowar et al., 2018).
%
Thus, while conducting OS may initially require more work in the short term, it
can greatly benefit one’s career in the long term. [Florez, 2021]




\subsection{Two-sided stuff}

\subsubsection{As a data consumer, can you trust the data creators?}

\todo[inline]{check the data you created or others will do it; might get
"embarrassing"}

\todo[inline]{I could write here that I pulled my hair out while searching for
inconsistencies in the timings, and found that the audio track of the
audio-description is essentially unsystematically shifted}

%
Dataset will never be perfect and will contain noise, or even artefacts.
%
Dataset creators need to be extra careful and describe description of procedures
and data as exhaustive as possible.
%
Quality standards vary from field to field and even within subfields of
neuroscience (a.k.a. "interessiert uns ja nicht" vs. "nach bestem Wissen und
Gewissen").
%
Since it is impossible to anticipate all future use cases, unknown unknowns of
dataset creators are inevitable.
%
This essentially boils down to researchers that want to publish data to highly
take care that the dataset gets really, really good, and test and validate the
data substantially and rigorously.
%
Contingencies need to be taken care of and use-cases considered/anticipated that
go beyond the originally anticipated use-cases (``a.k.a. interessiert uns ja
nicht'').
%
Analyses can be fixed and rerun, data based on shitty paradigms are a waste of
time and money.

%
The same applies not just for the collection of raw data but also any
preprocessing steps, (that might lead to different results based on parameters,
operation system, software version etc.) or any kind of results.
%
Standardizing the analyses pipelines helps.
%
Nevertheless, there is no "one size fits all" uses-cases.
%
Hence, being able to re-run analyses with custom parameters for specific
use-cases helps

%
Vice versa, dataset "consumers" need to check the data according to their uses
cases.
%
dataset "consumers need to assume that everything that is not explicitly stated
in the description of the dataset is has not been considered and done.

%
In summary,
%
creators: work extra carefully, anticipate use cases (be aware of requirements
in adjacent fields, and describe in as much detail as possible,
%
Academic education: it is mandatory to create awareness, and teach established
and emerging standards to students.


\paragraph{"Solution": Balance of checking and trust}

%
Consumers: "Trust is good, control is better" (Wladimir Iljitsch Lenin).
%
On the other hand, there is an hard to judge ``correct'' balance between
trusting the work of others that collected the raw data, and checking the data
and familiarize yourself with the data.
%
Researchers need to handle that two-sided sword and balance trusting the
creators of the dataset and checking/validating everything themselves.

%
However, controlling everything leads the idea ad absurdum, not possible in some
cases (visually check fmri data of hundreds of persons?)
%
Consumers need to be able to have a degree of trust.




\subsection{Pro}

\todo[inline]{Why was is good for science that the data were already existing?}

\todo[inline]{Why was is good for you that the data were already existing?}

The advantages of a reproducible approach
%
a) Errors are easier to identify and correct. You trace and record how your data
and/or code evolves from the very start of the project and with each
modification.
%
It is much harder and less safe if you have to reconstruct these developments a
posteriori.
%
b) The results you obtain can be more easily explained and justified to peers.
%
When submitting an article for publication, it will be easier for you to respond
to any requests from your reviewers.
%
c) Future work is made less uncertain.
%
You give yourself the possibility of reusing data, code, documents, etc. in the
future.


I was glad about the provided infrastructure.

Open and transparent sciences increases trust of the public into scientific
process and its results.

Publishing data makes researchers accountable to collect, process, document, and
store data properly (opposed to data collected and stored for mere in-house use;
"ach, Tömme...")

Published data allows validation by external persons.

Also, helps students to take a look at the methods in detail and replicate the
results (method sections of papers are often insufficient)

Facilitates progress of a whole field: data re-use for bigger Projects
(meta-analyzes) or unanticipated use cases.

Open materials facilitate tracking (and understanding!) the process (esp.
analyzes) in detail (pipelines are often far easier to understand by reading the
code step-by-step than just reading the method section)

Researchers want and have to be (more) responsible to create traceable [?] and
understandable pipelines.
%
Be ready and open to held accountable years later how results were achieved
(which should be self-evident by the published material anyway).

Benefits are increased robustness and reliability of science when all steps are
openly documented and data are openly available.
%
This is also a boon to the individual scientist, as open science can protect
oneself against unreproducible studies to a certain degree.
%

\subsubsection{Raw data}

%
On the one hand, not spending time on collecting data is speeding up the process
of getting to analyze the data, and go beyond what would have been possible if
you would have collected the data yourself solid base.

%
Not everybody has the resources to collect (big) datasets.
%
Covid-Pandemic has impressively shown that "human subject research" has gone
dormant for almost 1.5 years.
%
Probably to personal: plan of the project was adjusted accordingly.

\paragraph{Less work (i.e. raw data)}
%
You save time and money (especially if you do not collect the data yourself) but
you have to trust that the data are ``good'' and start at some point to reach
goals that you would not accomplished if you would have done all from scratch
(i.e. preprocessing).


\paragraph{Saving time because data exist does not mean that you have more time}

%
It's not getting easier, it's just that the focus of the work shifts to another
area [a.k.a. writing a thesis is so easy today because we did it on typing
machines and you have computer software today]



\paragraph{But opportunity costs}

%
Follow a chosen path or do it all from scratch again?

Wikipedia: ``opportunity cost of a particular activity is the value or benefit
given up by engaging in that activity, relative to engaging in an alternative
activity.
%
More simply, it means if you chose one activity (for example, an investment) you
are giving up the opportunity to do a different option.
%
The optimal activity is the one that, net of its opportunity cost, provides the
greater return compared to any other activities, net of their opportunity
costs''.

%
you need to trust the dataset creators but still test/[re]check the data
according to your needs (and knowledge).

%
Any further processing steps is based on variables/decisions/parameters.
%
Opportunity costs: take (for granted) what is already done or do it yourself?


\paragraph{Opportunity cost example: missing ROIS of RSC and OPA in Sengupata}

%
Raw measures vs. preprocessed data vs. results
%
For example, analyzes in \citet{sengupta2016extension} were performed (and
published) in voxel-space (not surface-space).
%
Resulting masks were restricted to one scene-selective area (\ac{ppa}; no
\ac{rsc}, \ac{opa} = transverse occipital sulcus).
%
Should be very hard to exactly copy the procedure applied to \ac{ppa} to
\ac{rsc} and \ac{opa}.


We (and Sengupta) chose the PPA among three possible candidates (cf. answer to
point 2) because it was the first area to be discovered as a visual
``scene-selective'' region, is the most reliably activated region across studies
that investigate visual scene perception [cf. response to reviewer \#2].

``We thank the reviewer for bringing up the connection to visual scene
processing and scene imagery in the medial parietal cortex. We adjusted the
figures, as suggested (see point 3). We agree with the reviewer and also believe
that the increased hemodynamic activity in the medial parietal cortex is of
interest. We assumed that results (at least of the audio-visual stimulus) could
also yield significant clusters in the retrosplenial complex (RSC) and superior
lateral occipital cortex (i.e. “occipital place area”, OPA) but did not
explicitly hypothesize that fact. Whereas the PPA is assumed to be more involved
in landmark recognition by processing basal perceptual features that constitute
a scene, the RSC (i.e. ventral precuneus and posterior cingulate region)
exhibits stronger responses when the scenes are familiar to the participants
suggesting the RSC might be more concerned with localizing, i.e. orienting, the
observer in space (e.g. Epstein \& Vass, 2016). We believe that a detailed
discussion of the RSC activation is out of scope for this manuscript, but the
current results are certainly an incentive for further studies''.

\todo[inline]{following paragraph is simply copied from the PPA paper}

%#12 RSC + LOC
``Apart from the PPA, results show significantly increased activity in the
ventral precuneus and posterior cingulate region (referred to as ``retrosplenial
complex'', RSC) of the medial parietal cortex, and in the superior lateral
occipital cortex (referred to as ``occipital place area'', OPA) for both
naturalistic stimuli.
% RSC intro
Like the PPA, the RSC and OPA have repeatedly shown increased hemodynamic
activity in studies investigating visual spatial perception and navigation
\citep{chrastil2018heterogeneity, bettencourt2013role, dilks2013occipital,
epstein2019scene}.
% inference
Thus, our model-driven approach to operationalize spatial perception based on
stimulus annotations reveals increased hemodynamic responses in a network that
is implicated in visual spatial perception and cognition.
% medial parietal cortex: anterior-posterior gradient
Similarly to the parahippocampal cortex \citep{aminoff2013role}, the medial
parietal cortex exhibits a posterior-anterior gradient from being more involved
in perceptual processes to being more involved in memory related processes
\citep{chrastil2018heterogeneity, hassabis2009construction, silson2019posterior,
steel2021network}''.

% future studies
``Future, complementary studies using specifically designed paradigms could
investigate where in the posterior-anterior axis of the parahippocampal and
medial parietal cortex auditory semantic information is correlated with
increased hemodynamic activity:
% we hypothesize
we hypothesize that the auditory perception of spatial information (compared to
non-spatial information) is correlating with clusters in the middle of possibly
overlapping clusters correlating with visual perception (peak activity more
posterior) and scene construction from memory (peak activity more anterior)''
\citep{haeusler2022processing}.



\subsubsection{Processing data}

\todo[inline]{cf. point as for FOSS and bugs in software; but nobody looked at
my code anyway}



\subsubsection{Publishing data and / or results}


\subsection{Conclusion (a.k.a. the greater goods of open science)}

Benefits that go along this additional work are not immediately
visible to researchers/authors but...

%
Scientific advancement is best served by enabling as large a community as
possible to build upon existing research; and think about the general public and
fucking humankind in general!.


From introduction:
% reproducibility crisis
Over the last decade, there has been a growing awareness that results of
scientific publications are not reproducible or general scientific findings are
not replicable letting some authors speak of a ``reproducibility crisis'' or
``replication crisis'' in the sciences \citep{baker2016reproducibility,
plesser2018reproducibility, stupple2019reproducibility, nosek2022replicability}.
% reproducibility: definition
``A study is reproducible if all of the code and data used to generate the
numbers and figures in the paper are available and exactly produce the published
results'' \citep{leek2017most}.
% replicability: definition
A study is replicable if the same analysis of an equivalent experiment's data
leads to consistent results \citep{dubois2016building, leek2017most}.


\todo[inline]{cf. [Florez 2021]: 5.2. Implications for the Development of OS
Policies and Training Programs}

%
There is a need to introduce systematic OS policies with clear incentives and
specific training strategies to support these bottom-up interests.



\section{Conclusion: Naturalistic stimuli as functional localizer}

Summary of PPA paper:
%#13 natural stimulation
``In summary, natural stimuli like movies \citep{eickhoff2020towards,
hasson2008neurocinematics, sonkusare2019naturalistic} or narratives
\citep{hamilton2018revolution, honey2012not, lerner2011topographic,
silbert2014coupled, wilson2008beyond} can be used as a continuous, complex,
immersive, task-free paradigm that more closely resembles our natural dynamic
environment than traditional experimental paradigms.
% method
We took advantage of three fMRI acquisitions and two stimulus annotations that
are part of the open-data resource
\href{http://www.studyforrest.org}{studyforrest.org} to operationalize the
perception of spatial information embedded in an audio-visual movie and an
auditory narrative, and compare current results to a previous report of a
conventional, block-design localizer.
% results
The present study offers evidence that a model-driven GLM analysis based on
annotations can be applied to a naturalistic paradigm to localize concise
functional areas and networks correlating with specific perceptual processes --
an analysis approach that can be facilitated by the neuroscout.org platform
\citep{delavega2021neuroscout}.
% interpretation
More specifically, our results demonstrate that increased activation in the PPA
during the perception of static pictures generalizes to the perception of
spatial information embedded in a movie and an exclusively auditory stimulus.
% interpretation: aPPA vs. pPPA
Our results provide further evidence that the PPA can be divided into functional
subregions that coactivate during the perception of visual scenes.
% interpretation
Finally, the presented evidence on the in-principle suitability of a naturally
engaging, purely auditory paradigm for localizing the PPA may offer a path to
the development of diagnostic procedures more suitable for individuals with
visual impairments or conditions like nystagmus''
\citep{haeusler2022processing}.

\subsubsection{Caveats of naturalistic stimuli}
%
Challenging data data analysis, but create \& share annotation.
%
Hence, data analysis pipelines should be implemented in common and
well-documented packages and code, and custom code shared along the paper.

%
Just an approximation of real life.
%
Setting is still the scanner.
%
Passive watching \& listening.
%
Executive functions?


\subsubsection{Clinical application}

\todo[inline]{most on this topic is in SRM part}

%
``The ability to non-invasively and automatically delineate cortical areas in
living subjects may have clinical implications, for example by providing
neurosurgeons with detailed, individualized maps of the brains on which they
operate'' \citep{glasser2016multi}.

%
A full feature film might substitute traditional localizer paradigms dedicated
localizer by mapping a variety of brain functions beyond category-specific
visual areas.

%
Therefore, a new independent dataset should be collected that employs
naturalistic stimulation.
%
Additional measures of a variety of localizers would enable comparison of
results from analyzing the naturalistic stimuli and results from localizer
contrasts.

%
For example \ac{fmri} could be used as an noninvasive alternative to map
language areas and potentially assess lateralization (or hemispheric asymmetry)
of functional brain topography related to language (sub)functions, in order to
guide pre- and perioperative assessment of neurosurgery, e.g., in case of
epilepsy.

\todo[inline]{language areas are more clinically relevant, but problem in case
of prediction (esp. using ROI): atypical language lateralization \& usually no
lateralization in naturalistic stimuli (but operationalization is different from
localizer paradigms), assumption of (strict) lateralization probably wrong
anyway}

\todo[inline]{Further quotes/templates from papers using \ac{fmri} to localize
language areas are outsourced to separate file}


\section{Conclusion: naturalistic stimuli in general}
%
Naturalistic stimuli are not a panacea but traditional paradigms and
naturalistic paradigms should be used in tandem / reciprocally to generate new
hypotheses and progress our understanding of the brain.


%
In summary, naturalistic stimuli ``impose a meaningful timecourse across
subjects while still allowing for individual variation in brain activity and
behavioral responses, and lend themselves to a broader set of analyses than
either pure rest or pure event-related task designs'' \citep{finn2017can}.
%
``Naturalistic paradigms do not aim to replace the classic, controlled
neuroimaging paradigms (Sonkusare et al., 2019). Due to their complexity and
current limitations in understanding the statistical properties of different
features in naturalistic conditions, naturalistic stimuli are not optimal for
model development [see, e.g., Rust and Movshon, 2005]. Controlled experiments
are still needed for hypothesis testing and developing models, while
naturalistic stimuli are best employed to test models in ecologically valid
settings and to expand them to situations where context matters
more'' \citep{saarimaki2021naturalistic}.
