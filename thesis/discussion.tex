\section{Theory part}

\todo[inline]{might be merged with "Overview (incl. general goals)" below}

Human brain mapping studies have traditionally averaged \ac{fmri} data across
participants.
%
However, data need to be assessed on the level of individual persons in order to
advance the field towards a clinical application.
% functional localizer
An established method to characterize the topography (i.e. the location, size,
and shape) of functional areas on the level of individual are functional
localizers.
% contra localizers
However, traditional localizer paradigms employed selectively sampled, tightly
controlled stimuli, rely heavily on a participant's compliance, and can usually
map just one domain of brain functions.


\section{Overview (incl. general goals)}

\todo[inline]{This is just an overview of the goals (that need to get mentioned)
and the transition to the excursion on "Open Science"; after that "Naturalistic
stimuli as localizer" get discussed}

\subsection{Naturalistic stimuli as functional localizer?}

% movies & narratives
Naturalistic stimuli like movies and auditory narratives \citep[cf.][for
reviews]{jaaskelainen2021movies, jaaskelainen2020neural} provide a time-locked
event structure that samples a broad range of brain states, and engage multiple
perceptual and cognitive systems in parallel \citep{haxby2020naturalistic}.

%
Therefore, localizer based on naturalistic stimulus could
%
a) potentially map a variety of brain functions [ranging from low-level
perception (e.g., luminance) to high-level cognition (e.g., social cognition)]
simultaneously,
%
b) while also resemble how we perceive the real world outside of the laboratory
during everyday life, and, thus, could provide higher external validity,


%
The goal of this thesis was---while following the principles of
open, transparent, and reproducible science---to explore whether a movie
and the movie's audio-description could, in principle, substitute a traditional
localizer paradigm.

% PPA as proof of concept
As a proof of concept, we focused on the \ac{ppa}, a ``classic'' higher visual
area that exhibits increased hemodynamic activity when participants view photos
of landscapes, buildings or landmarks, compared to, e.g., photos of faces or
tools \citep[e.g.,][for reviews]{epstein2014neural, aminoff2013role}.
% auditory semantics unclear
To our knowledge only one study \citep[cf.][]{aziz2008modulation} compared
hemodynamic activity levels in the \ac{ppa} that were correlated with different
categories presented in spoken sentences.
%
Despite mixed results, the findings by \citet{aziz2008modulation} suggest that
\ac{ppa} does not exclusively respond to visually presented scene-related
stimuli.
% visually impaired
Lastly, an exclusively auditory stimulus like an audiobook or audio drama would
also be appropriate for visually impaired persons[, e.g., suffering from
nystagmus or lack of eyesight].


%
I will evaluate the movie's and audio-description's potential to substitute a
visual localizer in two ways.


\subsubsection{First approach: \ac{glm} $t$-contrasts}

\todo[inline]{Somehow better prime that stimuli need(ed) to be annotated}

% similarity
Similarly to traditional localizer paradigms, we model hemodynamic activity
correlating with the perception of spatial information, and created \ac{glm}
$t$-contrasts in order to localize the \ac{ppa}.


\paragraph{naturalistic visual stimulation}

\todo[inline]{at least the annotated features are visual}

\todo[inline]{no blocks, but events}

% based on stimulus annotations
Differently from traditional localizers, we model hemodynamic activity based on
annotated stimulus features that are embedded in the audio-visual movie
``Forrest Gump''.


\paragraph{auditory naturalistic stimulation}

% based on stimulus annotations
Differently from traditional localizers, we model hemodynamic activity based on
annotated stimulus features that are embedded in the movie's audio-description.



\subsubsection{Second approach: estimation from ref}

\todo[inline]{Estimation from reference mentioned here for the first time}

\todo[inline]{When SRM study is written, revise accordingly}

%
In order to address the practical and monetary constraints of a clinical
context, we estimate localizer results of participants from results of
participants in a \textit{reference group}.
%
This is based on a super awesome functional alignment using naturalistic fMRI
data (to create the common functional space and align a left-out subject).
%
Mention partial alignment



\subsection{Open Science}

\paragraph{\citet{halchenko2021datalad}}

\todo[inline]{cf. text 1.3.5}

%
The meta goal of this dissertation was to perform all studies under the
principles of open, shared, and transparent science.

% goal PPA study
Under the perspective of an open science project, the goal of study 2 was to use
three \ac{fmri} datasets \citep{hanke2014audiomovie, hanke2016simultaneous,
sengupta2016extension}, two stimulus annotations \citep{haeusler2021speechanno,
haeusler2016cutanno}, as well as previously published results
\citep{sengupta2016extension} for a new research question.

%
Hence, \citet{halchenko2021datalad} was the technical groundwork for the
"actual" thesis.
%
Results enabled us to track, version-control stuff and publish data, code,
materials, results, publications in a way that...

%
...enables independent researchers to validate current results and use written
code to replicate current findings in prospective studies, all created data,
code, analysis steps, and results are published as version-controlled DataLad
\citep[\href{www.datalad.org}{datalad.org};][]{halchenko2021datalad} datasets.



\section{Open Science}

%
``Open and reproducible research means you need to guarantee the accuracy of the
methods used and to explicitly describe and document all stages of the
scientific process to ensure its transparency and traceability''.

%
Over the course of the present project, affected stages were
% data-related
a) acquiring open data (assessing their quality, processing it),
%
b) providing open data (collect or create, description and storage of data),
%
c) automatize all that shit (processing and analyzing data) via code,
% publishing shit
d) publication of data, materials and results.



\subsection{Acquiring open data}


\subsubsection{Definition of "open data"}

\todo[inline]{Define open data here (includes preprocessed data \& results)}

find, download, assess quality

\subsubsection{Example: Data for PPA study}

% skipped work
On the one hand, the availability of the \ac{fmri} data and the subject-specific
\acp{roi} enabled us to shift our focus from acquiring the raw data to
subsequent stages of a research project.

% example of skipped work
For example, the annotations \citep{haeusler2016cutanno} that were created in a
"general purpose state" could be extended immediately to match the needs of
\citep{haeusler2022processing}, followed by writing the scripts that
preprocessed and statistically analyzed the data.
%
For me, it was not "3rd party" data but I was involved in the data collection
process and hence somewhat familiar with the data (provenience, location,
quality, accessibility, storage format, performed preprocessing steps).

\todo[inline]{not relevant in my case: participants' consent, anonymization,
most legal issues}

\subsubsection{Example: analyses in voxel space \&  missing ROIS of RSC \& OPA}

More an issue, when data have been preprocessed (more decisions were made) or in
case of results.

We focussed on the \ac{ppa}.
%
% RSC intro
Like the PPA, the RSC and OPA have repeatedly shown increased hemodynamic
activity in studies investigating visual spatial perception and navigation
\citep{chrastil2018heterogeneity, bettencourt2013role, dilks2013occipital,
epstein2019scene}'' \citep{haeusler2022processing}.
%
``We (and Sengupta) chose the PPA among three possible candidates
because it was the first area to be discovered as a visual ``scene-selective''
region, is the most reliably activated region across studies that investigate
visual scene perception'' [response to reviewer \#2].
%
In the progress of conducting study 2, ``we assumed that results (at least of
the audio-visual stimulus) could also yield significant clusters in the
retrosplenial complex (RSC) and superior lateral occipital cortex (i.e.
“occipital place area”, OPA) but did not explicitly hypothesize that fact''.
%
``Apart from the PPA, results show significantly increased activity in the
ventral precuneus and posterior cingulate region (referred to as ``retrosplenial
complex'', RSC) of the medial parietal cortex, and in the superior lateral
occipital cortex (referred to as ``occipital place area'', OPA) for both
naturalistic stimuli.

%
``Whereas the PPA is assumed to be more involved in landmark recognition by
processing basal perceptual features that constitute a scene, the RSC (i.e.
ventral precuneus and posterior cingulate region) exhibits stronger responses
when the scenes are familiar to the participants suggesting the RSC might be
more concerned with localizing, i.e. orienting, the observer in space [e.g.
Epstein \& Vass, 2016]'' [response to reviewer \#2].
% medial parietal cortex: anterior-posterior gradient
``Similarly to the parahippocampal cortex \citep{aminoff2013role}, the medial
parietal cortex exhibits a posterior-anterior gradient from being more involved
in perceptual processes to being more involved in memory related processes
\citep{chrastil2018heterogeneity, hassabis2009construction, silson2019posterior,
steel2021network}'' \citep{haeusler2022processing}.

%
''We believe that a detailed discussion of the RSC Activation in RSC and OPA was
out of scope of the current study, results are an incentive for further
studies''.
% future studies
``Future, complementary studies using specifically designed paradigms could
investigate where in the posterior-anterior axis of the parahippocampal and
medial parietal cortex auditory semantic information is correlated with
increased hemodynamic activity:
% we hypothesize
we hypothesize that the auditory perception of spatial information (compared to
non-spatial information) is correlating with clusters in the middle of possibly
overlapping clusters correlating with visual perception (peak activity more
posterior) and scene construction from memory (peak activity more anterior)''
\citep{haeusler2022processing}.

%
In the context of open science, this was kind of an limitation / aftereffect of
coverage of mask for functional areas \citet{sengupta2016extension}, and the
non-algorithmic procedure of \citet{sengupta2016extension} based on subjective
decision that is hard to replicate \& to amply to the other functional areas
\citep[cf. algorithmic procedure in, e.g.,][]{julian2012algorithmic}.



\subsubsection{Pro's \& Con's}


\paragraph{Pros from perspective of consumers}

%
Open data low-threshold access to datasets, especially fruitful for research
groups that enjoy minor funding but also students that can learn hands-on using
"real world data".
%
Open data helps researchers to shift time and resources from data collection to
subsequent stages of a study; or evaluate data quality given the decisions,
parameters made during the data collection, or just run proof-of-concept before
collection their own data.


\paragraph{Cons from perspective of consumers}

% avoid "the bigger, the better" and "garbage in, garbage out"
An mostly not explicitly stated issue in the context of open science is that
standards (quality, formats, parameters) and open sciences practices (e.g.,
documenting) might vary across scientific field, or within scientific fields
depending on a working group's knowledge and rigor.
% check the data
Dataset consumers need to assume that everything that is not explicitly stated
in the description of a dataset has not been considered and done by a dataset's
creator.
% laugh with many, don't trust any
Even if the data a from a renowned source, researchers should consider
themselves to be obliged to test and validate a dataset's quality according to
their standards and specific use cases.


\paragraph{Conclusion (= consider opportunity costs)}

% problem of preprocessed data
Moreover, choices made during data collection and preprocessing -- despite being
state-of-the-art at the time of being published -- might not be optimal for
every use case or made obsolete by more advanced methods.
% tell me about opportunity costs without saying opportunity costs
Hence, researchers need to weigh the costs and benefits of one path (e.g.,
preprocessing the same data differently than the preprocessing performed as part
of an open dataset) relative to an alternative path (e.g., using the
preprocessed data and performing new analyses), and choose the path with the
greater net return.
%
Anything that is not 100\% automatized is not 100\% reproducible, hard to
extend, sadly because automatization takes a long time for some stuff or is not
possible for some stuff.


\subsection{Providing open data}

"It is more blessed to give than to receive"
%
In the context of open data, data are not collected for mere internal purposes
but also collected, described, stored for re-use by third parties which needs to
be considered.



\subsubsection{Example: Annotation}
% additional effort 1
Pursuing the goal of creating a publication-worthy annotation of speech in
\citep{haeusler2021speechanno} as dataset led to additional work that goes far
beyond the work that was necessary to build the \ac{glm} in
\citep{haeusler2022processing}.

% additional effort 2
The published annotation provides, among others, time-stamps of phonemes, words
and sentences of all speakers, a grammatical tagging, and an annotation of
syntactic dependencies and semantics.

%
In summary, the annotation provides extensive information about the time course
of stimulus features, and therefore a headstart to independent researchers that
wish to ``model hemodynamic brain responses that correlate with a variety of
aspects of spoken language ranging from a speaker's identity, to phonetics,
grammar, syntax, and semantics'' \citep{haeusler2021speechanno} under more
real-life like conditions.
%
Therefor, it's an exhaustive annotation of speech that substantially exceeds the
groundwork necessary to conduct study \citep{haeusler2022processing} in order to
extend the studyforrest dataset as a public resource for independent research.

%
Consequently, the outcome of study 1 contributes to the studyforrest project as
a resource for the scientific community by further widening the ``annotation
bottleneck'' \citep{aliko2020naturalistic} of two naturalistic stimuli.



\subsubsection{Pros \& Cons}


\paragraph{Pros from perspective of creators}

% better organized, better documented
An immediate benefit of following the principles of a reproducible study is that
a researcher is forced to work more organized and document every step from a
study's start to finish more rigorously.
%
First, documenting every step and justifying every step by weighting pros and
cons of alternative [mutual exclusive] procedural paths leads to better
understanding, avoids tricking oneself into performing unnecessary statistical
tests, HARKing hypothesizing after the results are known; Kerr, 1998,
HARKing...), and therefore supports following general good scientific practices.
%
Similarly, the extra time and effort spend on inspecting data and testing code
leads to higher confidence in one's own work and the reliability of results.
%
Second, a researcher who records all changes to data and code from the start to
the final results can restore a particular state of data and code and trace,
identify and correct errors more easily [similar: Klein, 2018. A practical guide
for transparency in psychological science].
%
Third, tracking and documenting every step increases reliability of results and
can be seen as a "lab protocol" containing information / templates for writing
scientific articles.
%
Last, automating recurring tasks gives yourself the possibility of reusing
certain data, code, documents, etc. in the future.


\paragraph{Cons from perspective of creators}

%
Hence, dataset creators need to anticipate which people might use the data for
which purpose, collect the data according to best practices, convert data into a
standardized format (considering, e.g., naming conventions, folder structure,
separating raw from analyzed data), and create metadata.

% data analysis & automatization
The data, materials and code need to be documented more rigorously, and coverage
of procedures need to exceed the coverage given in method sections of regular
articles.

Data need to be of quality and in a state worthy to be published and documented
for other readers, analyses pipelines needed to be in a state to be automatized,
every processing step documented, saved, protocolled, and shared to allow
reproducibility of results and facilitate replicability of finding.


% jeez! it's annoying!
In general, creating open data, materials and code requires a considerable about
of time and effort with little incentives and little, immediate rewards.


%
Publishing data (or merely using open data) is associated with the risk that
other working groups, possibly having more funding and ``people and brain
power'' at disposal, are using the same data for a similar research question at
the same time.
%
Hence, there is the concern that someone else might ``claim priority, usually
through publishing, to a research idea or result you yourself have been working
on'' \citep{laine2017afraid}.
%
On the one hand, being second in the ``competitive race in the sciences'' leads
to diminished opportunities to publish own results because high impact journals
favour novel findings.
%
The risk, and therefore stress, is aggravated in case of researchers that are
early in their scientific career \citep[cf.][]{toribio2021early}, created and
curate the published dataset, pre-registered studies based on open data, or have
to stick to inflexible project plans.
%
On the other hand one advantage of publishing a dataset with an assigned DOI is
that it might get re-used and cited in another study.
%
In case of a dataset creator's fear of being superseded / outrun, ``concerns can
be alleviated by delaying the sharing or using a data-sharing repository with an
embargo period'' \citep{nichols2017best}.



\subsection{Providing code \& Automatize everything}


Open access packages, transparency, reproducibility, avoid creating a "paywall"
for processing open data (turning that shit ad absurdum)



Code need to be of quality and in a state worthy to be published and documented
for other readers, analyses pipelines needed to be in a state to be automatized,
every processing step documented, saved, protocolled, and shared to allow
reproducibility of results and facilitate replicability of finding.

Automatization of downloading, processing \& analyzing, creating figures,
results.





\subsubsection{Example: from basic python to neuroscience-specific packages}



Python, NumPy, Brainiak, NiLearn...
%
Shared code (analyses-pipelines) helps researchers adjust
and extent the analysis pipeline as part of an exploratory data analysis.

\subsubsection{Pro's \& Con's}

Often forgotten, but open-source packages were prerequisite and done by others
"that like to share".

\paragraph{Contra}

%
In order to allow reproducibility from input data, changes made to the data, to
computation and visualization of results, every processing step needs to be
designed and tested to be run reliably and automatically.

%
Every change made to data, materials or code, and command line invocations need
to be tracked via a version control system \citep[e.g.,][]{halchenko2021datalad}
to allow other researchers to inspect a study's full history.


\paragraph{Pro}

Similarly, the extra time and effort spend on inspecting data and testing code
leads to higher confidence in one's own work and the reliability of results.
%
Second, a researcher who records all changes to data and code from the start to
the final results can restore a particular state of data and code and trace,
identify and correct errors more easily [similar: Klein, 2018. A practical guide
for transparency in psychological science].
%
Third, tracking and documenting every step increases reliability of results and
can be seen as a "lab protocol" containing information / templates for writing
scientific articles.
%
Last, automating recurring tasks gives yourself the possibility of reusing
certain data, code, documents, etc. in the future.


\subsubsection{Pros \& Cons}


\subsection{Publication of data, materials and results}

\subsubsection{Definition of open access}

% publication: findable, accessible, interoperable, reusable
In the stage of preparing a publication, a researcher needs to facilitate
discovery by humans and web bots (e.g., via extensive description and
machine-readable metadata), ensure long-term curation [e.g., maintenance],
availability [e.g., accessibility], and choose an appropriate data host.
% legal issues
Finally, a researcher need to resolve legal issues that raise during due to the
publication of data, materials and code (e.g. statement of agreement / consent,
anonymization, intellectual property rights, use license).



\subsubsection{Example from present thesis}

\todo[inline]{choosing the data host was easy because filtered based on DataLad
support (and Michael knows everything anyway)}

\todo[inline]{mention "open paper"? speech anno paper is on github;
ppa paper is not a public github repository (yet)}

% results
Our results have been published in a peer-reviewed, open-access journal
%
``offer evidence that a model-driven GLM analysis based on annotations can be
applied to a naturalistic paradigm to localize concise functional areas and
networks correlating with specific perceptual processes''
\citep{haeusler2022processing},
%
``demonstrate that increased activation in the PPA during the perception of
static pictures generalizes to the perception of spatial information embedded in
a movie and an exclusively auditory stimulus \citep{haeusler2022processing}, and
%
``provide further evidence that the PPA can be divided into functional
subregions that coactivate during the perception of visual scenes''
\citep{haeusler2022processing}

% conclusion
In summary, we re-used existing data as a foundation for a new investigation in
order to generate novel findings encourage further studies, and illustrate the
benefits of publicly and freely available datasets.



\subsubsection{Pros \& Cons}


\paragraph{Cons}



\paragraph{Pros}

\todo[inline]{My super interesting papers might get cited more often because,
yeah, open access that gets, on average, cited more often [REFERENCE?]}

\todo[inline]{compare that to papers that do not share code}

\todo[inline]{better understanding (than from a method section), step-by-step
guide; learning via reading or "trying it yourself"}


``greater potential impact of a work when it may be cited not just for its
scientific findings but also when its data is reused in other works''
\citep{nichols2017best}.



%
From the perspective of reader, open access journals provides low-cost access to
information.
% readers get a better understanding
A ``transparent and complete reporting of all facets of a study, allowing a
critical reader to evaluate the work and fully understand its strengths and
limitations'' \citep{nichols2017best}.
%
It helps readers to take a look at the methods in more detail it is conveyed in
a often limited method section of a regular study.
%
``This also facilitates subsequent research efforts by other investigators, who
can exactly follow (or carefully manipulate) each aspect of a study''
\citep{nichols2017best}.
%
Open materials facilitate tracking (and understanding!) the process (esp.
analyzes) in detail (pipelines are often far easier to understand by reading the
code step-by-step than just reading the method section).
%
Interesting to students how can not just read a method section but also take a
look at the code and follow step by step every command.
%
Fully transparent studies that also include the input data can serve as an
``education playground'' by enabling (undergraduate) student to trace the
progress of real world project, to learn coding and data analysis.


\subsection{Conclusions on open science}

\subsubsection{Summary of my life's story}

\todo[inline]{Caveat of data re-use: know your data! I could write that I pulled
my hair out while searching for inconsistencies in the timings, and found that
the audio track of the audio-description is essentially unsystematically
shifted; similar cases stay probably undiscovered in non-open datasets; vice
versa, a point for less error-prone open science}

\todo[inline]{Covid-Pandemic has impressively shown that collecting data based
on human subjects" can go dormant for almost 1.5 years; plan of the project was
adjusted accordingly; and I am so lucky that I could fall back on open data}

\todo[inline]{it is/was somewhere between "stupid" and "brave" to mess with
someone like Haxby's group; also, cf. "my precious" of Susanne and Lisa}



%
Following the practices of open and reproducible science was not mandatory for
submitting the thesis but required additional work and time.

%
Standards to follow are not yet fully established and corresponding software
tools are still emerging.
%
Since the best practices are not yet part of a graduate or PhD curriculum,
learning about the principles and standards and applying the corresponding
procedures and necessary tools was based on self-initiative and self-learning.

%
Great care was taken during the initial creation and subsequent iterative
corrections in order to provide accurate information to the scientific
community.
%
However, over the course of generating the dataset it became apparent that there
is no such thing as a ``perfect'' annotation:
%
As in human language in general, an annotation of speech will always contain
ambiguities.
%
Additionally, there is a trade-off that needed to be balanced between a) doing
the ``mere minimum'' and putting time and effort in creating additional
information that might not be fruitful, and b) providing a sound/substantial
groundwork for potential use-cases that needed to be anticipated.
%
Any further processing step might be based on a decision that might not match
the requirement of a specific use case.
%
For example, an annotation of semantics might be based on a current state-of-the
art language model that might be superseded by future language models.
%
Therefore, the published annotation does not only comprise the final outcome but
also the raw data and documented code that can automatically be rerun step by
step to reproduce the final outcome of both the annotation and its validation
analysis, all freely accessible in a version-controlled dataset.

%
Automatization gets super fucking annoying in case of automatized creation of
(complex) figures from numeric results without final editing of the figure by a
human.  Jeez! Fuck me sideways!

\todo[inline]{I cannot remember one clear case which made me
glad having documented, version-controlled, and automatized stuff; maybe,
materials are a little better organized or my code was a little better to grasp
after not having taken a look at it for a longer time...}


% no incentive
``Current incentives do not justify spending large amounts of time preparing
data for sharing, as institutional promotion panels or grant reviewers currently
do not adequately reward such efforts'' \citep{nichols2017best}.

Grateful, that open source neuro-software as well as the data were available,
which allowed me to go far beyond what would have been possible without open
data [kind of not true because I used "in-house data"].
%
Lastly, I feel more confident about my work now compared to the dilettantish
procedures experienced (and followed) in, uhm, another lab in Magdeburg.


\paragraph{Questionable, immediate benefits; gambling}

\todo[inline]{80\% of PhD students leave science anyway}

%
``The weight that OS currently has for researchers’ career advancement is rather
small, despite'' \citep{toribio2021early}.
%
At the same time, they might feel that investing additional effort in making
research open (i.e., transparent and reproducible) is unrewarded [Nicholas et
al., 2017], such as conducting replication studies that might not be considered
for publication in high-impact journals'' \citep{toribio2021early}.
%
``As long as scientists are being evaluated on traditional journal metrics,
there are few incentives from a career perspective to fully commit to OS''
\citep{toribio2021early}.


%
``Thus, while conducting OS may initially require more work in the short term,
it can greatly benefit one’s career in the long term'' \citep{toribio2021early}.
%
``OA publications have been found to receive more citations than paywalled
publications [Piwowar et al., 2018] and can therefore aid ECRs’ career
advancement'' \citep{toribio2021early}.
%
``Similarly, open data can be highly beneficial to promote new collaborations
and increase the number of citations and the confidence that the field has in
the findings [Popkin, 2019]'' \citep{toribio2021early}.
%
Currently, playing be the old rules is the ``smarter way'' than gambling getting
cited when data or code get re-used, imo.


\subsubsection{But, probably, it needs to be done}

Open sciences makes researchers accountable to collect, document, process and
store data and materials according to best practices.
%
Published data and analysis pipelines allow external persons to check the data
and analyses for undiscovered errors, and replicate the results step by step.
%
Varying parameters and running different statistics on the data allows
inspection of robustness of results.

%
``As scientists, we are supposed to be objective arbiters of evidence and
theory, but we are not infallible and must be ready to accept criticism and
revise our claims when errors are discovered'' \citep{nichols2017best}.
%
``However, we need to develop a culture of constructive criticism, which
recognizes that errors are an inevitable part of scientific progress and
protects individual researchers from inappropriately harsh consequences when
honest mistakes are discovered'' \citep{nichols2017best}.

%
``We see no better way to advance understanding on a contested finding than to
have as many researchers as possible puzzling over the data at hand''
\citep{nichols2017best}

%
Benefits are increased robustness and reliability of science when all steps are
openly documented and data are openly available.
%
Multiple datasets can be combined to perform unanticipated use cases, and
extensively and openly documented results of multiple studies facilitate
performing meta-analyses to strengthen the claims of individual studies.
%
Thus, open transparent science is the way to make knowledge and technologies
widely accessible, and increase reproducibility of study results and
replicability of scientific findings while increasing trust of the public into
scientific process and its results.
%
Open science promises increased efficiency (time and financial expense) of
making scientific progress, make advance, and promotes innovation.



\subsection{Call to action: educate, incentivize, coerce}

\paragraph{Guidelines \& tools}

\todo[inline]{need to be established; and not change all the fucking time, so as
soon as you have done it, the procedure is not obsolete already again}
%
``OS still requires the establishment of clear guidelines for transparency and
openness of research at the international level.
%
Examples for guidelines for OA publishing [Nosek et al., 2015; Schiltz, 2018],
and collaborations [Gold et al., 2019] are already existing, and their use
should be promoted by governments and funding agencies, as well as integrated in
the training of ECRs by academic institutions.
%
Organizations and/or regulators in charge of overviewing the open scholarly
system need to be established [cf. Nicholas et al., 2019, 2020]''
\citep{toribio2021early}.


\paragraph{Education}

\todo[inline]{Breed open science enthusiast in (under)graduate curriculi}

%
``It is necessity to promote further training on the benefits and risks of OS
practices [cf. Schönbrodt, 2019].
%
Promoting training would not only increase the knowledge of ECRs about specific
OS practices but also could foster its implementation among ECRs.
%
It would be highly beneficial to introduce these training schemes in the
curriculum of undergraduates programs.
%
Courses should cover the benefits and risks of OS practices, together with a
guideline on how to implement them [cf. Farnham et al., 2017]''
\citep{toribio2021early}.


\paragraph{Carrots...}

\todo[inline]{Start with incentives to foster self-learning and applying the
principles "voluntarily"}

%
More incentives to conduct open science project needs to be established.
%
``Extra efforts may not be valued appropriately by a scientific community who
assesses research based on journal impact metrics and number of publications
[Moher et al., 2018]'' \citep{toribio2021early}.
%
``Individual incentives for researchers should be introduced through, for
example, professional recognition or the allocation of extra funding [Kidwell et
al., 2016; Fecher et al., 2015; Ali-Khan et al., 2018].


\paragraph{...and sticks}

\todo[inline]{later, convince the remaining insurgents by force}
%
``Funding agencies already require publication of findings in OA
schemes and data-sharing plans [Neylon, 2017]'' \citep{toribio2021early}.
%
``Compulsory requirements from funders, which might only lead researchers to
show minimal compliance [Neylon, 2017]'' \citep{toribio2021early}.




\section{Naturalistic stimuli as functional localizer?}

\todo[inline]{cf. 1.3 \& 1.3.5}

\todo[inline]{this is more about the general aims}


\subsection{Intro: localizer is standard, but problematic}

\todo[inline]{it is reliable, but construct?}

\todo[inline]{ecologically validity?}

\todo[inline]{boring, compliance, inefficient}

\todo[inline]{Therefor: naturalistic stimulus}


\subsection{Evaluation in two ways: direct modeling \& estimation}

\todo[inline]{maybe, cite \citet{bartels2004mapping}, and a study that did GLM +
naturalistic speech paradigm}





\subsection{Results: direct modeling works moderately}

\todo[inline]{literature says it is impossible (but Alexander Hut!). But: how
"prohibitive" is it? How naive was it to do it? What did take the most time?}

\todo[inline]{yes, you can analyze data from naturalistic stimuli based on
stimulus annotation despite people saying it is not possible}


\subsubsection{Speech Anno}


% what we did in 1 sentence
In \citep{haeusler2021speechanno}, we created and validated an annotation of
speech occurring in the movie and its audio-description.
% validation analysis
We validated the annotation's quality \citep{haeusler2021speechanno} and
performed a canonical \ac{glm} analysis by contrasting regressors correlating
with speech-related events to a regressor correlating with events without
speech.
% results
As hypothesized, results revealed statistically significant increased
hemodynamic activity in a bilateral cortical network known to be involved in the
perception of speech \citep[e.g.,][]{friederici2011brain, wilson2008beyond}.

% conclusion
These results (group-level) encouraged us to a) use the annotation as the
groundwork for \citep{haeusler2022processing}, b) publish the annotation as an
extension of the studyforrest project.


\subsubsection{PPA paper}

\todo[inline]{cf. \citep{haeusler2022processing}'s discussion regarding
neuroscout / modeling and the new, corresponding paper
\citep{delavega2022neuroscout}}

\todo[inline]{mih: worth stating again somewhere in the discussion that the
studyforrest dataset is not for this (diverse), but it is a small dataset, which
limits the generality}


% study in one sentence
The goal \citep{haeusler2022processing} was to explore whether an
audio-visual and an exclusively auditory naturalistic stimulus could be used in
order to localize the \ac{ppa} as it was previously identified in the same set
of participants by a traditional block-design functional localizer that employed
static pictures \citep{sengupta2016extension}.



\paragraph{Method}

% method
We took advantage of three fMRI acquisitions and two stimulus annotations that
are part of the open-data resource
\href{http://www.studyforrest.org}{studyforrest.org} to operationalize the
perception of spatial information embedded in an audio-visual movie and an
auditory narrative, and compare current results to a previous report of a
conventional, block-design localizer.


% AV operationalization
For the model-based mass-univariate statistical analysis (i.e.\ac{glm}) of the
movie's data, we operationalized the perception of visual spatial information
based on an annotation of movie cuts and depicted locations
\citep{haeusler2016cutanno}.
% AD operationalization
For the \ac{glm} of the audio-description's data, we extended the annotation of
speech \citep{haeusler2021speechanno} by further annotating nouns that the
narrator uses to describe the movie's absent visual content.


\paragraph{Results (generally)}

% group results: AV \& AD
On a group-average level, findings demonstrate that increased activation in the
\ac{ppa} generalizes to the perception of spatial information embedded in the
audio-visual movie and the audio-description.
% individual AD
On an individual level, semantic spatial information occurring in the
audio-description is correlated with significant activity in the anterior part
of the \ac{ppa} bilaterally in nine individuals and unilaterally in one
individual.

% results
``The present study offers evidence that a model-driven GLM analysis based on
annotations can be applied to a naturalistic paradigm to localize concise
functional areas and networks correlating with specific perceptual processes --
an analysis approach that can be facilitated by the neuroscout.org platform
\citep{delavega2021neuroscout}.
% interpretation
More specifically, our results demonstrate that increased activation in the PPA
during the perception of static pictures generalizes to the perception of
spatial information embedded in a movie and an exclusively auditory stimulus
\citep{haeusler2022processing}.

% conclusion 1
Results add evidence \citep[cf.][]{bartels2004mapping} that a functionally
defined region, such as the \ac{ppa}, can be localized using a model-driven
analysis that is based on a naturalistic stimulus' annotated temporal structure.


\paragraph{Results: Pro naturalistic localizer}


% localizer data
\citet{sengupta2016extension} successfully delineated the left-hemispheric
\ac{ppa} in 12 of 14 subjects and right-hemispheric \ac{ppa} in 14 of 14
subjects based on localizer data.
%
The primary movie contrast in \citet{haeusler2022processing} ``yielded bilateral
clusters in five participants, a unilateral right cluster in six participants
(of which one participant yielded a unilateral cluster in the visual localizer),
and a unilateral left cluster in one participant.
%
We find bilateral clusters for participant sub-20, whereas the block-design
localizer yielded only one cluster in the right hemisphere''
\citep{haeusler2022processing} (= i.e. 5 + 1 left-hemispheric, 5 + 6
right-hemispheric).
%
The primary audio-description contrast in \citet{haeusler2022processing}
``yielded bilateral clusters in nine participants that are within or overlapping
with the block-design localizer results.
%
In participant sub-04, two bilateral clusters are apparent, whereas block-design
localizer, and movie stimulus yielded only one cluster in the right hemisphere.
%
For another participant (sub-09) the analysis yielded one cluster in the
left-hemispheric PPA'' \citep{haeusler2022processing}; i.e. 9 + 1
left-hemispheric, 9 right-hemispheric.


% conclusion 2
Further, results suggest that a purely auditory naturalistic stimulus like an
audio-description could potentially substitute a visual localizer as a
diagnostic procedure to assess brain functions in visually impaired individuals.






\paragraph{Results: Contra naturalistic localizer}

\todo[inline]{Annotation \& modeling}

\todo[inline]{length, events, sampling}

``consistent with previous reports showing significant differences between
topographies estimated by static and dynamic localizers, especially in superior
temporal and frontal cortices (Fox et al., 2009; Pitcher et al., 2011)''
\citep{jiahui2022cross}.

%
Assumptions of the form of the HRF and modelling HRF  might be adjusted;
%
The approach is not simply transferable
%
Naturalistic stimuli are hyped, imo (a.k.a. "I want to do what I did before
using controlled experiments but simply using naturalistic stimuli").




\paragraph{Example: Reliability of audio-description as localizer}

\todo[inline]{sample more events in less time (fatigue), improve modeling,
control for alertness}


% statement
On an individual-level, we observed higher intersubject variability of responses
of the \ac{ppa} to a naturalistic auditory stimulation compared to the
audio-visual movie and visual localizer paradigms \citep[cf. Table 3
in][]{sengupta2016extension}.
% not necessarily noise
Our naturalistic auditory paradigm differs from block-design localizer paradigms
not just in the exclusively auditory stimulation but also in the accidental,
event-like presentation of spatial information, and the absence of a task which
leaves study participant naive to the investigated cognitive process.

%
Reliability could be influenced by uncontrolled situational factors like the
experimental design (stimulus type, no task), (transient) state of a participant
(e.g., alertness or engagement),  our simply our ``adventurous'' modeling
approach[?].


\paragraph{Auditory response might be too different, too}

%
``The presented evidence on the in-principle suitability of a naturally
engaging, purely auditory paradigm for localizing the PPA may offer a path to
the development of diagnostic procedures more suitable for individuals with
visual impairments or conditions like nystagmus''
\citep{haeusler2022processing}.


% conclusion 2
Further, results suggest that a purely auditory naturalistic stimulus like an
audio-description could potentially substitute a visual localizer as a
diagnostic procedure to assess brain functions in visually impaired individuals.

% our interpretation
Previous studies in the field of visual perception suggest that the \ac{ppa} can
be divided into functionally subregions that might process different stimulus
features.

%
Present results revealed that increased hemodynamic activity during auditory
stimulation is spatially restricted to the anterior \ac{ppa}.
% interpretation: aPPA vs. pPPA
Our results provide further evidence that the PPA can be divided into functional
subregions that coactivate during the perception of visual scenes.

%
We attributed the revealed pattern to different features inherent in the visual
stimuli compared to features inherent in the naturalistic auditory stimulus
[phrasing pretty similar to \citep{haeusler2022processing}].
%
However, our interpretation of the observed pattern ``can only be preliminary,
because the auditory stimulation dataset differs in key acquisition properties
(field-strength, resolution) from the datasets of the movie and visual localizer
representing a confound of undetermined impact'' [still pretty similar to
phrasing in \citep{haeusler2022processing}].

%
Our results invite further studies that investigate the properties of the
parahippocampal area in response to to a controlled paradigm (with or without
any task) investigating generalizability of findings to, well, controlled
paradigms.


\subsection{However, for now, better stick to localizer}

\todo[inline]{What does the PPA actually do? What is the psychological
construct?}

\todo[inline]{Even if the construct is "watching pics of landscapes" or "pics
with similar low-level features of landscapes"}

%
The localizer is the established method to identify the \ac{ppa}.
% usually, visual PPA works pretty well
It's a reliable methods that yields bilateral clusters of increased hemodynamic
activity in most subjects.
%
However, ``the PPA definition may depend on the type of experiment, task, and
stimuli used'' \citep{weiner2018defining}.


\todo[inline]{There might be dynamic localizers}
%
``We found more reliable estimates using the dynamic localizer than the static
localizer, consistent with previous reports on the increased power of dynamic
localizers [Fox et al., 2009; Pitcher et al., 2011]
\citep{jiahui2020predicting}.

%
``The dynamic localizer used short video clips for each category.
%
For all categories, the dynamic localizer elicited stronger and broader
category-selective activations than the static localizer, and the searchlight
analysis showed that the dynamic localizer had higher reliabilities across the
cortex, especially in regions that were selectively responsive to the target
category.
%
For example, for the face-selective topographies, the dynamic localizer
activated more areas than the static localizer (e.g., in superior temporal and
frontal cortices).
%
In the ventral temporal cortex, especially in the right hemisphere, both dynamic
and static localizers performed well in the cross-localizer-type predictions.
%
The low correlations were not because the prediction method failed but reflected
the difference in the topographies activated by different types of localizers.''
\citep{jiahui2022cross}.


\todo[inline]{But there is no localizer based on naturalistic stimuli for a
reason?}

Notably, 20 years after group-level findings of \citep{bartels2004mapping} there
might be "dynamic localizers" using video snippets
\citep{pitcher2011differential, fox2009defining} but, to my knowledge, no
localizers based on naturalistic stimuli!



\subsubsection{Transition to estimation}

%
However, we should have sampled response vector(s) that carry the spatial
response information (if you know what I mean).



\subsection{Results: estimation works amazingly}

\todo[inline]{cf. discussion of SRM part (when that version is final)}

\subsubsection{Goal of SRM study}
% goal 1: new procedure
We estimated results of a dedicated localizer \citep{sengupta2016extension} via
functional alignment from results of a reference group.


% the problem
Considering practical and monetary constraints in a clinical context, a paradigm
lasting 90 to 120 minutes is inappropriate for even an extensive individual
diagnostic procedure, we also assessed the relationship between length of
naturalistic stimulation used to align the test participant to the fixed
\ac{cfs} and the estimation performance.



\subsection{Vision: calibration scan + database}

\todo[inline]{This topic is only touched in the SRM study's discussion}


% examples of probabilistic atlasses: \citet{rosenke2021probabilistic}:
% Cortical atlases have been developed, which allow localization of visual areas
% ``in new subjects by leveraging ROI data from an independent set of typical
% participants: Frost and Goebel 2012;
% ventral temporal cortex (VTC) category selectivity: Julian et al. 2012,
% Zhen et al. 2017, Weiner et al. 2018; visual field maps: Benson et al. 2012,
% Benson and Winawer 2018; Wang et al. 2015''.


\subsubsection{Problem space}

``Identifying all of the currently known topographic regions of the human visual
system requires multiple scanning sessions'' \citep{wang2015probabilistic}.
%
``Given the expense and availability of fMRI, this is not always practical''
\citep{wang2015probabilistic}.
%
``For example, time-limitations and subject-fatigue both potentially limit the
time researchers may be able to spend with patients suffering from neurological
or neuropsychological disorders'' \citep{wang2015probabilistic}.
%
The database ``may prove especially useful for predicting functional patterns in
case no localizer data are available, saving scanning time and expenses''
\citep{rosenke2021probabilistic}


\subsubsection{Database}
%
The reference group requires a ``database of data for movies and a range of
functional localizers in a normative group of subjects''
\citep{jiahui2020predicting}.
%
``A database from a normative group could allow researchers to estimate new
subjects' functional topographies with by collecting only a movie-viewing data
set and then deriving the individualized topographies with the normative
database'' \citep{jiahui2020predicting}.

%
``Our approach has the potential to estimate an unlimited variety of functional
topographies at the individual level based on the responses to a single
naturalistic, dynamic stimulus.
%
A normative database of participants who were scanned during movie viewing and
during functional localizers for different perceptual and cognitive functions
would serve as a reference and allow projecting the data from the normative
sample into new brains' cortical anatomies'' \citep{jiahui2020predicting}.

%
``There are numerous other functional localizers in other perceptual and
cognitive domains, such as simple visual motion, biological motion, tonotopy,
voice perception, music perception, language, calculations, working memory, and
theory of mind.
%
Because naturalistic movies include people, human actions, conversations, social
interactions, background music etc., we predict that hyperalignment
transformation matrices based on these movies also will work for localizers of
functional topographies for audition, language, and social cognition''
\citep{jiahui2020predicting}.


\subsubsection{Calibration}
%
A naturalistic stimulus like a move or audio-description could be used to align
a test subject to a \ac{cfs} created from data of a normative reference group.
%
Naturalistic stimuli ``engage in parallel multiple neural systems for vision,
audition, language, person perception, social cognition, and other functions''
\citep{jiahui2020predicting} and offer higher generalizability [and provide
higher validity?] of transformations matrices.

%
``From a single movie dataset multiple functional topographies can be estimated
\citep{guntupalli2016model}, whereas different localizers are typically required
to map different functional topographies, making a thorough mapping of selective
topographies time-consuming and inefficient'' \citep{jiahui2020predicting}.
%
``Investigators would need to scan their participants only during movie viewing
and a wide range of idiosyncratic functional topographies could then be
estimated individually based on localizer data projected from the brains in the
normative sample into the new participants' cortical anatomies''
\citep{jiahui2020predicting}.



\subsubsection{Application: estimation}
%
Once a valid alignment is established, known functional properties of the
(normative) reference can then be projected into the respective individual voxel
space (s. Fig. 1 in \citep{nishimoto2016lining}) by mapping a variety $Z$-maps
created from a variety of $t$-contrast from a normative reference group onto an
individual subjects and thus potentially substitute a variety of localizers.

%
``Functional topographies could be mapped from a database containing a wide
range of perceptual and cognitive functions to new subjects based only on fMRI
data collected while watching an engaging, naturalistic stimulus and other
subjects' localizer data from a normative sample'' \citep{jiahui2020predicting}.
%
``A new subject's functional topographies could be estimated based only on that
subject's movie data and other subjects' localizer data from the normative
database that could be projected into that subject's cortical anatomy using
hyperalignment transformation matrices derived from movie data and could replace
tedious functional localizers with an engaging movie''
\citep{jiahui2020predicting}.




\subsubsection{Application: deviation}

\todo[inline]{cf. SRM discussion: quantify the deviation from the norm vs.
predict deviant pattern?}

%
That reference would enable an qualitative and quantitative description of an
individual's brain function with respect to such a norm, and consequently
progress the field towards neuroimaging studies of individual differences that
more closely resemble their psychological counterparts.


\subsubsection{Clinical application[?]}


\todo[inline]{cf. general introduction}

\todo[inline]{Merge into "Application: estimation" \& "Application: deviation"}

\todo[inline]{\citet{silva2018challenges, szaflarski2017practice}}


``In the clinical context, fMRI plays an important role for planning surgery in
patients with tumors or epilepsies, as it aids the understanding of which parts
of the brain need to be spared in order to preserve sensory, motor or cognitive
abilities'' \citep{wegrzyn2018thought}.


\paragraph{Language lateralization}

\todo[inline]{I abandoned the idea to come up with language area (asymmetry);
the topic is clinically more relevant, but problem in case of prediction (esp.
using ROI): most interesting is atypical language lateralization, and there is
usually no lateralization in naturalistic stimuli (but operationalization is
different from localizer paradigms), assumption of (strict) lateralization
probably wrong anyway; templates from papers using \ac{fmri} to localize
language areas are outsourced to separate file}

%
For example \ac{fmri} could be used as an noninvasive alternative to map
language areas and potentially assess lateralization (or hemispheric asymmetry)
of functional brain topography related to language (sub)functions, in order to
guide pre- and perioperative assessment of neurosurgery, e.g., in case of
epilepsy.






\section{Naturalistic stimuli are no panacea!}

%
Naturalistic stimuli are not a panacea but traditional paradigms and
naturalistic paradigms should be used in tandem / reciprocally to generate new
hypotheses and progress our understanding of the brain.



\subsection{Practical stuff}

\todo[inline]{Does an auditory naturalistic stimulus give too much room to
participants to do not give a shit? a.k.a. freely listening is bad? In
hindsight: it was a very stupid idea to do it}

\todo[inline]{it's not about length (hihi) but more about what is happening
(here: spatial events)}

``Natural stimuli like movies \citep{eickhoff2020towards,
hasson2008neurocinematics, sonkusare2019naturalistic} or narratives
\citep{hamilton2018revolution, honey2012not, lerner2011topographic,
silbert2014coupled, wilson2008beyond} can be used as a continuous, complex,
immersive, task-free paradigm that more closely resembles our natural dynamic
environment than traditional experimental paradigms''
\citep{haeusler2022processing}.

%
``Because naturalistic movies include people, human actions, conversations,
social interactions, background music etc., we predict that hyperalignment
transformation matrices based on these movies also will work for localizers of
functional topographies for audition, language, and social cognition''
\citep{jiahui2020predicting}
%
Some high-level cognitive processes, such as calculation, working memory, and
logical reasoning, may be less well sampled by movie viewing, and further work
is necessary to test whether hyperalignment based on movie-viewing data can be
used to estimate topographies for these other domains of high-level cognition.
'' \citep{jiahui2020predicting}.


%
Just an approximation of real life.
%
Setting is still the scanner.
%
Passive watching \& listening.



\subsection{Methodological stuff}

\todo[inline]{model-driven analyses are possible; but no simple mapping of
methods from controlled paradigms to naturalistic stimuli}



\subsection{Future studies}
%
Challenging data data analysis, but create \& share annotation.

%
Audio-description lacks visual stimulation; Sampling of "executive functions"
during movie/audio-description;
%
additionally, audio-description lacks visual stimulation

%
''Extending this approach to other populations, such as children, or other
cultural groups will present further challenges for selecting appropriate movies
and developing databases that allow adjustment for factors such as age''
\citep{jiahui2020predicting}.




\section{Conclusion}

%
In summary, naturalistic stimuli ``impose a meaningful timecourse across
subjects while still allowing for individual variation in brain activity and
behavioral responses, and lend themselves to a broader set of analyses than
either pure rest or pure event-related task designs'' \citep{finn2017can}.
%
``Naturalistic paradigms do not aim to replace the classic, controlled
neuroimaging paradigms (Sonkusare et al., 2019). Due to their complexity and
current limitations in understanding the statistical properties of different
features in naturalistic conditions, naturalistic stimuli are not optimal for
model development [see, e.g., Rust and Movshon, 2005]. Controlled experiments
are still needed for hypothesis testing and developing models, while
naturalistic stimuli are best employed to test models in ecologically valid
settings and to expand them to situations where context matters
more'' \citep{saarimaki2021naturalistic}.




\section{Some backups}


\subsection{Group-level vs individual-level analyses}

Backup of quotes for general discussion (or SRM study).  Studies that average
data across study participants may draw

\begin{itemize}

\item ``provide only an approximate view of any individual's brain organization,
    potentially obscuring meaningful individual differences in cortical
        organization'' \citep{laumann2015functional},

\item may just ``capture the common denominator of each individual cognitive
    circuit and lose a large amount of information''

\item ``obscure(s) patterns of brain organization specific to each individual''
    \citep{laumann2015functional}.

\end{itemize}


\subsection{Brain \& behavior: "fingerprints"}

\todo[inline]{reliability of differences is premise for "fingerprints"}
%
Maybe might be stable individual differences in cognitive tendencies or
cognitive abilities like susceptibility / predisposition [?] to attend to, [or]
recognize [or process] auditory spatial information.
% kanai
In case the pattern is stable within individual subjects / is ``highly
consistent across different sessions [or experiments], then they are
characteristics of the individuals and may reflect differences in their brain
function'' \citep{kanai2011structural} [on structural diffences].
%
``Individual differences in topology (i.e. location, size, shape of functional
areas) and the activity within functional areas can also be considered to be
interesting cases of inter-individual variability to understand the neural basis
of human cognition and behavior, brain-phenotype relationships'', and ``present
useful phenotypes or biomarkers \citep{glasser2016multi,
vanhorn2008individual}''


\subsubsection{Brain \& behavior: example studies}

\todo[inline]{shorten heavily or drop altogether}

\todo[inline]{cf. also \citep{gordon2017individual, gordon2017precision}}
%
For example, \citet{kong2019spatial} suggested based on resting-state functional
connectivity measures ``that individual-specific network topography (i.e.,
location and spatial arrangement) might serve as a fingerprint of human behavior
that can predict behavioral phenotypes across cognition, personality, and
emotion'' \citep{kong2019spatial} [with modest accuary, comparable to previous
reports predicting phenotypes based on connectivity strength].

%
\citep{bijsterbosch2018relationship}'s ``results indicate that spatial variation
in the topography of functional regions across individuals is strongly
associated with behaviour'' \citep{bijsterbosch2018relationship}.
%
\citet{bijsterbosch2018relationship} found ``that the spatial arrangement of
functional regions is strongly predictive of non-imaging measures of behavior
and lifestyle'' [however shape \& exact location of brain regions interacted
strongly with  modeling of brain connectivity].
%
\citet{bijsterbosch2018relationship} found ``that individual differences in the
size, shape and exact position of the brain regions [as identified by
resting-state functional connectivity measures] was strongly linked to
individual differences in behavioral tests and questionnaires [including
intelligence, life satisfaction, drug use and aggression problems]''
\citep{bijsterbosch2018relationship}.

%
``The variations in spatial topographical features captured a more direct and
unique representation of subject variability than temporal correlations between
regions defined by group parcellation approaches (coupling).
%
Hence, the cross-subject information represented in commonly adopted
'connectivity fingerprints' could largely reflect spatial variability in the
location of functional regions across individuals, rather than variability in
coupling strength (at least for methods that directly map group-level
parcellations onto individual data)'' \citep{bijsterbosch2018relationship}.

\todo[inline]{drop following paragraph; just here to better understand paragraph
above}
%
``Depending on the employed spatial alignment algorithm and the amount of
removed spatial intersubject variability, the degree to which spatial
information may influence FC estimates possibly varies considerably across
studies.
%
In recent years, significant efforts have gone into the methods that more
accurately estimate the spatial location of functional parcels in individual
subjects [Chong et al., 2017; Glasser et al., 2016; Gordon et al., 2016; Hacker
et al., 2013; Harrison et al., 2015; Varoquaux et al., 2011; Wang et al., 2015],
and into advanced hyperalignment approaches [Chen et al., 2015; Guntupalli et
al., 2016; Guntupalli and Haxby, 2017]'' \citep{bijsterbosch2018relationship}.
