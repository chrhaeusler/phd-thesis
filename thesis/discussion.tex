\todo[inline]{it doesn't matter where I place the part on "open science": it's
an excursion \& doesn't fit in anywhere perfectly; at the moment it comes
before going into details about naturalistic stimuli as localizer}

\section{Overview}

\todo[inline]{an overview over the structure of the discussion that is supposed
to prime its topics}

\todo[inline]{delete subsection(s), so 6.1. will be "Open Science"}


Human brain mapping studies have traditionally averaged \ac{fmri} data across
participants.
%
However, data need to be assessed on the level of individual persons in order to
advance the field towards a clinical application.
% functional localizer
An established method to characterize the topography (i.e. the location, size,
and shape) of functional areas on the level of individuals are functional
localizers.
% contra localizers
However, traditional localizer paradigms employ selectively sampled, tightly
controlled stimuli, rely heavily on a participant's compliance, and can usually
map just one domain of brain functions.


\subsection{The usual rant about localizers here}

\todo[inline]{imo, it makes sense to shortly repeat the usual stuff here}

\todo[inline]{cf. general intro \& SRM part (localizer is standard, but
problematic; it's reliable, but what is the construct? ecologically validity?
boring, compliance, inefficient; therefor, naturalistic stimulus)}



\subsection{Naturalistic stimuli as functional localizer?}

\todo[inline]{prime here that annotations are bottleneck and modeling
is "prohibitively" difficult? imo, it's not necessary}

% movies & narratives
Naturalistic stimuli like movies and auditory narratives \citep[cf.][for
reviews]{jaaskelainen2021movies, jaaskelainen2020neural} provide a time-locked
event structure that samples a broad range of brain states ranging from
low-level perception (e.g., luminance) to high-level cognition (e.g., social
cognition)
%
A localizer based on naturalistic stimuli could
%
a) provide higher external validity because they resemble how we perceive the
real world outside of the laboratory during everyday life more close and,
%
b) potentially map a variety of brain functions.

% goal of thesis
Therefore, the goal of this thesis was---while following the principles of open,
transparent, and reproducible science---to explore whether a movie and the
movie's audio-description could, in principle, substitute a traditional
localizer paradigm.
% PPA as proof of concept
As a proof of concept, we focused on the \ac{ppa}, a ``classic'' higher visual
area.
%
The \ac{ppa} exhibits increased hemodynamic activity when participants view
photos of landscapes, buildings or landmarks, compared to, e.g., photos of faces
or tools \citep[e.g.,][for reviews]{epstein2014neural, aminoff2013role}.
%
Moreover, results of \citep{aziz2008modulation} that compared hemodynamic
activity levels in the \ac{ppa} correlated with different categories
presented in spoken sentences suggest that activity level of the  \ac{ppa}
are modulated by semantic scene-related information.
%
The movie's and audio-description's potential to substitute a
visual localizer were assessed in two ways.


\subsubsection{First approach: \ac{glm} $t$-contrasts}

\todo[inline]{prime here that annotations are bottleneck and modeling is
"prohibitively" difficult? imo, it's not necessary}

% similarity
Similarly to traditional localizers, we model hemodynamic responses correlating
with the temporal structure the paradigm in order to create \ac{glm}
$t$-contrasts that aimed at localizing the \ac{ppa}.
%
Differently localizer paradigms that employ blocks of stimuli, we created
\ac{glm} $t$-contrasts based on modeled hemodynamic responses correlating
annotated stimulus features embedded in the movie \citep{haeusler2016cutanno}
and audio-description \citep{haeusler2021speechanno}.


\subsubsection{Second approach: estimation from ref}

\todo[inline]{when SRM study is written, revise general intro \& here
accordingly}

%
In order to address the practical and monetary constraints of a clinical
context, we estimate localizer results of participants from results of
participants in a \textit{reference group}.
%
This is based on a super awesome functional alignment using naturalistic fMRI
data (to create the common functional space and align a left-out subject).



\subsubsection{Transition to open Science}

\todo[inline]{if the overview above stays short, imo, not explicit transition
necessary}



\section{Open Science}

\todo[inline]{phrase more in terms of (sub)goals not about "affected stages";
adjust general intro accordingly}

\todo[inline]{where definition is necessary, check if intro concisely defines it
(e.g., "open-source", "open data", "open science", "open access")}


On a metalevel, this dissertation aimed to meet both the requirements of open,
shared, accessible, and transparent science \citep[cf.][]{watson2015will,
fecher2014open} as well as the requirements of a reproducible and replicable
research project.
%
Two (sub)goals:

\begin{itemize}
    \item Utilize open data, open materials, and open-source software,
    \item Publishing open data, open materials, and open-access manuscripts
\end{itemize}


The publications that describe generated data, the reasoning of methodological
choices, analysis steps, and results of this thesis have been published in
open-access journal.
%
Unthresholded statistical maps are available at Neurovault
(\href{https://neurovault.org/}{\url{neurovault.org}}).



\subsection{Utilize open data, open materials, and open-source software}

%
First goal was to use open data and open-source software.

\paragraph{Example: Open data \& open source}

The current thesis capitalized on publicly and freely available
%
\ac{fmri} data \citep{hanke2014audiomovie, hanke2016simultaneous,
sengupta2016extension},
%
subject-specific \acp{roi} \citep{sengupta2016extension} and
%
stimulus annotations \citep{haeusler2016cutanno}
%
that are part of the \textit{studyforrest} project
(\href{www.studyforrest.org}{\url{studyforrest.org}}).
%
In order to avoid creating an ``artificial paywall'' for rerunning the analyses
on open data, all analyses are implemented in open-source software
packages\todo{FSL is not OS?}.

We benefited from established free software like
%
Python and
%
FSL \citep[\href{https://www.fmrib.ox.ac.uk/fsl}{FMRIB's Software
Library;}][]{smith2004fsl} that have been developed and debugged over years by
an collaborative effort,
%
but also from scientific software packages that emerged during current years
like
%
DataLad
\citep[\href{www.datalad.org}{\url{datalad.org}};][]{halchenko2021datalad} or
%
BrainIAK
\citep[\href{https://brainiak.org}{\url{brainiak.org}};][]{kumar2020brainiak,
kumar2020brainiaktutorial}.


\paragraph{Pro \& Con.}

Preexisting software packages, data, and results from previous analyses enabled
us shift time and resources from software development and data collection to
subsequent stages of the project.\todo{what else?}
%
However, a too often neglected aspect of open data is that open data does not
exempt from the duty to familiarize yourself with the data.\todo{Jeez! OK!}
% check the data
Dataset consumers need to assume that everything that is not explicitly
stated in the description of a dataset has not been considered by a dataset's
creators.
% laugh with many, don't trust any
Even if the data a from a renowned source, researchers should consider
themselves to be obliged to test and validate a dataset's quality according to
their standards and specific use cases.
%
Standards (quality, formats, parameters) and open sciences practices (e.g.,
documenting) might vary across scientific field, or within scientific fields
depending on a working group's knowledge and rigor.
%
Choices made during data collection and preprocessing -- despite being
state-of-the-art at the time of being published -- might not be optimal for
every use case or made obsolete by more advanced methods.


\paragraph{Example 3: ROIs}
%
Moreover, the extent of raw data and decisions made during data collection,
preprocessing, and further analyses might influence the subsequently performed
analyses.
%
For example, we and \citet{sengupta2016extension} chose the \ac{ppa} among
possible candidates of ``scene-selective'' regions because it was the first area
to be discovered and is the most reliably activated region across
studies that investigate visual scene perception.
%
Like the \ac{ppa}, the \ac{rsc} and \ac{opa} have repeatedly shown
increased hemodynamic activity in studies investigating visual spatial
perception and navigation \citep{chrastil2018heterogeneity, bettencourt2013role,
dilks2013occipital, epstein2019scene}.
%
We assumed that results (at least of the audio-visual stimulus) could also
yield significant clusters in the \ac{rsc} and \ac{opa} but did not explicitly
hypothesize that fact.
%
Apart from the PPA, results show significantly increased activity in the
\ac{rsc} \ac{opa} and are an incentive for further studies.
% \citep[cf. algorithmic procedure in, e.g.,][]{julian2012algorithmic}.
However, in case of preexisting \acp{roi} of \citep{sengupta2016extension}, one
would have to replicate the non-automatized procedure of
\citep{sengupta2016extension}.
%
A point that also highlights that some stages or results may rely on human
decisions that cannot be replicated complicating updating or the extension of
datasets.\todo{daddy, chill!}


\paragraph{Pro \& Con: Opportunity costs}

% tell me about opportunity costs without saying opportunity costs
Hence, when considering using open data, researchers need to weigh the costs and
benefits of one path (e.g., preprocessing the same data differently than the
preprocessing performed as part of an open dataset) relative to an alternative
path (e.g., using the preprocessed data and performing new analyses), and choose
the path with the greater net return.



\subsection{Publishing open data, open materials, and open-access manuscripts}
%
%The annotation comprises, e.g., time-stamps of phonemes, words and sentences of
%all speakers, a grammatical tagging, and an annotation of syntactic
%dependencies and semantics.

%
The second goal was to create open data and extend the studyforrest dataset.
% additional effort 1
The content of the published annotation of speech \citep{haeusler2021speechanno}
goes beyond what was necessary to perform the analyses in
\citet{haeusler2022processing}.
%
Consequently, the annotation further widen the ``annotation bottleneck''
\citep{aliko2020naturalistic} of two naturalistic stimuli, and provides a
headstart for independent research that wish to model hemodynamic brain
responses that are correlated with different aspects of spoken language.
%
In order to facilitate transparency, data and custom code are
version-controlled, and changes made to data and code were protocolled and
documented.
%
In order to facilitate reproducibility, processing steps ranging from
downloading input data to plotting figures are implemented in custom code that
can be rerun from the command line.


\subsubsection{Con}
%
Creating data, materials, and code to be published requires a considerable about
of time and effort.
%
A dataset's content needs to be collected, described, stored and published in a
manner that attracts re-use by third parties.
%
Dataset creators need to anticipate use cases, collect the data according to
best practices, convert data into a standardized format (considering, e.g.,
naming conventions, folder structure, separating raw from analyzed data), and
create metadata.
%
Analyses pipelines need to be designed and tested to automatically and
reliably rerun the history of a dataset's stages.
%
% publication: findable, accessible, interoperable, reusable
Especially when data are supposed to be published, a researcher needs consider
legal issues (e.g. intellectual property rights, use license, statement of
agreement and anonymization of participant data,), facilitate discovery by
humans and web bots (e.g., via extensive description and machine-readable
metadata), and ensure long-term curation and accessibility at an appropriate
data host.



\subsubsection{Pro}


% method sections is too short
It helps readers to gain a better understanding from documented step-by-step
workflow than the often limited coverage of a regular publication's methods
section.



%
However, creating a dataset that is supposed to be published provides immediate
benefits to the dataset's creator.
%
Documenting every step and commenting on pros and cons of alternative procedural
paths lead[s] to better understanding.
%
Version-controlling steps diminishes the risk of look-ahead bias.
%
Extensively tracking and documenting the state and development of data and code
from the start to the final results can also be considered as a form of a lab
protocol that contains structured information for writing the corresponding
scientific article.
%
In summary, creating a dataset supposed to be published supports meticulous
working methods and good scientific practices.
%
Finally, it enables independent researchers to validate current results and use
written code to replicate current findings in prospective studies.


% readers get a better understanding
``Transparent and complete reporting of all facets of a study allows a critical
reader to evaluate the work and fully understand its strengths and limitations
%
and it facilitates subsequent research efforts by other investigators, who can
exactly follow (or carefully manipulate) each aspect of a study''
\citep{nichols2017best}.




\subsubsection{Con: scooped}

\todo[inline]{maybe, shift this into personal assessment}

%
Publishing data is associated with the risk of being ``scooped''
\citep[cf.][]{laine2017afraid}, i.e. that other working groups are using the
same data for a similar research question at the same time.
%
There is the concern that someone else might ``claim priority, usually through
publishing, to a research idea or result you yourself have been working on''
\citep{laine2017afraid}.
%
This risk is aggravated in case of early career scientists that created and
curate published datasets, pre-registered studies based on open data, or have to
stick to inflexible project plans \citep[cf.][]{toribio2021early}.



\pagebreak


\subsection{Personal assessment}

\todo[inline]{how personal am I supposed to get? Telling "the story of my
thesis?"}


\subsubsection{Utilize open data, open materials, and open-source software}




\subsubsection{Publishing open data, open materials, and open-access
manuscripts}





\todo[inline]{merge the following four subsections into the two new ones}


\subsubsection{a) acquiring open data (assessing their quality, processing it)}

%
Being able to use already existing data was convenient because not dealing with
ethic committee, participants' consent, anonymization, legal issues.
%
Especially, Covid-Pandemic has impressively shown that collecting data based on
human subjects can go dormant for almost 1.5 years.
%
Luckily, the project plan could be adjusted to just rely on the studyforrest
dataset as it was then.
%
Strictly, it was not "3rd party data" for my, because I was (somewhat) involved
in the data collection process, and hence somewhat familiar with the data
(provenience, location, quality, accessibility, storage format, performed
preprocessing steps).
%
However, I cannot stress enough: know your data! Plot, test, and check for
errors.
%
Especially, assume that everything that is not mentioned has not been
considered.
%
It is too easy to switch the focus from the data collection, quality assessment,
and exploratory data analysis to "just pushing the data through the analysis
pipeline".



\subsubsection{b) providing open data (creation, description, and storage of
data)}

\todo[inline]{somehow related: Haxby's group with more brain / people power can
use the same open data for a similar topic; cf. Susannes \& Lisas "precious"; an
embargo period makes sense}


When providing data there is a trade-off that needed to be balanced between a)
doing the ``mere minimum'' and  might not be fruitful, and b) putting time and
effort in creating additional information that to provide a sound/substantial
groundwork for potential use-cases.

%
Vibrant example is the annotation of speech:
%
As in human language in general, an annotation of speech will always contain
ambiguities.
%
Any further processing step might be based on a decision that might not match
the requirement of a specific use case.
%
For example, an annotation of semantics might be based on a current state-of-the
art language model that might be superseded by future language models.
%
Therefore, the published annotation does not only comprise the final outcome but
also the raw data and documented code that can automatically be rerun step by
step to reproduce the final outcome of both the annotation and its validation
analysis, all freely accessible in a version-controlled dataset.
%
Anything that is not 100\% automatized is not 100\% reproducible, hard to
extend, sadly because automatization takes a long time for some stuff or is not
possible for some stuff.
%
It needs a shit town of time, anticipating potential use cases is fine but
gambling on somebody to give a shit about it.

%
One advantage of publishing a dataset with an assigned DOI is that it might get
re-used and cited in another study.
%
In case of a dataset creator's fear of being superseded / outrun, ``concerns can
be alleviated by delaying the sharing or using a data-sharing repository with an
embargo period'' \citep{nichols2017best}.

%
Automatization of downloading, processing \& analyzing, creating figures,
results.
%
Writing cleaner code is fine, automatization is the biggest pain, especially
when not needed to rerun stuff yourself.


\subsubsection{c) publication of data, materials and results}

\todo[inline]{mention "open paper"? speech anno paper is on github;
ppa paper is on github but not public; diss is not on github}


\todo[inline]{three open access paper are published}

%
Choosing a data hast was easy because guided / filtered by DataLad's
functionality / support.
%
Having a supervisor with knowledge of data hosts and licenses helps a lot.



\subsubsection{Summary (for all steps)}

\paragraph{DataLad (tied the room together)}
%
DataLad \citet{halchenko2021datalad} is the technical foundation that made
following the principles possible.
%
DataLad is a free and open-source software solution
that manages provenance, distribution, and version-control of code and data,
was the technical groundwork for the "actual" thesis.

%
Another goal was to provide all data and code documented, version-controlled,
automatized processing (from downloading to plotting) in order to allow the
reproducibility of current results and to facilitate the replicability of
findings on other datasets.

%
Without DataLad (still in its "infancy"? alpha, beta-stadium?) that would not
have been possible (at least is see no competitive software solution)


\paragraph{Yes, it's annoying}

%
Following the practices of open and reproducible science was not mandatory for
submitting the thesis but required additional work and time.
%
Standards to follow are not yet fully established and corresponding software
tools are still emerging / in a developmental state.

%
Since the best practices are not yet part of a graduate or PhD curriculum,
learning about the principles and standards and applying the corresponding
procedures and necessary tools was based on self-initiative and self-learning.

Data and code need to be of quality and in a state worthy to be published and
documented for other readers, analyses pipelines needed to be in a state to be
automatized, every processing step documented, saved, protocolled, and shared to
allow reproducibility of results and facilitate replicability of finding.
%
Automating recurring tasks gives yourself the possibility of reusing
certain data, code, documents, etc. in the future.

\todo[inline]{I cannot remember one clear case which made me
glad having documented, version-controlled, and automatized stuff; maybe,
materials are a little better organized or my code was a little better to grasp
after not having taken a look at it for a longer time...}


\paragraph{However...}

%
However, open-source software (the more neuro-specific the better) and open data
allowed me to go far beyond what would have been possible without open
data [kind of not true because I used "in-house data"].
%
The thesis makes me appreciate open source neuro-software as well as the data
more.

%
The extra time and effort spend on inspecting data and testing code
leads to higher confidence in one's own work and the reliability of results.
%
Lastly, I feel more confident about my work now compared to previous projects
during which I did not do it.

%
We re-used existing data as a foundation for a new investigation in
order to generate novel findings encourage further studies, and illustrate the
benefits of publicly and freely available datasets.
%
Extended studyforrest
%


\subsection{Summary: it needs to be done (for greater goods)}

%
From the perspective of reader, open access journals provides low-cost access to
information.

%
Nevertheless, open science is the best [?] way tackle the issue if
``reproducibility crisis'' or ``replication crisis''.
%
Open sciences makes researchers accountable to collect, document, process and
store data and materials according to best practices.
%
Published data and analysis pipelines allow external persons to check the data
and analyses for undiscovered errors, and replicate the results step by step.
%
Varying parameters and running different statistics on the data allows
inspection of robustness of results.
%
Benefits are increased robustness and reliability of science when all steps are
openly documented and data are openly available.

%
Multiple datasets can be combined to perform unanticipated use cases, and
extensively and openly documented results of multiple studies facilitate
performing meta-analyses to strengthen the claims of individual studies.
%
Open science promises increased efficiency (time and financial expense) of
making scientific progress, make advance, and promotes innovation.
%
Thus, open transparent science is the way to make knowledge and technologies
widely accessible, and increase reproducibility of study results and
replicability of scientific findings while increasing trust of the public into
scientific process and its results.


\paragraph{immediate benefits are small; "gambling" vs. "being smart"}

\todo[inline]{80\% of PhD students leave science anyway}

Perceived immediate benefits outweigh the required time and effort.
%
Open access publications might receive more citations than paywalled
publications [\citep{piwowar2018state}], open data might
get cited, and promote new collaborations [\citep{popkin2019data}].


``greater potential impact of a work when it may be cited not just for its
scientific findings but also when its data is reused in other works''
\citep{nichols2017best}.

However, from a career perspective, I see few if none incentives to commit to
OS:
% no incentive
``current incentives do not justify spending large amounts of time preparing
data for sharing, as institutional promotion panels or grant reviewers currently
do not adequately reward such efforts'' \citep{nichols2017best}.
%
``the weight that open science currently has for researchers' career advancement
is small'' \citep{toribio2021early}.
%
``investing additional effort in making research open (i.e., transparent and
reproducible) is unrewarded [Nicholas et al., 2017], such as conducting
replication studies that might not be considered for publication in high-impact
journals'' \citep{toribio2021early}.

%
Currently, playing be the ``old rules'' is the ``smarter way'' than gambling
getting cited when data or code get re-used, imo.


\paragraph{Therefore: guidelines \& tools: Guidelines \& tools}

\todo[inline]{Problem: standards change, software tools are in development,
change, "landscape is moving too much" still; concrete standards, tools might be
outdated quickly}

%
``OS still requires the establishment of clear guidelines for transparency and
openness of research at the international level.
%
Examples for guidelines for OA publishing [Nosek et al., 2015; Schiltz, 2018],
and collaborations [Gold et al., 2019] are already existing, and their use
should be promoted by governments and funding agencies, as well as integrated in
the training of ECRs by academic institutions.
%
Organizations and/or regulators in charge of overviewing the open scholarly
system need to be established [cf. Nicholas et al., 2019, 2020]''
\citep{toribio2021early}.


\paragraph{Education}

% incentives like ``professional recognition or the allocation of extra funding
% [Kidwell et al., 2016; Fecher et al., 2015; Ali-Khan et al., 2018];
% Funding agencies already require publication of findings in OA schemes and
% data-sharing plans [Neylon, 2017]'' \citep{toribio2021early}.

In my opinion, risk, benefits, and practices of OS should be introduced trained
in the curriculum of undergraduates programs.
%
Hands-on training would not only increase the knowledge of OS practices but
familiarize user with emerging software tools.
%
Instead of compulsory requirements from funders, which might only lead
researchers to show minimal compliance [Neylon, 2017], more incentives to
conduct open science project needs to be established.


\pagebreak



\section{Naturalistic stimuli as functional localizer?}

\todo[inline]{Following parts has to be in line with "Aims of thesis" \&
"specific aims and objectives"}


\subsection{Functional localization via modeling hemodynamic responses}




\subsubsection{Speech Anno}


% what we did in 1 sentence
In \citep{haeusler2021speechanno}, we created and validated an annotation of
speech occurring in the movie and its audio-description.
% validation analysis
% conclusion
The results of the validation encouraged us to a) use the annotation as the
groundwork for \citep{haeusler2022processing}.

\subsubsection{PPA paper}

\todo[inline]{cf. \citep{haeusler2022processing}'s discussion regarding
neuroscout / modeling and the new, corresponding paper
\citep{delavega2022neuroscout}}

\todo[inline]{mih: worth stating again somewhere in the discussion that the
studyforrest dataset is not for this (diverse), but it is a small dataset, which
limits the generality}


\paragraph{Goal}

% study in one sentence
The goal \citep{haeusler2022processing} was to explore whether an audio-visual
naturalistic stimulus and an exclusively auditory naturalistic stimulus could be
used in order to localize the \ac{ppa} as it was previously identified in the
same set of participants by a traditional block-design functional localizer that
employed static pictures \citep{sengupta2016extension}.

\paragraph{Method}

% AV operationalization
For the model-based mass-univariate statistical analysis (i.e.\ac{glm}) of the
movie's data, we operationalized the perception of visual spatial information
based on an annotation of movie cuts and depicted locations
\citep{haeusler2016cutanno}.
% AD operationalization
For the \ac{glm} of the audio-description's data, we extended the annotation of
speech \citep{haeusler2021speechanno} by further annotating nouns that the
narrator uses to describe the movie's absent visual content.


\paragraph{Results (specifically)}

\todo[inline]{same text as in general intro's ``specific objectives''}

% group results
On a group-average level, findings demonstrate that increased activation in the
\ac{ppa} during the perception of static pictures generalizes to the perception
of spatial information embedded in an audio-visual movie and exclusively
auditory naturalistic stimulus \citep{haeusler2022processing}.
% individual AD
On an individual level, the analysis of the movie yielded bilateral
clusters of increased hemodynamic activity in the \ac{ppa} of five participants
and a unilateral cluster in seven participants.
%
The analysis of the audio-description revealed bilateral clusters in nine
participants and one unilateral cluster in one participant.

% conclusion 1
Results add evidence \citep[cf.][]{bartels2004mapping} that a that functional
specialization of cortical areas is preserved during naturalistic stimulation.
%
Results also suggest that model-driven \ac{glm} analysis based on a naturalistic
stimulus' annotation could be used to localize functional areas in individual
subjects.


\paragraph{Results more in general context}

% results
``The present study offers evidence that a model-driven GLM analysis based on
annotations can be applied to a naturalistic paradigm to localize concise
functional areas and networks correlating with specific perceptual processes --
an analysis approach that can be facilitated by the neuroscout.org platform
\citep{delavega2021neuroscout}.
% interpretation
More specifically, our results demonstrate that increased activation in the PPA
during the perception of static pictures generalizes to the perception of
spatial information embedded in a movie and an exclusively auditory stimulus
\citep{haeusler2022processing}.

% conclusion 1
Results add evidence \citep[cf.][]{bartels2004mapping} that a functionally
defined region, such as the \ac{ppa}, can be localized using a model-driven
analysis that is based on a naturalistic stimulus' annotated temporal structure.


\paragraph{Results: Pro naturalistic localizer}


% localizer data
\citet{sengupta2016extension} successfully delineated the left-hemispheric
\ac{ppa} in 12 of 14 subjects and right-hemispheric \ac{ppa} in 14 of 14
subjects based on localizer data.
%
The primary movie contrast in \citet{haeusler2022processing} ``yielded bilateral
clusters in five participants, a unilateral right cluster in six participants
(of which one participant yielded a unilateral cluster in the visual localizer),
and a unilateral left cluster in one participant.
%
We find bilateral clusters for participant sub-20, whereas the block-design
localizer yielded only one cluster in the right hemisphere''
\citep{haeusler2022processing} (= i.e. 5 + 1 left-hemispheric, 5 + 6
right-hemispheric).
%
The primary audio-description contrast in \citet{haeusler2022processing}
``yielded bilateral clusters in nine participants that are within or overlapping
with the block-design localizer results.
%
In participant sub-04, two bilateral clusters are apparent, whereas block-design
localizer, and movie stimulus yielded only one cluster in the right hemisphere.
%
For another participant (sub-09) the analysis yielded one cluster in the
left-hemispheric PPA'' \citep{haeusler2022processing}; i.e. 9 + 1
left-hemispheric, 9 right-hemispheric.


% conclusion 2
Further, results suggest that a purely auditory naturalistic stimulus like an
audio-description could potentially substitute a visual localizer as a
diagnostic procedure to assess brain functions in visually impaired individuals.






\paragraph{Results: Contra naturalistic localizer}

\todo[inline]{Annotation \& modeling}

\todo[inline]{length, events, sampling}

``consistent with previous reports showing significant differences between
topographies estimated by static and dynamic localizers, especially in superior
temporal and frontal cortices (Fox et al., 2009; Pitcher et al., 2011)''
\citep{jiahui2022cross}.

%
Assumptions of the form of the HRF and modelling HRF  might be adjusted;
%
The approach is not simply transferable
%
Naturalistic stimuli are hyped, imo (a.k.a. "I want to do what I did before
using controlled experiments but simply using naturalistic stimuli").




\paragraph{Example: Reliability of audio-description as localizer}

\todo[inline]{sample more events in less time (fatigue), improve modeling,
control for alertness}


% statement
On an individual-level, we observed higher intersubject variability of responses
of the \ac{ppa} to a naturalistic auditory stimulation compared to the
audio-visual movie and visual localizer paradigms \citep[cf. Table 3
in][]{sengupta2016extension}.
% not necessarily noise
Our naturalistic auditory paradigm differs from block-design localizer paradigms
not just in the exclusively auditory stimulation but also in the accidental,
event-like presentation of spatial information, and the absence of a task which
leaves study participant naive to the investigated cognitive process.

%
Reliability could be influenced by uncontrolled situational factors like the
experimental design (stimulus type, no task), (transient) state of a participant
(e.g., alertness or engagement),  our simply our ``adventurous'' modeling
approach[?].


\paragraph{Auditory response might be too different, too}

%
``The presented evidence on the in-principle suitability of a naturally
engaging, purely auditory paradigm for localizing the PPA may offer a path to
the development of diagnostic procedures more suitable for individuals with
visual impairments or conditions like nystagmus''
\citep{haeusler2022processing}.


% conclusion 2
Further, results suggest that a purely auditory naturalistic stimulus like an
audio-description could potentially substitute a visual localizer as a
diagnostic procedure to assess brain functions in visually impaired individuals.

% our interpretation
Previous studies in the field of visual perception suggest that the \ac{ppa} can
be divided into functionally subregions that might process different stimulus
features.

%
Present results revealed that increased hemodynamic activity during auditory
stimulation is spatially restricted to the anterior \ac{ppa}.
% interpretation: aPPA vs. pPPA
Our results provide further evidence that the PPA can be divided into functional
subregions that coactivate during the perception of visual scenes.

%
We attributed the revealed pattern to different features inherent in the visual
stimuli compared to features inherent in the naturalistic auditory stimulus
[phrasing pretty similar to \citep{haeusler2022processing}].
%
However, our interpretation of the observed pattern ``can only be preliminary,
because the auditory stimulation dataset differs in key acquisition properties
(field-strength, resolution) from the datasets of the movie and visual localizer
representing a confound of undetermined impact'' [still pretty similar to
phrasing in \citep{haeusler2022processing}].

%
Our results invite further studies that investigate the properties of the
parahippocampal area in response to to a controlled paradigm (with or without
any task) investigating generalizability of findings to, well, controlled
paradigms.


\subsection{However, for now, better stick to localizer}

\todo[inline]{What does the PPA actually do? What is the psychological
construct?}

\todo[inline]{Even if the construct is "watching pics of landscapes" or "pics
with similar low-level features of landscapes"}

%
The localizer is the established method to identify the \ac{ppa}.
% usually, visual PPA works pretty well
It's a reliable methods that yields bilateral clusters of increased hemodynamic
activity in most subjects.
%
However, ``the PPA definition may depend on the type of experiment, task, and
stimuli used'' \citep{weiner2018defining}.


\todo[inline]{There might be dynamic localizers}
%
``We found more reliable estimates using the dynamic localizer than the static
localizer, consistent with previous reports on the increased power of dynamic
localizers [Fox et al., 2009; Pitcher et al., 2011]
\citep{jiahui2020predicting}.

%
``The dynamic localizer used short video clips for each category.
%
For all categories, the dynamic localizer elicited stronger and broader
category-selective activations than the static localizer, and the searchlight
analysis showed that the dynamic localizer had higher reliabilities across the
cortex, especially in regions that were selectively responsive to the target
category.
%
For example, for the face-selective topographies, the dynamic localizer
activated more areas than the static localizer (e.g., in superior temporal and
frontal cortices).
%
In the ventral temporal cortex, especially in the right hemisphere, both dynamic
and static localizers performed well in the cross-localizer-type predictions.
%
The low correlations were not because the prediction method failed but reflected
the difference in the topographies activated by different types of localizers.''
\citep{jiahui2022cross}.


\todo[inline]{But there is no localizer based on naturalistic stimuli for a
reason?}

Notably, 20 years after group-level findings of \citep{bartels2004mapping} there
might be "dynamic localizers" using video snippets
\citep{pitcher2011differential, fox2009defining} but, to my knowledge, no
localizers based on naturalistic stimuli!



\subsubsection{Transition to estimation}

%
However, we should have sampled response vector(s) that carry the spatial
response information (if you know what I mean).



\subsection{Results: estimation works amazingly}

\todo[inline]{cf. discussion of SRM part (when that version is final)}

\subsubsection{Goal of SRM study}
% goal 1: new procedure
We estimated results of a dedicated localizer \citep{sengupta2016extension} via
functional alignment from results of a reference group.


% the problem
Considering practical and monetary constraints in a clinical context, a paradigm
lasting 90 to 120 minutes is inappropriate for even an extensive individual
diagnostic procedure, we also assessed the relationship between length of
naturalistic stimulation used to align the test participant to the fixed
\ac{cfs} and the estimation performance.



\subsection{Vision: calibration scan + database}

\todo[inline]{This topic is only touched in the SRM study's discussion}


% examples of probabilistic atlasses: \citet{rosenke2021probabilistic}:
% Cortical atlases have been developed, which allow localization of visual areas
% ``in new subjects by leveraging ROI data from an independent set of typical
% participants: Frost and Goebel 2012;
% ventral temporal cortex (VTC) category selectivity: Julian et al. 2012,
% Zhen et al. 2017, Weiner et al. 2018; visual field maps: Benson et al. 2012,
% Benson and Winawer 2018; Wang et al. 2015''.


\subsubsection{Problem space}

``Identifying all of the currently known topographic regions of the human visual
system requires multiple scanning sessions'' \citep{wang2015probabilistic}.
%
``Given the expense and availability of fMRI, this is not always practical''
\citep{wang2015probabilistic}.
%
``For example, time-limitations and subject-fatigue both potentially limit the
time researchers may be able to spend with patients suffering from neurological
or neuropsychological disorders'' \citep{wang2015probabilistic}.
%
The database ``may prove especially useful for predicting functional patterns in
case no localizer data are available, saving scanning time and expenses''
\citep{rosenke2021probabilistic}


\subsubsection{Database}
%
The reference group requires a ``database of data for movies and a range of
functional localizers in a normative group of subjects''
\citep{jiahui2020predicting}.
%
``A database from a normative group could allow researchers to estimate new
subjects' functional topographies with by collecting only a movie-viewing data
set and then deriving the individualized topographies with the normative
database'' \citep{jiahui2020predicting}.

%
``Our approach has the potential to estimate an unlimited variety of functional
topographies at the individual level based on the responses to a single
naturalistic, dynamic stimulus.
%
A normative database of participants who were scanned during movie viewing and
during functional localizers for different perceptual and cognitive functions
would serve as a reference and allow projecting the data from the normative
sample into new brains' cortical anatomies'' \citep{jiahui2020predicting}.

%
``There are numerous other functional localizers in other perceptual and
cognitive domains, such as simple visual motion, biological motion, tonotopy,
voice perception, music perception, language, calculations, working memory, and
theory of mind.
%
Because naturalistic movies include people, human actions, conversations, social
interactions, background music etc., we predict that hyperalignment
transformation matrices based on these movies also will work for localizers of
functional topographies for audition, language, and social cognition''
\citep{jiahui2020predicting}.


\subsubsection{Calibration}
%
A naturalistic stimulus like a move or audio-description could be used to align
a test subject to a \ac{cfs} created from data of a normative reference group.
%
Naturalistic stimuli ``engage in parallel multiple neural systems for vision,
audition, language, person perception, social cognition, and other functions''
\citep{jiahui2020predicting} and offer higher generalizability [and provide
higher validity?] of transformations matrices.

%
``From a single movie dataset multiple functional topographies can be estimated
\citep{guntupalli2016model}, whereas different localizers are typically required
to map different functional topographies, making a thorough mapping of selective
topographies time-consuming and inefficient'' \citep{jiahui2020predicting}.
%
``Investigators would need to scan their participants only during movie viewing
and a wide range of idiosyncratic functional topographies could then be
estimated individually based on localizer data projected from the brains in the
normative sample into the new participants' cortical anatomies''
\citep{jiahui2020predicting}.



\subsubsection{Application: estimation}
%
Once a valid alignment is established, known functional properties of the
(normative) reference can then be projected into the respective individual voxel
space (s. Fig. 1 in \citep{nishimoto2016lining}) by mapping a variety $Z$-maps
created from a variety of $t$-contrast from a normative reference group onto an
individual subjects and thus potentially substitute a variety of localizers.

%
``Functional topographies could be mapped from a database containing a wide
range of perceptual and cognitive functions to new subjects based only on fMRI
data collected while watching an engaging, naturalistic stimulus and other
subjects' localizer data from a normative sample'' \citep{jiahui2020predicting}.
%
``A new subject's functional topographies could be estimated based only on that
subject's movie data and other subjects' localizer data from the normative
database that could be projected into that subject's cortical anatomy using
hyperalignment transformation matrices derived from movie data and could replace
tedious functional localizers with an engaging movie''
\citep{jiahui2020predicting}.




\subsubsection{Application: deviation}

\todo[inline]{cf. SRM discussion: quantify the deviation from the norm vs.
predict deviant pattern?}

%
That reference would enable an qualitative and quantitative description of an
individual's brain function with respect to such a norm, and consequently
progress the field towards neuroimaging studies of individual differences that
more closely resemble their psychological counterparts.


\subsubsection{Clinical application[?]}


\todo[inline]{cf. general introduction}

\todo[inline]{Merge into "Application: estimation" \& "Application: deviation"}

\todo[inline]{\citet{silva2018challenges, szaflarski2017practice}}


``In the clinical context, fMRI plays an important role for planning surgery in
patients with tumors or epilepsies, as it aids the understanding of which parts
of the brain need to be spared in order to preserve sensory, motor or cognitive
abilities'' \citep{wegrzyn2018thought}.


\paragraph{Language lateralization}

\todo[inline]{I abandoned the idea to come up with language area (asymmetry);
the topic is clinically more relevant, but problem in case of prediction (esp.
using ROI): most interesting is atypical language lateralization, and there is
usually no lateralization in naturalistic stimuli (but operationalization is
different from localizer paradigms), assumption of (strict) lateralization
probably wrong anyway; templates from papers using \ac{fmri} to localize
language areas are outsourced to separate file}

%
For example \ac{fmri} could be used as an noninvasive alternative to map
language areas and potentially assess lateralization (or hemispheric asymmetry)
of functional brain topography related to language (sub)functions, in order to
guide pre- and perioperative assessment of neurosurgery, e.g., in case of
epilepsy.






\section{Naturalistic stimuli are no panacea!}

\todo[inline]{maybe, cite \citet{bartels2004mapping}, and a study that did GLM +
naturalistic speech paradigm}

\todo[inline]{literature says it is impossible (but Alexander Hut!). But: how
"prohibitive" is it? How naive was it to do it? What did take the most time?}

\todo[inline]{yes, you can analyze data from naturalistic stimuli based on
stimulus annotation despite people saying it is not possible}

%
Naturalistic stimuli are not a panacea but traditional paradigms and
naturalistic paradigms should be used in tandem / reciprocally to generate new
hypotheses and progress our understanding of the brain.



\subsection{Practical stuff}

\todo[inline]{Does an auditory naturalistic stimulus give too much room to
participants to do not give a shit? a.k.a. freely listening is bad? In
hindsight: it was a very stupid idea to do it}

\todo[inline]{it's not about length (hihi) but more about what is happening
(here: spatial events)}

``Natural stimuli like movies \citep{eickhoff2020towards,
hasson2008neurocinematics, sonkusare2019naturalistic} or narratives
\citep{hamilton2018revolution, honey2012not, lerner2011topographic,
silbert2014coupled, wilson2008beyond} can be used as a continuous, complex,
immersive, task-free paradigm that more closely resembles our natural dynamic
environment than traditional experimental paradigms''
\citep{haeusler2022processing}.

%
``Because naturalistic movies include people, human actions, conversations,
social interactions, background music etc., we predict that hyperalignment
transformation matrices based on these movies also will work for localizers of
functional topographies for audition, language, and social cognition''
\citep{jiahui2020predicting}
%
Some high-level cognitive processes, such as calculation, working memory, and
logical reasoning, may be less well sampled by movie viewing, and further work
is necessary to test whether hyperalignment based on movie-viewing data can be
used to estimate topographies for these other domains of high-level cognition.
'' \citep{jiahui2020predicting}.


%
Just an approximation of real life.
%
Setting is still the scanner.
%
Passive watching \& listening.



\subsection{Methodological stuff}

\todo[inline]{model-driven analyses are possible; but no simple mapping of
methods from controlled paradigms to naturalistic stimuli}



\subsection{Future studies}
%
Challenging data data analysis, but create \& share annotation.

%
Audio-description lacks visual stimulation; Sampling of "executive functions"
during movie/audio-description;
%
additionally, audio-description lacks visual stimulation

%
''Extending this approach to other populations, such as children, or other
cultural groups will present further challenges for selecting appropriate movies
and developing databases that allow adjustment for factors such as age''
\citep{jiahui2020predicting}.




\section{Conclusion}

\todo[inline]{Somehow manage to combine open science and naturalistic stuff?}




%
In summary, naturalistic stimuli ``impose a meaningful timecourse across
subjects while still allowing for individual variation in brain activity and
behavioral responses, and lend themselves to a broader set of analyses than
either pure rest or pure event-related task designs'' \citep{finn2017can}.
%
``Naturalistic paradigms do not aim to replace the classic, controlled
neuroimaging paradigms (Sonkusare et al., 2019). Due to their complexity and
current limitations in understanding the statistical properties of different
features in naturalistic conditions, naturalistic stimuli are not optimal for
model development [see, e.g., Rust and Movshon, 2005]. Controlled experiments
are still needed for hypothesis testing and developing models, while
naturalistic stimuli are best employed to test models in ecologically valid
settings and to expand them to situations where context matters
more'' \citep{saarimaki2021naturalistic}.




\section{Some backups}


\subsection{Group-level vs individual-level analyses}

Backup of quotes for general discussion (or SRM study).  Studies that average
data across study participants may draw

\begin{itemize}

\item ``provide only an approximate view of any individual's brain organization,
    potentially obscuring meaningful individual differences in cortical
        organization'' \citep{laumann2015functional},

\item may just ``capture the common denominator of each individual cognitive
    circuit and lose a large amount of information''

\item ``obscure(s) patterns of brain organization specific to each individual''
    \citep{laumann2015functional}.

\end{itemize}


\subsection{Brain \& behavior: "fingerprints"}

\todo[inline]{reliability of differences is premise for "fingerprints"}
%
Maybe might be stable individual differences in cognitive tendencies or
cognitive abilities like susceptibility / predisposition [?] to attend to, [or]
recognize [or process] auditory spatial information.
% kanai
In case the pattern is stable within individual subjects / is ``highly
consistent across different sessions [or experiments], then they are
characteristics of the individuals and may reflect differences in their brain
function'' \citep{kanai2011structural} [on structural diffences].
%
``Individual differences in topology (i.e. location, size, shape of functional
areas) and the activity within functional areas can also be considered to be
interesting cases of inter-individual variability to understand the neural basis
of human cognition and behavior, brain-phenotype relationships'', and ``present
useful phenotypes or biomarkers \citep{glasser2016multi,
vanhorn2008individual}''


\subsubsection{Brain \& behavior: example studies}

\todo[inline]{shorten heavily or drop altogether}

\todo[inline]{cf. also \citep{gordon2017individual, gordon2017precision}}
%
For example, \citet{kong2019spatial} suggested based on resting-state functional
connectivity measures ``that individual-specific network topography (i.e.,
location and spatial arrangement) might serve as a fingerprint of human behavior
that can predict behavioral phenotypes across cognition, personality, and
emotion'' \citep{kong2019spatial} [with modest accuary, comparable to previous
reports predicting phenotypes based on connectivity strength].

%
\citep{bijsterbosch2018relationship}'s ``results indicate that spatial variation
in the topography of functional regions across individuals is strongly
associated with behaviour'' \citep{bijsterbosch2018relationship}.
%
\citet{bijsterbosch2018relationship} found ``that the spatial arrangement of
functional regions is strongly predictive of non-imaging measures of behavior
and lifestyle'' [however shape \& exact location of brain regions interacted
strongly with  modeling of brain connectivity].
%
\citet{bijsterbosch2018relationship} found ``that individual differences in the
size, shape and exact position of the brain regions [as identified by
resting-state functional connectivity measures] was strongly linked to
individual differences in behavioral tests and questionnaires [including
intelligence, life satisfaction, drug use and aggression problems]''
\citep{bijsterbosch2018relationship}.

%
``The variations in spatial topographical features captured a more direct and
unique representation of subject variability than temporal correlations between
regions defined by group parcellation approaches (coupling).
%
Hence, the cross-subject information represented in commonly adopted
'connectivity fingerprints' could largely reflect spatial variability in the
location of functional regions across individuals, rather than variability in
coupling strength (at least for methods that directly map group-level
parcellations onto individual data)'' \citep{bijsterbosch2018relationship}.

\todo[inline]{drop following paragraph; just here to better understand paragraph
above}
%
``Depending on the employed spatial alignment algorithm and the amount of
removed spatial intersubject variability, the degree to which spatial
information may influence FC estimates possibly varies considerably across
studies.
%
In recent years, significant efforts have gone into the methods that more
accurately estimate the spatial location of functional parcels in individual
subjects [Chong et al., 2017; Glasser et al., 2016; Gordon et al., 2016; Hacker
et al., 2013; Harrison et al., 2015; Varoquaux et al., 2011; Wang et al., 2015],
and into advanced hyperalignment approaches [Chen et al., 2015; Guntupalli et
al., 2016; Guntupalli and Haxby, 2017]'' \citep{bijsterbosch2018relationship}.
