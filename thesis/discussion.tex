\todo[inline]{most importantly: is anything missing that needs to be discussed?}

\todo[inline]{delete subsection(s)}

Human brain mapping studies have traditionally averaged \ac{fmri} data across
participants.
%
However, data need to be assessed on the level of individual persons in order to
advance the field towards a clinical application.
% functional localizer
An established method to characterize the topography (i.e. the location, size,
and shape) of functional areas on the level of individuals are functional
localizers.
% contra localizers
However, traditional localizer paradigms employ selectively sampled, tightly
controlled stimuli, rely heavily on a participant's compliance, and can usually
map just one domain of brain functions.
% movies & narratives
Naturalistic stimuli like movies and auditory narratives \citep[cf.][for
reviews]{jaaskelainen2021movies, jaaskelainen2020neural} provide a time-locked
event structure that samples a broad range of brain states ranging from
low-level perception (e.g., luminance) to high-level cognition (e.g., social
cognition).
%
A localizer based on naturalistic stimuli could
%
a) provide higher external validity because they resemble how we perceive the
real world outside of the laboratory during everyday life more close and,
%
b) potentially map a variety of brain functions.

% goal of thesis
Therefore, the goal of this thesis was---while following the principles of open,
transparent, and reproducible science---to explore whether a movie and the
movie's audio-description could, in principle, substitute a traditional
localizer paradigm.
% PPA as proof of concept
As a proof of concept, we focused on the \ac{ppa}, a ``classic'' higher visual
area.
%
The \ac{ppa} exhibits increased hemodynamic activity when participants view
photos of landscapes, buildings or landmarks, compared to, e.g., photos of faces
or tools \citep[e.g.,][for reviews]{epstein2014neural, aminoff2013role}.
%
Moreover, results of \citet{aziz2008modulation} that compared hemodynamic
activity levels in the \ac{ppa} correlated with different categories presented
in spoken sentences suggest that activity level of the \ac{ppa} is also
modulated by semantic scene-related information.
%
We assessed the potential of both the movie and the audio-description to
substitute a visual localizer two ways.
% direct modeling
First, we adapted the method used to analyze data from traditional localizer
paradigms to the analysis of data from the two naturalistic paradigms:
%
hemodynamic responses correlating with the temporal structure of annotated
stimulus features \citep[cf.][]{haeusler2016cutanno, haeusler2021speechanno}
were modeled in order to create \ac{glm} $t$-contrasts that aimed at localizing
the \ac{ppa}.
% estimation
Second, we applied functional alignment procedure as a new method in order to
estimate results from the visual localizer \citep[cf.][]{sengupta2016extension},
movie and audio-description \citep[cf.][]{haeusler2022processing} in one
participant from results of participants in a reference group.


\section{Open Science}

\todo[inline]{it doesn't matter where I place the part on "open science": it's
an excursion \& doesn't fit in anywhere perfectly}

%
An overarching goal of this dissertation was to meet both the requirements of
open, shared, accessible, and transparent science \citep[cf.][]{watson2015will,
fecher2014open} as well as the requirements of a reproducible and replicable
research project. This goal included to a) utilize open data and open-source
software, and b) publish data, materials, code, and results openly available.


\subsection{Utilizing open data and open-source software}

\todo[inline]{add: familiarize yourself not just with the data but the
experimental paradigm / stimulus, too!}

%
The first subgoal was to use open data, open materials, and open-source
software.
%
The current thesis capitalized on publicly available
%
\ac{fmri} data \citep{hanke2014audiomovie, hanke2016simultaneous,
sengupta2016extension},
%
subject-specific \acp{roi} \citep{sengupta2016extension} and
%
stimulus annotations \citep{haeusler2016cutanno}
%
that are part of the studyforrest project
(\href{www.studyforrest.org}{\url{studyforrest.org}}).
%
In order to avoid creating an ``artificial paywall'' for rerunning the analyses
on the originally open data, all analyses are implemented in open-source
software packages\todo{FSL is not OS?}.
%
We benefited from established free software like
%
Python and
%
FSL \citep[\href{https://www.fmrib.ox.ac.uk/fsl}{FMRIB's Software
Library;}][]{smith2004fsl} that have been developed and debugged over years by
an collaborative effort,
%
but also from scientific software packages like
%
DataLad
\citep[\href{www.datalad.org}{\url{datalad.org}};][]{halchenko2021datalad} or
%
BrainIAK
\citep[\href{https://brainiak.org}{\url{brainiak.org}};][]{kumar2020brainiak,
kumar2020brainiaktutorial}
%
that emerged recently.

%
Preexisting software packages, data, and results from previous analyses enabled
us shift time and resources from software development and data collection to
subsequent stages of the project.
%
Already existing data were especially helpful when the project had to be
reoriented due to the COVID-19 pandemic that severely hampered collecting
\ac{fmri} data from new subjects.
%
However, a too often neglected aspect of open data is that open data does not
exempt from the duty to familiarize yourself with the data.
% check the data
Dataset consumers need to assume that everything that is not explicitly stated
in the description of a dataset has not been considered by a dataset's creators.
%
Moreover, standards (quality, formats, parameters) and open sciences practices
(e.g., documenting) might vary across scientific field, or within scientific
fields depending on a working group's knowledge and rigor.
%
It is too easy to switch the focus from the data collection, quality assessment,
and exploratory data analysis to "just pushing the data through the analysis
pipeline".
%
In the present project, it was very advantageous to have already been involved
in the data collection and being rather familiar with the data's location,
accessibility, storage format and performed preprocessing step.
% laugh with many, don't trust any
In any case, even if the data are provided by a renowned source, researchers
that consider using third-party data should also consider themselves to be
obliged to test and validate a dataset's quality as if collected by themselves,
according to their standards and specific use case.
%
In that sense open data---despite collected to best of knowledge and
belief---could be compared to open-source software:
%
as data contain noise, errors, or artefacts, software will contain bugs but
``given enough eyeballs, all bugs are shallow'' \citep[][p.
30]{raymond1999cathedral}.




%
Moreover, the extent of raw data and decisions made during data collection,
preprocessing, and further analyses might influence or even limit subsequently
performed analyses.
%
For example, we and \citet{sengupta2016extension} chose the \ac{ppa} among
possible candidates of ``scene-selective'' regions because it was the first area
to be discovered and is the most reliably activated region across studies that
investigate visual scene perception.
%
Like the \ac{ppa}, the \ac{rsc} and \ac{opa} have repeatedly shown increased
hemodynamic activity in studies investigating visual spatial perception and
navigation \citep{chrastil2018heterogeneity, bettencourt2013role,
dilks2013occipital, epstein2019scene}.
%
We assumed that results (at least of the audio-visual stimulus) could also yield
significant clusters in the \ac{rsc} and \ac{opa} but did not explicitly
hypothesize that fact.
%
Apart from the PPA, results show significantly increased activity in the
\ac{rsc} and \ac{opa}, and are an incentive for further studies.
% \citep[cf. algorithmic procedure in, e.g.,][]{julian2012algorithmic}.
However, in case of preexisting \acp{roi} of \citep{sengupta2016extension}, one
would have to replicate the non-automatized procedure of
\citep{sengupta2016extension}.
%
This example highlights that choices made during data collection and
preprocessing---despite being state-of-the-art at the time of being
published---are influencing subsequent analyses.
% pro & contra: opportunity costs
Hence, when considering using open data, researchers need to weigh the costs and
benefits of one path (e.g., using preprocessed data as is) relative to an
alternative path (e.g., preprocessing raw data differently than provided) and
choose the path with the greater net return.
%
However, any previous step that is not fully automated but relied on any human
decision or intervention influences the degree to which data or materials can be
replicated automatically, updated, or extended.


\subsection{Publishing data, materials, code, and results openly available}

\todo[inline]{speech anno paper is on github; ppa paper is on github but not
public; thesis is not on github}

%
%The annotation comprises, e.g., time-stamps of phonemes, words and sentences of
%all speakers, a grammatical tagging, and an annotation of syntactic
%dependencies and semantics.

%
The second subgoal was to publish data, materials, and results openly
accessible.
%
In order to increase transparency, data and custom code generated over the
course of this dissertation are version-controlled, and changes made to data and
code were protocolled and documented.
%
In order to facilitate reproducibility, processing steps ranging from
downloading input data to plotting figures are implemented in custom code that
can be rerun from the command line.
%
The content of annotation of speech \citep{haeusler2021speechanno} goes beyond
what was necessary to perform the analyses in \citet{haeusler2022processing} and
serves as an extension of the studyforrest dataset.
%
Consequently, the annotation widens the ``annotation bottleneck'' \citep[][p.
16]{aliko2020naturalistic} of two naturalistic stimuli, and provides a headstart
for independent research that wish to model hemodynamic brain responses that are
correlated with different aspects of spoken language.
%
In \citet{haeusler2022processing}, we relied on open \ac{fmri} data in order to
investigate a research question that was not foreseen during the data's initial
release.
%
Results of \citet{haeusler2022processing} suggest that increased hemodynamic
activity in the \ac{ppa} generalizes from blocks of pictures to spatial
information embedded in a movie and an auditory narrative, and illustrate the
benefits of publishing and reusing open data.

% contra
From a negative perspective, creating data, materials, and code to be published
requires a considerable about of time and effort.
%
A dataset's content needs to be collected, described, stored and published in a
manner that attracts re-use by third parties.
%
Dataset creators need to anticipate use cases in order to attract re-use by
third parties, collect the data accordingly in extent and rigor, convert data
into a standardized format (considering, e.g., naming conventions, folder
structure, separating raw from analyzed data).
%
Analyses pipelines need to be designed and tested to automatically and reliably
rerun the history of a dataset's stages.
% publication: findable, accessible, interoperable, reusable
Especially when data are supposed to be published, a researcher needs consider
legal issues (e.g. intellectual property rights, use license, statement of
agreement and anonymization of participant data, anonymization), facilitate
discovery by humans and web bots (e.g., via extensive description and
machine-readable metadata), and ensure long-term curation and accessibility at
an appropriate data host.
%
From a positive perspective, creating a dataset that is supposed to be published
provides immediate benefits to the dataset's creator.
%
Documenting every step and commenting on pros and cons of alternative procedural
paths lead[s] to better understanding of the scientific field, its methods and
practices.
%
Version-controlling steps diminishes the risk of look-ahead bias.
%
Extensively tracking and documenting the state and development of data and code
from the start to the final results can also be considered as a form of a lab
protocol that contains structured information for writing the corresponding
scientific article.
%
Hence, creating a dataset supposed to be published supports meticulous working
methods and following good scientific practices in general.


\subsection{Interim summary}

\todo[inline]{this is the new "personal assessment"; how personal can I / am I
supposed to get?}

% Open access publications might receive more citations than paywalled
% publications [\citep{piwowar2018state}], open data might get cited, and
% promote new collaborations [\citep{popkin2019data}].

% incentives like ``professional recognition or the allocation of extra funding
% [Kidwell et al., 2016; Fecher et al., 2015; Ali-Khan et al., 2018];
% Funding agencies already require publication of findings in OA schemes and
% data-sharing plans [Neylon, 2017]'' \citep{toribio2021early}.

%
In summary, following the goal to conduct an open and reproducible science
project was not mandatory for submitting the thesis, and required considerably
additional work and time.
%
Since the best practices are not part of a graduate or PhD curriculum yet,
learning about the principles and standards, and applying the corresponding
procedures was based on self-initiative and self-learning.
%
Implementing the theoretical knowledge in practice was impeded by still emerging
standards and best practices, and software packages that are in early
development to implement said standards and practices \citep[e.g., DataLad's
recently added support of software
containerization;][]{wagner2022fairly}.\todo{which I didn't implement}
%
In my fucking opinion, the required time and effort heavily outweigh immediate
benefits.
%
Pursuing the ``higher goal'' of contributing to tackle the replication crisis,
or ``gambling'' on getting cited for data reuse does not justify preparing and
maintaining openly shared datasets.
%
Especially, designing and testing fully automated processing of data or
automated creation of complex figures for the perceived pure sake of
replicability is out of proportion to the immediate benefit of, e.g., easier bug
tracking or simply ``higher confidence in one's own work''.
%
The incentive to do all that stuff is especially low for those PhD students that
do not consider a career in science;
%
PhD students that pursue a career in science are faced with the concern of
making themselves vulnerable to critique due to a maximum of transparency or
simply overlooked errors.
%
Another concern is the possibility of being ``scooped'', i.e. the risk that
other working groups are using the same data for a similar research question at
the same time, eventually claiming priority to a research idea or discovery
\citep[cf.][]{laine2017afraid}.
%
This risk is aggravated in case of early career scientists that created and
maintain public datasets, pre-registered studies based on open data, or have to
stick to inflexible project plans.
%
Therefor, risks, benefits and best practices of open science and hands-on
training of related software packages should be introduced in undergraduate
programs.
%
For graduate students, incentives to conduct an open science project should be
established.
% Instead of compulsory requirements from funders, which might only lead
% researchers to show minimal compliance [Neylon, 2017].
%
After all, open sciences is an appropriate tool to
%
a) make researchers accountable to collect, store, document, process, and
publish data and materials according to best practices,
%
b) increase reproducibility of results and reliability of findings,
%
c) make knowledge and technologies widely accessible,
%
d) increase the efficiency of the scientific progress and promote innovation,
and
%
e) ultimately increase the trust of the public into scientific process and its
results.

\todo[inline]{just bold statements at the end but probably okay}



\section{Naturalistic stimuli for functional localization?}

\todo[inline]{This discussion is about the present project; might be merged with
the general rant about naturalistic stimuli below}

%
The \ac{ppa} is traditionally identified by contrasting hemodynamic responses to
blocks of pictures of scenes or landscapes to, e.g., blocks of pictures of tools
or faces.
%
Although the exact definition of the \ac{ppa} depends on the type of stimuli,
the task, and the $t$-contrast, the traditional localizer approach can reliably
delineate the \ac{ppa} bilaterally in a large proportion of subjects
\citep{zhen2017quantifying}.
%
For example, \citet{sengupta2016extension} successfully delineated the
left-hemispheric \ac{ppa} in 12 of 14 subjects and right-hemispheric \ac{ppa} in
14 of 14 subjects based on localizer data.
%
However, the highly controlled nature of the employed stimuli raises the
question whether the spatial localization of the isolated psychological
construct of ``scene perception'' generalizes to more ecological settings
outside of the laboratory (the neuronal correlate of the perception of
black-and-white landscape pictures).
%
Hence, we employed two naturalistic stimuli, a movie and its audio-description
that provides a continuous, complex, immersive, task-free paradigm that more
closely resembles our natural dynamic environment than traditional experimental
paradigms in order to assess the generalizability of inferences drawn from
highly controlled experiments to more naturalistic stimulation.



\subsection{Functional localization via modeling hemodynamic responses}

\todo[inline]{mih: worth stating again somewhere in the discussion that the
studyforrest dataset is not for this (diverse), but it is a small dataset, which
limits the generality}

% study in one sentence
In \citet{haeusler2022processing}, we explored whether an audio-visual
naturalistic stimulus and an exclusively auditory naturalistic stimulus could be
used in order to localize the \ac{ppa} as it was previously identified in the
same set of participants by a traditional block-design functional localizer that
employed static pictures \citep{sengupta2016extension}.


\paragraph{Method}
% stress similarity to localizer approach
Adopting the approach of traditional localizer, we modeled hemodynamic responses
to events in two naturalistic stimuli in order to create $t$-contrasts that
aimed to localize the \ac{ppa}.
% AV operationalization
For the model-based mass-univariate statistical analysis (i.e. \ac{glm}) of the
movie's data, we operationalized the perception of visual spatial information
based on an annotation of movie cuts and depicted locations
\citep{haeusler2016cutanno}.
% AD operationalization
For the \ac{glm} of the audio-description's data, we extended the annotation of
speech that we created and validated in \citep{haeusler2021speechanno} by
further annotating nouns that the narrator uses to describe the movie's absent
visual content.


\paragraph{Results}
% group results
On a group-average level, results demonstrate that increased activation in the
\ac{ppa} during the perception of static pictures generalizes to the perception
of spatial information embedded in an audio-visual movie and exclusively
auditory naturalistic stimulus \citep{haeusler2022processing}.
% glm analysis
Further, results show that a model-driven \ac{glm} analysis based on a
naturalistic stimulus' annotation can be used to replicate findings of studies
that employed traditional paradigms, and add evidence
\citep[cf.][]{bartels2004mapping} that functional specialization of cortical
areas is preserved during naturalistic stimulation.
% individual AD
On an individual level, the analysis of the movie yielded bilateral clusters of
increased hemodynamic activity in the \ac{ppa} of five participants and a
unilateral cluster in seven participants, whereas the analysis of the
audio-description revealed bilateral clusters in nine participants and one
unilateral cluster in one participant.
% conclusion
Results suggest that a movie and a exclusively auditory naturalistic stimulus
could potentially substitute a visual localizer as a diagnostic procedure to
assess brain functions in individual persons.


\paragraph{Contra: auditory response is different; sometime not reliable}

\todo[inline]{however: non-reliability might be reliable in some subjects}
%
However, the usability of a purely auditory paradigm to localize the \ac{ppa} as
it is defined by a visual paradigm might be limited by our findings that suggest
that increased hemodynamic activity during auditory stimulation is spatially
restricted to the anterior \ac{ppa}.
%
On the one hand, our results provide further evidence to studies in the field of
visual perception that suggest that the \ac{ppa} can be divided into
functionally subregions that are coactivate during the perception of visual
scenes but process different stimulus features
\citep{aminoff2007parahippocampal, baldassano2013differential}.
%
On the other hand, results encourage future studies to investigate response in
the parahippocampal region to auditory stimuli under more controlled conditions.
%
In case the controlled paradigm reveals less variation in reliability across
participants, future studies employing naturalistic stimuli could then
investigate factors that might have influenced reliability of individual results
in \citet{haeusler2022processing}:
%
a) stimulus-related factors like the number available events that can be modeled
and contrasted per stimulus segment, or the general confound structure,
%
b) modeling-related factors like the assumed shape of the hemodynamic response
%
c) subject-specific factors like alertness or engagement over the course of the
experiment.


\subsection{The rant about model-driven analyses of nat. stimuli}

\todo[inline]{This discussion is about the naturalistic stimuli in general}


\paragraph{Origin and assumptions of GLM}

%
Originating from \ac{pet} research, the currently dominating \ac{glm} is
tailored to analyse data of parametric\todo{Def?} experimental designs that
manipulate isolated experimental variables of interest, and requires the
researcher to model a hypothesized hemodynamic time course that is fit to the
data in order to predict and contrast the observed hemodynamic activity
\citep{friston1998event}.
%
However, the continuity and complexity of naturalistic stimuli stress
physiolgical assumptions like
%
a) the consistency of responses across [time-locked] events (the basis for
\textit{trial-averaging}) [Dale and Buckner (1997)],
%
b) the linearity of the hemodynamic responses [Cohen (1997). Parametric Analysis
of fMRI; Boynton (1996). Linear systems analsysis; Dale (1999). Optimal
experimental design for event-related fmri]
%
c) and cognitive substraction [Friston (1996)],
%
as well as statistical assumptions like the absence of collinearity among
variables.
%
Therefore, there is no consensus yet on how to adapt physiological and
statistical assumption underlying model-driven analyses from traditional
paradigms to naturalistic stimuli.


\pagebreak



\subsubsection{Solution to lack of control: annotations}

\todo[inline]{but how to model constructs like growing empathy}

%
A common method to tackle the lack of experimental control over temporal
structure of stimulus features are extensive annotations that allow the modeling
and statistical control of possibly confounding variables \citep[e.g., Wagner,
2016, The dorsal medial prefrontal cortex
responds...,][]{deniz2019representation}.


\subsubsection{From objective and automatic...}

\todo[inline]{stimulus features vs. observer features; short temporal scales
vs. long temporal scales; objective vs. subjective; level of ambiguity}

``The words ‘ratings’ and ‘annotations’ are used somewhat interchangeably to
describe any manually extracted descriptions of the stimuli, but ratings often
refer to more subjective features (i.e., observer features) while annotations
refer to features that are considered relatively consistent across individuals
(i.e., stimulus features)'' \citep{saarimaki2021naturalistic}.


%
Low-level stimulus features are often not the feature of interest but are
considered to be a confound that might obscure effects of interest, and
therefore need to be annotated and controlled in order to guide the
interpretation of results and allow generalization to other naturalistic
stimuli.

%
Low-level visual features like luminance / brightness\todo{difference?} or
perceptual difference of consecutive movie frames or low-level auditory features
like root-mean square power (a.k.a. volume) or left-right volume difference can
be extracted objectively and automatically on the temporal scale of movie frames
(usually 25-30 frames per second; cf.
\href{https://github.com/psychoinformatics-de/studyforrest-data-confoundsannotation
}{\url{github.com/psychoinformatics-de/studyforrest-data-confoundsannotation}}
for low-level annotations of the studyforrest dataset).

%
``Automatic feature extraction usually operates at a momentary single-unit
level, for instance, on single frames, words, or sounds''
\citep{saarimaki2021naturalistic}.


``The rapid developments in automatic feature extraction techniques allow
replacing part of the human ratings with automatic tools.
%
Automatic feature extraction usually relies on computer vision or machine
learning to find stimulus features that together represent a category.
%
Especially, clearly defined categories might benefit from automatic extraction
[McNamara et al., 2017]:
%
object categories that were formerly tediously manually annotated can now be
extracted automatically from naturalistic stimuli.
%
Automatic tools have been developed for extracting and higher-level features
such as faces, semantics, speech prosody, and actions [e.g., pliers, McNamara et
al., 2017]'' \citep{saarimaki2021naturalistic}.
%
Object categories such as faces and bodies have been extracted and modeled with
automated object recognition tools either from the stimulus [Horikawa et al.,
2020] or from the observers [Sawahata et al., 2013; Chang et al., 2021].


\subsubsection{...to subjective and ambiguous}

subject-related variables (e.g., felt emotions, level of engagement, attentional
focus)
%
``Importantly, automatic emotion-related feature extraction often relies on
human ratings in the first instance:
%
samples rated by humans are used to train an algorithm to extract features
automatically [see, e.g., Kragel et al., 2019].
%
Thus, automatic extraction of emotional content is only as reliable as the
original definition of the emotion feature.
%
For instance, automatic recognition of facial expressions (e.g., specific
emotion categories from faces) assumes that a correct emotion label was assigned
to the facial expressions in the training set, a task that is often
underspecified [Barrett et al., 2019]'' \citep{saarimaki2021naturalistic}.

%
``Human ratings are currently the main method for accessing and modeling
observer’s emotional experiences.
%
Self-report ratings of some experienced aspect of emotions vs. ratings from an
independent sample.
%
Here, the assumption is that naturalistic stimuli elicit similar emotional
processing across individuals.
%
The rating task is often subjective and challenging.
%
Annotating emotional content is a subjective task and depends on the
individual’s perception, experiences, and culture''
\citep{saarimaki2021naturalistic}.


``Data-driven analyses---because they do not require an explicit model of the
task or stimulus---are particularly useful for naturalistic experimental
paradigms, where constructing such a model may be \textbf{prohibitively
difficult} \citep{nastase2019measuring}.


%
c) because creating and assessing the suitability of different model-based
analyses requires the feature space to be extensively annotated which is often
still tediously and time-consuming.

%
Notoriously / prohibitively difficult, but more and more can be annotated at the
expense of models getting cumbersome
%
Before building a model stimulus needs to be annotated and assessed


Investigate or control variance correlating with...

%
``The interpretations based on combining stimulus-driven features with brain
imaging data are based on two critical assumptions:
%
first, that the researcher knows which features of the stimulus are driving the
brain activity, and second, that these features have been modeled accurately
[Chang et al., 2020]'' \citep{saarimaki2021naturalistic}.

%
``Standards methods such as the general linear model [1] require the
experimenter to construct a design matrix that models features of the presented
stimuli across time.
%
Such design matrices are \textbf{notoriously difficult} to construct for
naturalistic stimuli as one has to rely on manual annotations (see [2]) or deep
learning techniques (see e.g. [3], [4], [5] or [6]) that are hard to use, and
provide high-dimensional, \textbf{cumbersome} models of the stimulus''
\citep{richard2019fast} \citep[cf., e.g.,][]{deniz2019representation}



\subsubsection{Some, if not most, naturalistic stimuli might offer higher
ecologically validity at the cost of simply not suitable given limitations of
current analyses methods}

%
However, some low-level features are inherently intertwined with higher-level
features (e.g., the low-level feature ``green'' and the higher-level feature
``tree-leaf'') and therefore represent ``natural image statistics''.


``Prior to launching a full-scale study with a given media stimulus, one could
extract continuous regressors for low-level (e.g. luminance and audio
envelope), mid-level (e.g. presence of certain characters on screen) and
high-level (e.g. mood) features to determine the degree of collinearity between
features and the extent to which this might confound testing of a particular
hypothesis using that stimulus.
%
The potential ‘confounding’ features will vary based on the research questions
and phenomena of interest. For an example of assessing feature collinearity
profiles as part of the stimulus selection process, see Figure 2''
\citep{grall2022leveraging}.

%
Still similar to \citet{grall2022leveraging}: ``One popular solution to this
problem is to regress out the effects of these features in preprocessing or
first-level general linear model analyses and/or to limit analyses to
higher-order regions, which are assumed to be less closely driven by purely
perceptual features.
%
This is because those exact features, and how they vary and covary over time,
fundamentally influence the experience of the product as a whole.
%
Hence, the covariance of features of interest and confound features need to be
assessed, ultimately deeming some, if not most, naturalistic stimuli
inappropriate to investigate a specific aspect of perception and cognition under
current modeling approaches that produce unsatisfactory results in case of
collinearity''
%
Depending on the research question, a investigator need to assess the
covariance, if not collinearity, among stimulus features considered to be of
interest or considered to be a confound variable.


\subsection{Interim conclusion: recommendations}

\todo[inline]{ecologically validity at the cost of interpretability (data-driven
is more "how" and "when", less "why")}

%
Consequently, 20 years after group-level findings of \citep{bartels2004mapping}
and despite the rising popularity of naturalistic stimuli in neuroscience no
localizer exists that is based on a movie or an auditory narrative.
%
Probably, the most ecologically valid localizers today are so called
\textit{dynamic} localizers \citep[e.g.,][]{pitcher2011differential,
fox2009defining}:
%
dynamic localizers employ blocks of short videos (each video lasting
$\approx$\unit[2-3]{s}) of scenes, faces etc., and lend themselves conveniently
to traditional modeling procedures.
%
However, advances in machine learning promise to increase the number of stimulus
features that can---at least preliminarily---be annotated automatically
\citep[cf. the toolsbox ``pliers'' that is implemented in the platform
\href{https://neuroscout.org/}{\url{neuroscout.org}}
platform;][]{mcnamara2017developing, delavega2022neuroscout}.
%
After all, easing the annotation bottleneck of naturalistic stimuli is probably
the biggest prerequisite to further investigate methodological issues, adapt
traditional and develop new methods, and evaluate their appropriateness to draw
valid inferences from naturalistic stimuli.

Advances in modeling: Nunez-Elizalde (2019), Dupre la Tour (2022)


%
``Questions to guide researchers in choosing media stimuli for a future
experiment:
%
1. Why is this particular media stimulus the right task for this research
question?
%
2. How have you ensured your stimuli engage the processes you intend for them to
engage? What previous testing supports your choice of stimuli?
%
3. Which formal media elements can you notice in your stimulus, how might these
elements engage certain cognitive processes and can you model these elements at
the analysis stage to draw more nuanced inferences?''
\citep{grall2022leveraging}.
%
4. Researcher should know some film making techniques in order to assess a
stimulus, know what to extract (interpret extracted features), and interpret the
results.: ``Naturalistic stimuli are deliberately crafted products meant to
elicit particular human thought, emotion and behavior.
%
If a neuroscientist wishes to study a particular cognitive process using a movie
stimulus, having a basic knowledge of formal cinematic features, editing
techniques and genre conventions will allow them to more effectively realize the
many advantages that media offer because they are crafted for a specific
purpose'' \citep{grall2022leveraging}.

%
a) know what you want to study and if using a naturalistic stimulus makes sense
at all (not just for the sake of it)
%
b) choose appropriate stimulus (film making knowledge helps)
%
c) extract features
%
d) model the response correctly [e.g. an assumed growing empathy whith a movie
character].

In case, minimization of intersubject-variability and reliability in all
subjects is the main goal, stick to classic localizers.
%
In case, ecological validity and maximization of intersubject-variability (at
the cost of within-subject reliability) is okay [putting aside challenges],
consider naturalistic stimuli.

stimulus variables can be statistically controlled
observer variables [fluctuating engagement due to lack of task] is hard record
and therefore statisticall controlled.


\subsubsection{Designed to be engaging but do they engage?}

\todo[inline]{control observer features by recording or self-reports}

\todo[inline]{the time-course of time-locked stimulus features is fixed, but
behaviour is not controlled; less controlled than traditional paradigms (no eye
fixation; no task that forces participants to attend to a specific presented
element)}

\todo[inline]{Intersubject correlation obscures individual variation; in case
it's calculated across the whole stimulus it also obscures dynamic changes
across the course of the stimuli}

\todo[inline]{Trade off in case of individual level analyses: the more engaging,
the less natural?}

%
``The manner in which naturalistic paradigms can be employed varies along a
spectrum of active engagement and action.
%
Viewing naturalistic stimuli is an inherently challenging task that, in the very
least, requires attention, active comprehension, and integration of information
across multiple time scales.
%
In perceptually oriented experiments, participants are simply required to engage
in naturalistic audio, visual, or audio-visual stimuli''
\citep{sonkusare2019naturalistic}.

%
``Stimuli are naturally engaging.
%
However, a drawback of using naturalistic paradigms in this way is the lack of
means to probe or measure the level of engagement which may vary across
participants according to cultural background or personal preferences.
%
Although this can partly be overcome by eye tracking, concurrent physiological
recordings [29], and post hoc questionnaires, such as a recall task, the nature
of the real-time engagement in the absence of action remains unclear''
\citep{sonkusare2019naturalistic}.




\subsection{Functional localization via estimation from reference group}

\todo[inline]{write when SRM part is finished}

\todo[inline]{explicitly (re)state aims}

%
Results from \citet{haeusler2022processing} suggest that the movie as well as
the audio-description sample hemodynamic responses that correlate with the
occurrence of spatial information.
%
Therefor, we did the following ...

% goal 1: new procedure
We estimated results of a dedicated localizer \citep{sengupta2016extension} via
functional alignment from results of a reference group.
% the problem
Considering practical and monetary constraints in a clinical context, a paradigm
lasting 90 to 120 minutes is inappropriate for even an extensive individual
diagnostic procedure, we also assessed the relationship between length of
naturalistic stimulation used to align the test participant to the fixed
\ac{cfs} and the estimation performance.



\subsubsection{Interim summary and future studies}

\todo[inline]{This topic is only touched in the SRM study's discussion}

\todo[inline]{probably, it is better to discuss it here more than in SRM part}

\todo[inline]{Following are some "templates" outlining the general idea}

% examples of probabilistic atlasses: \citet{rosenke2021probabilistic}:
% Cortical atlases have been developed, which allow localization of visual areas
% ``in new subjects by leveraging ROI data from an independent set of typical
% participants: Frost and Goebel 2012;
% ventral temporal cortex (VTC) category selectivity: Julian et al. 2012,
% Zhen et al. 2017, Weiner et al. 2018; visual field maps: Benson et al. 2012,
% Benson and Winawer 2018; Wang et al. 2015''.


\paragraph{Problem space}

%
``Identifying all of the currently known topographic regions of the human visual
system requires multiple scanning sessions'' \citep{wang2015probabilistic}.
%
``Given the expense and availability of fMRI, this is not always practical''
\citep{wang2015probabilistic}.
%
``Our approach has the potential to estimate an unlimited variety of functional
topographies at the individual level based on the responses to a single
naturalistic, dynamic stimulus'' \citep{jiahui2020predicting}.


\paragraph{Database}

%
``A normative database of participants who were scanned during movie viewing and
during functional localizers for different perceptual and cognitive functions
would serve as a reference'' \citep{jiahui2020predicting}.
%
``There are numerous other functional localizers in other perceptual and
cognitive domains, such as simple visual motion, biological motion, tonotopy,
voice perception, music perception, language, calculations, working memory, and
theory of mind'' \citep{jiahui2020predicting}.

%
``A database from a normative group could allow researchers to estimate new
subjects' functional topographies by collecting only a movie-viewing data set
and then deriving the individualized topographies with the normative database''
\citep{jiahui2020predicting}.
%
The database ``may prove especially useful for predicting functional patterns in
case no localizer data are available, saving scanning time and expenses''
\citep{rosenke2021probabilistic}.


\paragraph{Calibration}
%
A naturalistic stimulus like a move or audio-description could be used to align
a test subject to a \ac{cfs} created from data of a normative reference group.
%
Naturalistic stimuli ``engage in parallel multiple neural systems for vision,
audition, language, person perception, social cognition, and other functions''
\citep{jiahui2020predicting} and offer higher generalizability [and provide
higher validity?] of transformations matrices.

%
''Some high-level cognitive processes, such as calculation, working memory, and
logical reasoning, may be less well sampled by movie viewing, and further work
is necessary to test whether hyperalignment based on movie-viewing data can be
used to estimate topographies for these other domains of high-level cognition.
'' \citep{jiahui2020predicting}.


\paragraph{Application: estimation}

%
Once a valid alignment is established, known functional properties of the
(normative) reference can then be projected into the respective individual voxel
space by mapping a variety $Z$-maps created from a variety of $t$-contrast from
a normative reference group onto an individual subjects and thus potentially
substitute a variety of localizers.
%
``A new subject's functional topographies could be estimated based only on that
subject's movie data and other subjects' localizer data from the normative
database that could be projected into that subject's cortical anatomy using
hyperalignment transformation matrices derived from movie data and could replace
tedious functional localizers with an engaging movie''
\citep{jiahui2020predicting}.

%
``Investigators would need to scan their participants only during movie viewing
and a wide range of idiosyncratic functional topographies could then be
estimated individually based on localizer data projected from the brains in the
normative sample into the new participants' cortical anatomies''
\citep{jiahui2020predicting}.
%
``Functional topographies could be mapped from a database containing a wide
range of perceptual and cognitive functions to new subjects based only on fMRI
data collected while watching an engaging, naturalistic stimulus and other
subjects' localizer data from a normative sample'' \citep{jiahui2020predicting}.

%
''Because naturalistic movies include people, human actions, conversations,
social interactions, background music etc., we predict that hyperalignment
transformation matrices based on these movies also will work for localizers of
functional topographies for audition, language, and social cognition''
\citep{jiahui2020predicting}.
%
``From a single movie dataset multiple functional topographies can be estimated
\citep{guntupalli2016model}, whereas different localizers are typically required
to map different functional topographies, making a thorough mapping of selective
topographies time-consuming and inefficient'' \citep{jiahui2020predicting}.


\paragraph{Application: deviation (a.k.a. clinical application)}

\todo[inline]{cf. general introduction (on "individual neuroscience")}

\todo[inline]{cf. SRM discussion: quantify deviation from a norm vs.  predict
deviant pattern?}


\todo[inline]{\citet{silva2018challenges, szaflarski2017practice}}

%
That reference would enable an qualitative and quantitative description of an
individual's brain function with respect to such a norm, and consequently
progress the field towards neuroimaging studies of individual differences that
more closely resemble their psychological counterparts.


``In the clinical context, fMRI plays an important role for planning surgery in
patients with tumors or epilepsies, as it aids the understanding of which parts
of the brain need to be spared in order to preserve sensory, motor or cognitive
abilities'' \citep{wegrzyn2018thought}.


\paragraph{Language lateralization}

\todo[inline]{I abandoned the idea to come up with language area asymmetry (at
least in the SRM study); the problem in case of prediction is that most
interesting are cases of atypical language lateralization; problem: the models
don't model individual component (except, maybe,
\citet{feilong2022individualized}) and ROIs and searchlight spheres are too
small}

\todo[inline]{templates from papers using \ac{fmri} to localize language areas
and discuss atypical language organization are outsourced to separate file}

%
For example \ac{fmri} could be used as an noninvasive alternative to map
language areas and potentially assess lateralization (or hemispheric asymmetry)
of functional brain topography related to language (sub)functions, in order to
guide pre- and perioperative assessment of neurosurgery, e.g., in case of
epilepsy.


\section{Conclusion}

\subsection{Naturalistic stimuli}

\todo[inline]{investigating processes under more ecologically conditions;
investigate psychological impossible to investigate using traditional paradigms
(e.g., increasing emphathy towards a movie character)}

%
Naturalistic stimuli ``impose a meaningful timecourse across subjects while
still allowing for individual variation in brain activity and behavioral
responses, and lend themselves to a broader set of analyses than either pure
rest or pure event-related task designs'' \citep[][p. 142]{finn2017can}.

%
``One always loses in control as the stimulus becomes more naturalistic.
%
For example, it could hypothetically be possible that some brain responses
attributed to emotions or social cognition could be in fact caused by there
being more close-ups in the respective parts of the movie clips being used.
%
Caveats can be avoided by utilization of artificial and naturalistic stimulus
paradigms in parallel (e.g., by using a continuum of stimuli from artificial to
naturalistic across experiments in the same subjects) and by modeling both
factors of interest (e.g., self-reports of emotional experiences) and potential
nuisance factors (e.g., shot sizes in the movie) and taking them into account in
the analyses'' \citep{jaaskelainen2021movies}.

%
``Naturalistic paradigms do not aim to replace the classic, controlled
neuroimaging paradigms \citep{sonkusare2019naturalistic}.
%
Due to their complexity and current limitations in understanding the statistical
properties of different features in naturalistic conditions, naturalistic
stimuli are not optimal for model development [see, e.g., Rust and Movshon,
2005].
%
Controlled experiments are still needed for hypothesis testing and developing
models, while naturalistic stimuli are best employed to test models in
ecologically valid settings and to expand them to situations where context
matters more'' \citep[][p. 19]{saarimaki2021naturalistic}.

%
``Developments in neuroimaging and in complementary behavior- and
data-analysis methods hold keys to advancing rapidly to even more robust use of
naturalistic stimuli.
%
Combining more traditional controlled experimental designs, such as ToM and
other localizer tasks, with use of movies and narratives represents another
highly promising research direction, as does expanding naturalistic stimulation
from movie clips and narratives to virtual reality and computer-game/simulated
environments'' \citep{jaaskelainen2021movies}.
%
Naturalistic stimuli are not a panacea but traditional paradigms and
naturalistic paradigms should be used in tandem / reciprocally to generate new
hypotheses and progress our understanding of the brain.

%
``Modeling the stimulus and task properties is a central challenge with
naturalistic paradigms and one that has great potential if solved [Simony and
Chang, 2020].
%
Compared to controlled paradigms, naturalistic stimuli allow investigating
multiple functional components simultaneously, and studying individual
variation'' \citep{saarimaki2021naturalistic}.

However, despite current limitation and challenges:
%
``Has the use of naturalistic stimuli delivered upon its promise a decade later?
%
However, as is the case with any scientific field, the introduction of new
methods requires independent validation and the reproduction of findings from
previous studies before embarking upon higher aspiration and practical
applications.
%
More innovative means of introducing subtle experimental perturbations into
otherwise innocuous films and stories also require time to develop.
%
Sometimes, disruptive and counterfactual findings can help [Feyerabend (2010).
Against method: Outline of an anarchistic theory of knowledge].
%
Consequently, the answer may be that a decade is not yet a sufficiently long
time-window;
%
however, given the recent successes in using naturalistic stimuli, we suspect
that its influence as a research tool will continue to grow in both cognitive
and translational neuroscience'' \citep{sonkusare2019naturalistic}.

%
Exploratory studies and ``methodological developments are still needed to
account for the complex interaction dynamics, such as feedback loops, between
different component processes [e.g., Pessoa, 2018]''
\citep{saarimaki2021naturalistic}.


\subsubsection{Naturalistic stimuli are not naturalistic in the strict sense}

\todo[inline]{a.k.a. natural image statistics vs. crafted "movie statistics"}

%
This is aggravated because naturalistic stimuli are not "naturalistic" in the
strict sense
%
Despite the growing popularity of naturalistic stimuli it should not be
forgotten that naturalistic stimuli like movies and narratives are not
``naturalistic'' in the strict sense but only an approximation of real-life.
%
The experimental setting (e.g., lying in a noise fMRI scanner), the limited
field of view, and passive participation in the paradigm limit a fully immersive
experience and the range of potentially sampled cognitive brain states (e.g.,
movement, mental calculation, decision-making, social interaction).
%
Similar to traditionally employed stimuli that have been carefully designed by
researchers to probe specific processes, most naturalistic stimuli that have
been employed in neuroscience have been carefully designed by professional media
creators to entertain an audience.
%
For example, a film director's utilize a variety of techniques like
camera-movement, composition, movie editing, voice-overs
\citep{brown2012cinematography, dancyger2011film-technique, katz1991film,
mercado2011filmmakers}---despite occurring largely unnoticed as a cinematography
tool by the viewer---often fundamentally differ from real-live in order to
intentionally manipulate the viewers' attentional focus and mental states.
%
For example, participants asked to spot movie cuts miss between 10\% and 50\% of
them depending on the type of cut \citep{smith2008edit}.
%
These techniques might lead to a large amount of synchronized spatial-temporal
responses across subjects that is reliably across presentations
\citep{hasson2008neurocinematics}, but also leads to an artificial product and a
medium-specific confound structure, and diminishes individual variation.
%
These may be exploited or need to be considered in order to assess
appropriateness of naturalistic stimuli to be chosen and/or modeled in order to
interpret the results (not just "how" and "when" but also "why").

%
Stimulus features that are related to film making techniques can be exploited
\citep{haeusler2022processing, kauttonen2018brain} or need to be controlled
(``Demons to some, angels to others'' -- Pinhead).

%
Physiologial assumptions need to be reevaluated, methods and models need to be refined


\subsection{Sharing is caring (and advances the field through collaborative
effort)}

%
Challenging data data analysis, but create \& share (data from naturalistic
stimuli \& ) annotations.

%
Naturalistic stimuli are so rich that dataset decay is low, everybody can get
a slice of the cake and do his/her part to advance the field.
%
We re-used existing data as a foundation for a new investigation in order to
generate novel findings encourage further studies, and illustrate the benefits
of publicly and freely available datasets.
%
Collaborative effort in order to advance human knowledge and shit.

%
``Moreover, there lacks a movie database with robustly validated measures,
especially with test--retest reliability.
%
This is perhaps a key requirement for valid and reproducible research, which the
field should strive to establish.
%
Positive steps in this direction are apparent in big data sharing initiatives,
such as the HCP [http://www.humanconnectome.org] and OpenfMRI [156], which have
included film clips and gambling task in their task-fMRI paradigms.
%
Recent developments in machine learning and artificial intelligence are nicely
positioned to exploit such open big data sets by tackling the complex challenges
presented by multimodal contents of naturalistic stimuli.
%
No doubt, such data sharing initiatives will provide a further impetus to the
development of novel analytical methods and insights into brain processing of
complex information in naturalistic paradigms''
\citep{sonkusare2019naturalistic}.



\pagebreak


\section{Some backups}


\subsection{Group-level vs individual-level analyses}

Backup of quotes for general discussion (or SRM study).  Studies that average
data across study participants may draw

\begin{itemize}

\item ``provide only an approximate view of any individual's brain organization,
    potentially obscuring meaningful individual differences in cortical
        organization'' \citep{laumann2015functional},

\item may just ``capture the common denominator of each individual cognitive
    circuit and lose a large amount of information''

\item ``obscure(s) patterns of brain organization specific to each individual''
    \citep{laumann2015functional}.

\end{itemize}


\subsection{Dynamic localizers}
%
``Previous reports showing significant differences between topographies
estimated by static and dynamic localizers, especially in superior temporal and
frontal cortices [Fox et al., 2009; Pitcher et al., 2011]''
\citep{jiahui2022cross}.
%
``For all categories, the dynamic localizer elicited stronger and broader
category-selective activations than the static localizer''
\citep{jiahui2022cross}.
%
``For example, for the face-selective topographies, the dynamic localizer
activated more areas than the static localizer (e.g., in superior temporal and
frontal cortices)'' \citep{jiahui2022cross}.
%
``The searchlight analysis showed that the dynamic localizer had higher
reliabilities across the cortex, especially in regions that were selectively
responsive to the target category'' \citep{jiahui2022cross}.
%
``The low correlations were not because the prediction method failed but
reflected the difference in the topographies activated by different types of
localizers.'' \citep{jiahui2022cross}.


\subsection{Brain \& behavior: "fingerprints"}

``two disciplines of scientific psychology."
%According to Cronbach,
the experimental discipline strives to uncover universal human traits and
abilities through experimental control and group averaging, whereas the
correlational discipline strives to explain variation between people by
measuring how they differ from one another.
%
A fundamental distinction between the two disciplines is how they treat
individual differences.
%
For the experimental researcher, variation between people is an error that must
be minimized to detect the largest experimental effect.
%
For the correlational investigator, variation between people is the primary unit
of analysis and must be measured carefully to extract reliable individual
differences (Cronbach, 1957; Hedge, Powell, \& Sumner, 2018).
%
Current task-fMRI paradigms are largely descended from the experimental
discipline.
%
Task-fMRI paradigms are intentionally designed to reveal how the average human
brain responds to provocation, while minimizing between-subjects variance.
%
Paradigms that are able to elicit robust targeted brain activity at the group
level are subsequently converted into tools for assessing individual
differences.
%
Within-subjects robustness is, then, often inappropriately invoked to suggest
between-subjects reliability, despite the fact that reliable within-subjects
experimental effects at a group level can arise from unreliable between-subjects
measurements [Fröhner, Teckentrup, Smolka, \& Kroemer, 2019].
%
Instead of continuing to adopt fMRI tasks from experimental studies emphasizing
within-subjects effects, we need to develop new tasks (and naturalistic stimuli)
from the ground up with the goal of optimizing their utility in
individual-differences research (i.e., between-subjects effects).
%
Psychometrics provides many tools and methods for developing reliable
individual-differences measures that have been underutilized in task-fMRI
development.
%
For example, stimuli in task fMRI could be selected on the basis of their
ability to maximally distinguish groups of people or to elicit reliable
between-subjects variance.
%
As noted in the first recommendation, psychometric tools for test construction
could be adopted to optimize reliable task-fMRI measures, including item
analysis, latent variable modeling, and internal-consistency measures (Crocker
\& Algina, 2006)'' \citep{elliott2020test}.

%
Maybe might be stable individual differences in cognitive tendencies or
cognitive abilities like susceptibility / predisposition [?] to attend to, [or]
recognize [or process] auditory spatial information.
% kanai
In case the pattern is stable within individual subjects / is ``highly
consistent across different sessions [or experiments], then they are
characteristics of the individuals and may reflect differences in their brain
function'' \citep{kanai2011structural} [on structural diffences].
%
``Individual differences in topology (i.e. location, size, shape of functional
areas) and the activity within functional areas can also be considered to be
interesting cases of inter-individual variability to understand the neural basis
of human cognition and behavior, brain-phenotype relationships'', and ``present
useful phenotypes or biomarkers \citep{glasser2016multi,
vanhorn2008individual}''


\subsubsection{Brain \& behavior: example studies}

\todo[inline]{cf. also \citep{gordon2017individual, gordon2017precision}}
%
For example, \citet{kong2019spatial} suggested based on resting-state functional
connectivity measures ``that individual-specific network topography (i.e.,
location and spatial arrangement) might serve as a fingerprint of human behavior
that can predict behavioral phenotypes across cognition, personality, and
emotion'' \citep{kong2019spatial} [with modest accuary, comparable to previous
reports predicting phenotypes based on connectivity strength].

%
\citep{bijsterbosch2018relationship}'s ``results indicate that spatial variation
in the topography of functional regions across individuals is strongly
associated with behaviour'' \citep{bijsterbosch2018relationship}.
%
\citet{bijsterbosch2018relationship} found ``that the spatial arrangement of
functional regions is strongly predictive of non-imaging measures of behavior
and lifestyle'' [however shape \& exact location of brain regions interacted
strongly with  modeling of brain connectivity].
%
\citet{bijsterbosch2018relationship} found ``that individual differences in the
size, shape and exact position of the brain regions [as identified by
resting-state functional connectivity measures] was strongly linked to
individual differences in behavioral tests and questionnaires [including
intelligence, life satisfaction, drug use and aggression problems]''
\citep{bijsterbosch2018relationship}.

%
``The variations in spatial topographical features captured a more direct and
unique representation of subject variability than temporal correlations between
regions defined by group parcellation approaches (coupling).
%
Hence, the cross-subject information represented in commonly adopted
'connectivity fingerprints' could largely reflect spatial variability in the
location of functional regions across individuals, rather than variability in
coupling strength (at least for methods that directly map group-level
parcellations onto individual data)'' \citep{bijsterbosch2018relationship}.

%
``Depending on the employed spatial alignment algorithm and the amount of
removed spatial intersubject variability, the degree to which spatial
information may influence FC estimates possibly varies considerably across
studies.
%
In recent years, significant efforts have gone into the methods that more
accurately estimate the spatial location of functional parcels in individual
subjects [Chong et al., 2017; Glasser et al., 2016; Gordon et al., 2016; Hacker
et al., 2013; Harrison et al., 2015; Varoquaux et al., 2011; Wang et al., 2015],
and into advanced hyperalignment approaches [Chen et al., 2015; Guntupalli et
al., 2016; Guntupalli and Haxby, 2017]'' \citep{bijsterbosch2018relationship}.
