%
Traditionally, human brain mapping studies have averaged \ac{fmri} data across
participants.
%
To advance the field towards a clinical application, data need to be interpreted
on the level of single individuals.
% functional localizer
Functional localizers are an established method to describe the topography (i.e.
the location, size, and shape) of functional areas on the level of individuals.
% contra localizers
However, traditional localizer paradigms rely on selectively sampled, tightly
controlled stimuli and participant compliance, and can usually map only one
domain of brain functions.
% movies & narratives
Naturalistic stimuli like movies and auditory narratives offer a time-locked
event structure that samples a variety of brain functions ranging from low-level
perception to high-level cognition.
%
A localizer based on a naturalistic stimulus could offer a higher external
validity and potentially map a variety of brain functions.
% goal of thesis
Consequently, the purpose of this thesis was---while adhering to the principles
of open, transparent, and reproducible science---to investigate whether a movie
and the movie's audio-description may, in principle, replace a traditional
localizer paradigm.
% PPA as proof of concept
As a proof of concept, we focused on the \ac{ppa}, as an example of a high-level
visual area.
%
The \ac{ppa} exhibits increased hemodynamic activity when participants view
photos of landscapes, buildings or landmarks, compared to, for instance, photos
of faces or tools \citep[cf,][for reviews]{epstein2014neural, aminoff2013role}.
%
Moreover, results of \citet{aziz2008modulation}, who compared hemodynamic
activity levels in the \ac{ppa} correlated with different categories presented
in spoken sentences, revealed that semantic scene-related information also
modulates the \ac{ppa}'s activity level.
%
We assessed the potential of both the movie and the audio-description to replace
a visual localizer in two ways.
%
As the first approach, we  modified the procedure for the analysis of data from
localizer paradigms to data from the two naturalistic stimuli.
%
Hemodynamic responses correlating with the temporal structure of annotated
stimulus features \citep[cf.][]{haeusler2016cutanno, haeusler2021speechanno}
were modeled in order to create \ac{glm} $t$-contrasts that aimed to localize
the \ac{ppa} as identified in the same participants using a visual localizer in
\citet{sengupta2016extension}.
% estimation
As the second approach, we applied a functional alignment procedure as a novel
method in order to estimate results from the visual localizer, the movie and the
audio-description in a participant from the results of participants in a
reference group.



\section{Open Science}

% intro
In recent years, there has been a growing movement towards open science, which
seeks to make scientific research more accessible, transparent, and
reproducible.
%
Open science encompasses a range of practices, including open data, open-source
software, and open access publishing.
%
The overarching objective of this dissertation was to meet the standards of
open, shared, accessible, and transparent science in general, as well as the
standards of a reproducible and replicable research project specifically
\citep[cf.][]{watson2015will, fecher2014open}.
%
This objective included using open data and open-source software, and publishing
data, materials, code, and results openly available.


\subsection{Using open data and open-source software}

%
The first goal in the context of open science was to use open data, open
materials, and open-source software.
%
To achieve this, the thesis utilized publicly available
%
\ac{fmri} data \citep{hanke2014audiomovie, hanke2016simultaneous,
sengupta2016extension},
%
subject-specific \acp{roi} \citep{sengupta2016extension} and
%
stimulus annotations \citep{haeusler2016cutanno}
%
that are part of the studyforrest project
(\href{www.studyforrest.org}{\url{studyforrest.org}}).
%
The analyses were implemented in freely available and, where possible,
open-source software to prevent creating an ``artificial paywall'' for running
the analyses again on the initially openly accessible data.
%
The thesis benefited from established free software such as
%
Python and
%
FSL \citep[\href{https://www.fmrib.ox.ac.uk/fsl}{FMRIB's Software
Library;}][]{smith2004fsl}, which have been developed and debugged for years
through collaborative efforts,
%
but also from scientific software packages like
%
DataLad
\citep[\href{www.datalad.org}{\url{datalad.org}};][]{halchenko2021datalad} or
%
BrainIAK
\citep[\href{https://brainiak.org}{\url{brainiak.org}};][]{kumar2020brainiak,
kumar2020brainiaktutorial}
%
that emerged recently.
%
The use of pre-existing software packages, data, and results from previous
analyses enabled the project to shift time and resources from software
development and data collection to subsequent stages of the project.
%
The available data proved to be extremely valuable during the COVID-19 pandemic
as acquiring new fMRI data from participants became impossible, which led to a
need to revise the project plan.

% issue 1: data quality
A first issue with open data that is frequently overlooked is that openly
accessible data do not exempt the data consumer from the responsibility of
carefully scrutinizing the quality of the data and the underlying experimental
paradigm (e.g., stimuli and code).
%
It is too tempting to ``simply push the data through an analysis pipeline''
without carefully assessing the quality of the data first.
%
Researchers must ensure that any potential errors in the data are identified and
addressed before proceeding with their analysis.
% check the data
Consumers of datasets must assume that anything not clearly specified in the
dataset's description has not been taken into account.
% standards may differ
This is particularly important as the standards (e.g., quality, formats,
parameters) and open sciences practices (e.g., documenting) may differ across
scientific fields or even within a scientific field depending on a working
group's expertise and rigor.
% laugh with many, don't trust any
Even if the data are provided by a reputable source, researchers who consider
using third-party data should also consider themselves to be obliged to test and
validate a dataset's quality as if it was created by themselves, and in
accordance with their standards and particular use case.
%
In this regard, open data, despite being collected to the best of knowledge and
belief, can be compared to open-source software:
% super fancy literal quote
data will contain noise, errors, or artifacts, just as software will contain
bugs, but ``given enough eyeballs, all bugs are shallow'' \citep[][p.
30]{raymond1999cathedral}.

% issue 2: decisions were made
A second issue of open data is that the decisions made during data collection,
preprocessing, and further analyses may influence or even limit subsequently
performed analyses.
%
Researchers must carefully consider these decisions when deciding whether to use
pre-existing data, or to collect or preprocess data themselves.
%
For instance, we and \citet{sengupta2016extension} selected the \ac{ppa} as one
of several scene-selective areas because the \ac{ppa} was the first
scene-selective area to be discovered and is the most reliably activated region
across studies that investigate visual scene perception.
%
However, other areas, such as the \ac{rsc} and \ac{opa}, have repeatedly been
shown to be involved in visual spatial perception and navigation
\citep{chrastil2018heterogeneity, bettencourt2013role, dilks2013occipital,
epstein2019scene}.
%
Although we did not explicitly hypothesize it, we assumed that at least the
analysis of the movie would likely reveal significant clusters in the medial
parietal and lateral occipital cortex that may correspond to the functionally
defined \ac{rsc} and \ac{opa} respectively.
%
Indeed, results revealed significantly increased activity in the medial parietal
and lateral occipital cortex, and provide an incentive for further studies.
% \citep[cf. algorithmic procedure in, e.g.,][]{julian2012algorithmic}.
However, in order to create the corresponding masks of participants of the
studyforrest dataset, one would have to replicate the non-automatized procedure
of \citet{sengupta2016extension}.
%
This example shows how decisions made during data collection, preprocessing or
preceding investigations, despite being state-of-the-art at the time of being
published, are affecting subsequent studies.
% pro & contra: opportunity costs
Hence, when considering using open data, researchers need to weigh the costs and
benefits of one option (such as using preprocessed data as provided) relative to
an alternative option (such as preprocessing raw data differently than
provided), and then choose the option that will yield the highest net return.
%
In summary, any previous step that required human intervention or was not fully
automated influences the degree to which data or materials can be replicated,
updated, or extended.




\subsection{Publishing data, materials, code, and results}

%
The second goal in the context of open science was to publish the data,
materials, and results openly available.
%
The data and custom code created for this dissertation are version-controlled,
meaning that any changes made were logged and documented, to promote
transparency.
%
To ensure reproducibility, processing steps, ranging from downloading input data
to plotting figures, are implemented in scripts that can be rerun from the
command line.
%
For example, the annotation of speech has been published freely accessible
\citep{haeusler2021speechanno}.
%
Its content goes beyond what was required to conduct the analyses in
\citet{haeusler2022processing}, serves as an extension of the studyforrest
project and widens the ``annotation bottleneck'' \citep[][p.
16]{aliko2020naturalistic} of two naturalistic stimuli.
%
In \citet{haeusler2022processing}, we used open \ac{fmri} data to investigate a
research subject that was not anticipated when the data were initially made
available.
%
The results of \citet{haeusler2022processing} indicate that increased
hemodynamic activity in the \ac{ppa} generalizes from blocks of images to
spatial information embedded in a movie and an auditory narrative.
%
These results published in a peer-reviewed journal highlight the benefits of
sharing and reusing data to explore unanticipated research questions and to
generate new insights.
% contra
From a negative perspective, creating data, materials, and code to be published
requires a considerable amount of time and effort.
%
To encourage third parties to reuse the data, dataset creators must anticipate
potential use cases, collect the data with appropriate extent and rigor, convert
the data into a standardized format (taking into account, for example, naming
conventions and folder structure).
% automation
Analyses pipelines need to be designed and tested in a way that they can
reliably replicate every stage of a dataset.
% publication: findable, accessible, interoperable, reusable
Additionally, dataset creators must take into account legal matters (such as
intellectual property rights, use licenses, statements of agreement, and
anonymization of participant data), facilitate discovery by humans and web bots
(e.g., by including detailed descriptions and machine-readable metadata), and
guarantee long-term curation and accessibility.

%
From a positive perspective, creating a dataset that is intended to be published
has immediate benefits for a researcher.
%
Meticulously recording each step and commenting the advantages and disadvantages
of alternate procedural options leads to deeper understanding of the scientific
area, its practices, and methods.
%
The version-control of every step reduces the likelihood of a look-ahead bias.
%
Tracking and extensively documenting each stage of the data and code from the
beginning to the final results can also be thought of a lab protocol that
comprises structured information for writing the corresponding scientific
article.
%
Hence, creating a dataset supposed to be published encourages precise work
habits and good scientific practices in general.


\subsection{Interim summary}

% Open access publications might receive more citations than paywalled
% publications [\citep{piwowar2018state}], open data might get cited, and
% promote new collaborations [\citep{popkin2019data}].

% incentives like ``professional recognition or the allocation of extra funding
% [Kidwell et al., 2016; Fecher et al., 2015; Ali-Khan et al., 2018];
% Funding agencies already require publication of findings in OA schemes and
% data-sharing plans [Neylon, 2017]'' \citep{toribio2021early}.

%
In summary, the pursuit of conducting an open and reproducible research project
was not mandatory for thesis submission but entailed significant additional
effort and time.
%
Since open science practices are not yet covered in graduate or PhD curricula,
learning about principles and standards, as well as putting them into practice,
relied on self-initiative and self-learning.
%
The constantly emerging standards and principles, and the steadily developing
software packages to apply these standards, made it difficult to put theoretical
knowledge into practice.
%
In my opinion, the time and effort needed for open science practices greatly
exceed any short-term advantages.
%
The lengthy procedures are not justified by ``gambling'' on being cited in the
event that released data are reused, or by merely pursuing the ``higher
purpose'' of addressing the replication crisis.
%
Particularly, designing and testing fully automated analysis pipelines or
scripts to plot complex figures without any manual finishing for the perceived
sole purpose of reproducibility is out of proportion to the immediate benefit of
easier bug tracking or simply ``higher confidence in one's own work''.
%
On the contrary, PhD students that pursue a career in science may be concerned
about exposing themselves to critique owing to a maximum of voluntary
transparency and possibly (and blamelessly?) overlooked errors.
%
Another concern is the potential for being ``scooped'', which refers to the risk
that another working group is using the same data for a similar research
question at the same time and eventually claiming priority to the research idea
and its findings \citep[cf.][]{laine2017afraid}.
%
This risk is aggravated in case of early-career scientists that created and
maintain a public dataset, pre-registered studies based on a public dataset, or
have to adhere to inflexible project plans.
%
Hence, undergraduate programs should teach the benefits and best practices, but
also risks of open science, and provide practical training in related software
packages.
%
Postgraduate programs should create incentives to conduct open science projects.
% Instead of compulsory requirements from funders, which might only lead
% researchers to show minimal compliance [Neylon, 2017].
%
After all, open sciences is a suitable tool to
%
(a) hold researchers responsible for collecting, storing, documenting,
processing, and publishing data and materials in accordance with best practices,
%
(b) increase the reproducibility of results and replicability of findings,
%
(c) make knowledge and technologies widely accessible,
%
(d) therefore increase the efficiency of the scientific progress and promote
innovation, and
%
(e) ultimately increase the public's trust in the scientific process and its
findings.


\section{Naturalistic stimuli for functional localization}

%
The traditional method for identifying the \ac{ppa} is to contrast hemodynamic
responses to blocks of images of scenes or landscapes with blocks of images of
tools or faces.
%
While the exact outline of the \ac{ppa} varies depending on the type of stimuli,
task, and contrast as well as statistical threshold, the traditional localizer
approach can reliably delineate the \ac{ppa} bilaterally in a large proportion
of subjects \citep{zhen2017quantifying}.
%
\citet{sengupta2016extension}, for instance, were able to identify the
left-hemispheric \ac{ppa} in 12 of 14 subjects and right-hemispheric \ac{ppa} in
14 of 14 subjects.
% study in one sentence
In \citet{haeusler2022processing}, we investigated whether the \ac{ppa}, as
previously identified in the same group of participants of
\citet{sengupta2016extension}, could be localized using an audio-visual
naturalistic stimulus and an exclusively auditory naturalistic stimulus.
% stress similarity to localizer approach
We adapted the traditional localizer approach and modeled hemodynamic responses
to events in the two naturalistic stimuli to create $t$-contrasts that aimed to
localize the \ac{ppa}.
% AV operationalization
For the statistical analysis (i.e. \ac{glm}) of the movie, we utilized an
annotation of movie cuts and depicted locations \citep{haeusler2016cutanno}.
% AD operationalization
For the \ac{glm} of the audio-description, we extended the annotation of speech
that we created and validated in \citet{haeusler2021speechanno} by further
annotating nouns that the audio-description's narrator uses to describe the
lacking visual content.
% group results: specifically
On a group-average level, results demonstrate that increased hemodynamic
activation in the \ac{ppa} during the perception of static images generalizes to
the perception of spatial information embedded in a movie and an auditory
stimulus.
%
We have shown that a model-driven analysis based on a naturalistic stimulus'
annotation can replicate findings of studies that employed traditional
paradigms.
%
Our results provide further evidence \citep[cf.][]{bartels2004mapping} that
functional specialization of cortical areas is maintained during naturalistic
stimulation.
% individual results
On an individual level, our analysis of the movie revealed bilateral clusters of
increased hemodynamic activity in the \ac{ppa} of five participants and a
unilateral cluster in seven participants.
%
The analysis of the audio-description revealed bilateral clusters in nine
participants and a unilateral cluster in one participant.
% conclusion
These findings suggest that a naturalistic stimulus, whether visual or auditory,
could potentially replace a traditional localizer to assess brain functions in
individuals.




\subsection{Current challenges and limitations}

%
The current thesis highlights obstacles in the pursuit of developing a
multi-functional localizer.
%
Traditional experimental designs typically involve presenting participants with
simple, well-controlled stimuli that are carefully designed to elicit clearly
defined responses in targeted brain regions.
%
This allows for modeling of hemodynamic responses that can predict and explain
the neural activity observed in response to these stimuli.
%
The currently dominant analysis approach is the mass-univariate \ac{glm}, which
has its roots in \ac{pet} research, and is tailored to analyze data of
parametric experimental designs that manipulate isolated experimental variables
of interest.
%
The \ac{glm} requires the researcher to specify which stimulus features are
presumed to be correlated with the brain process under investigation.
%
Then, the researcher needs to model a hypothesized hemodynamic time course that
is fit to the data in order to predict the observed hemodynamic activity and
contrast parameter estimates \citep{friston1998event}.
%
Naturalistic stimuli, however, are continuous and complex, with a multitude of
sensory features that can activate different brain regions simultaneously.
%
Applying the traditional analysis approach is challenging and can lead to
difficulties in isolating specific neural correlates of perceptual or cognitive
processes.
%
Moreover, properties of naturalistic stimuli stress physiological assumptions of
the traditional GLM approach, such as cognitive subtraction
\citep{friston1996trouble}, the consistency of hemodynamic responses across
events \citep[the rationale behind \textit{trial-averaging};
cf.][]{dale1997selective}, and the linearity of hemodynamic responses
\citep{cohen1997parametric, boynton1996linear, dale1999optimal}.
%
The properties of naturalistic stimuli also stress statistical assumptions such
as the absence of collinearity among variables.
%
The lack of experimental control, however, can be alleviated by detailed
annotations that allow modeling and statistically controlling potentially
confounding variables \citep[e.g.,][]{deniz2019representation}.
%
Low-level visual features, such as brightness, and low-level auditory features,
such as root-mean square power (i.e., volume), can be automatically extracted on
a low temporal scale (e.g., per movie frame; cf.
\href{https://github.com/psychoinformatics-de/studyforrest-data-confoundsannotation
}{\url{github.com/psychoinformatics-de/studyforrest-data-confoundsannotation}}
for low-level annotations of the studyforrest project).
%
Recent advances in machine learning have led to the creation tools, such as
``pliers'' \citep{mcnamara2017developing} implemented in the neuroscout platform
\citep[\href{https://neuroscout.org/}{\url{neuroscout.org}};][]{delavega2022neuroscout},
that can automatically extract high-level features like semantics or clearly
defined object categories.
%
Such tools can replace time-consuming manual annotations or provide a
provisional scaffold that reduces manual labor for a growing number of stimulus
features.
%
However, variables that are difficult to define, hard to consistently label,
have multiple interpretations, fluctuate on longer time scales, or
subject-related variables, such as the level of engagement or felt emotions
\citep[cf.][]{lettieri2019emotionotopy, saarimaki2021naturalistic}, still defy
an automatic annotation.
%
Hence, merely assessing the confound structure of a naturalistic stimulus as a
possible candidate for a prospective model-driven analysis might become
time-consuming.
%
Moreover, a large amount of annotated features may lead to annotations that are
``hard to use'' \citep[][p. 2]{richard2019fast} or ``high-dimensional,
cumbersome models'' \citep[][p. 2]{richard2019fast} eventually resulting in a
lack of statistical power due to insufficient data samples.



\subsection{Interim summary}
%
Given the unsolved issues and current limitations, it is perhaps not surprising
that, even 20 years after the group-level findings of
\citet{bartels2004mapping}, no functional localizer based on a movie or an
auditory narrative exists that localizes high-level visual areas.
%
The most ecologically valid visual localizers currently available are
\textit{dynamic localizers} \citep[e.g.,][]{pitcher2011differential,
fox2009defining} that use blocks of short videos (each video lasting
$\approx$\unit[2-3]{s}) of scenes, faces, etc., making them well-suited for
traditional modeling procedures.

%
Even naturalistic stimuli, despite being labeled as ``naturalistic'' and
ubiquitously referred to as ``more ecologically valid'', are not strictly
``naturalistic'', but rather an approximation of real-life presented via a
screen and headphones in the laboratory.
% entertain, inform, or advertise.
Similar to traditional stimuli that have been carefully designed by researchers
to probe specific brain processes, most naturalistic stimuli used in
neuroscience have been carefully designed by professional media creators to
appeal to their target audience.
%
Film directors intentionally manipulate the viewers' attentional focus and
mental states using a variety of techniques like camera-movement, composition,
movie editing, or voice-overs \citep{brown2012cinematography,
dancyger2011film-technique, katz1991film, mercado2011filmmakers} that, when used
correctly, largely occur unnoticed.
%
For example, participants asked to spot movie cuts miss between 10\% and 50\% of
them depending on the type of cut \citep{smith2008edit}.
%
While these techniques reduce individual variation and lead to reliably
synchronized spatial-temporal responses across subjects in a large part of the
cortex \citep{hasson2008neurocinematics}, they also introduce a confounding
factor in the form of ``naturalistic stimulus statistics''.

%
Although naturalistic stimuli are intended to be inherently engaging and offer a
task-free paradigm, sustained attention is still required by participants when
``freely viewing'' a movie or ``freely listening'' to an auditory narrative,
which may become challenging over longer periods of time.
%
The occasional disengagement of single subjects may have a negligible effect on
group-average results, especially when statistics are calculated over long
stimulus intervals.
%
However, when a study aims to investigate a brain process that is expected to be
universal across humans on an individual level, a varying engagement may impair
the reliability of individual-level results across stimulus segments and
potentially mask effects of interest.
%
Nonetheless, a varying level of engagement may reflect a personal preference
towards the presented stimulus or elicit, given the low demand characteristics
\citep[cf.][]{orne1962social} of naturalistic paradigms, a more natural behavior
reflecting a personal trait.


\subsection{Estimation based on data of a reference group}

%
Given the current limitations of modeling hemodynamic responses during
naturalistic stimulation to reliably localize the \ac{ppa} in all participants,
the thesis aimed to explore a second approach to identify a functional area
based on data of naturalistic stimuli.
%
In Chapter 5, we estimated the empirical $Z$-maps acquired from the analysis of
the visual localizer in a participant by leveraging data from other
participants.
%
Our results indicate that $\approx$\unit[15]{min} of movie data sampled at
\unit{0.5}{Hz} used for functional alignment can estimate the results of the
visual localizer more accurately than an estimation procedure based on
anatomical alignment.
%
Results suggest that a \ac{fmri} scanning session using a complex naturalistic
stimulus lasting 15 to 30 minutes could serve as a functional calibration scan.
%
This calibration scan can be used to align a new subject to a common functional
space derived from data of a reference group.
%
Once aligned with the common functional space, functional data of controlled and
naturalistic paradigms can be mapped through the common model space into the new
subject's voxel space.
%
This approach enables the possibility of using a short movie to estimate the
results of various localizers that are designed to provide reliable measures in
all individuals.
%
Just presenting an engaging short movie to a new subject would allow to estimate
patterns that are observed in the normative reference group, when additional
functional scans are not feasible due to various constraints (such as scanner
availability, time constraints, financial limitations, or compliance issues).
%
Furthermore, this approach would allow for quantifying the similarity or
dissimilarity between a new subject's actual pattern and the common pattern
estimated from the normative reference.
%
In particular, our results suggest that an auditory paradigm can be used to
estimate the results of a visual paradigm.
%
Future studies should explore the performance of functional alignment in other
domains than high-visual perception.
%
It would be intriguing to investigate whether functional alignment can be
utilized to predict brain patterns that are correlated with paradigms
specifically designed to elicit brain processes not captured during passive
movie viewing, such as planning or decision-making.
%
However, future developments are necessary to advance functional alignment to a
clinical application.
%
Increased sampling rates and improved functional alignment algorithms are
required to reduce scanning time and the amount of data needed to functionally
align a higher number of voxels simultaneously.
%
Further developments that allow aligning a large number of voxels across larger
distances would be particularly beneficial for functional areas that exhibit
large interindividual variability in anatomical location, such as language
areas, or in cases of atypical topography resulting from cortical reorganization
after brain injuries.



\section{Conclusions}

%
Traditional localizer paradigms are designed to selectively elicit certain
perceptual or cognitive processes in the majority of study participants.
%
In contrast, naturalistic stimuli more closely resemble the complexity of
real-world experiences, leading to responses in multiple brain regions
simultaneously.
% focus PPA
As a proof of concept, the thesis focused on the \ac{ppa}, a high-level visual
area, to investigate the potential of a movie and its audio-description to
replace a traditional visual localizer.
%
We found that a model-driven analysis based on annotations of stimulus features
embedded in the naturalistic stimuli can yield results that are consistent with
previous studies using a visual localizer.
%
A second, model-driven approach revealed that 15 to 30 minutes of functional
scanning during movie watching can generate a sufficient amount of data to
functionally align a subject with a common functional space and estimate brain
patterns more accurately than a procedure based on anatomical alignment.
% further studies
Further studies are needed to investigate whether findings of this thesis
generalize to other high-level visual areas and other domains of brain functions.

% challenges
The thesis also highlights challenges of naturalistic stimuli.
%
Researchers should familiarize themselves with media techniques to make informed
decisions when choosing potential stimulus candidates.
% create and provide annotations
Moreover, the creation of annotations is crucial for a couple of reasons.
%
First, annotations allow to quantify the confound structure of potential
candidates.
%
Second, annotations enable model-driven analyses that may reveal which stimulus
features and brain responses are correlated, enabling future investigations to
more effectively choose an appropriate naturalistic stimulus for a given
research question or population.
%
Last, annotations allow to test physiological assumptions, address statistical
issues, and eventually adapt traditional analysis approaches and foster the
development of new analysis methods.

%% data sharing
To address the challenge of individually varying levels of engagement due to a
lack of a task, \ac{fmri} scanning sessions should be accompanied with \ac{eeg},
eye-tracking, physiological recordings, such as skin conductance response and
heart rate, and followed up with self-reports to evaluate a participant's
alertness and audio track audibility within the noisy scanner.
%
These additional recordings may increase expenditures but also the number of use
cases of a dataset.
%
Given the versatility naturalistic stimuli, researchers who consider running an
experiment that employs a naturalistic stimulus, should also consider eventually
sharing the data with the scientific community.
% consider sharing
Creating a dataset with the intention of sharing it promotes best practices of
collecting, documenting, storing, and processing data, and ultimately promotes a
collaborative effort to advance the field.

%% localizers
With further investigations and refinements of analysis methods, it may be
possible to use only one naturalistic stimulus to assess multiple domains of
brain functions on an individual level under more ecological conditions.
%
It is important to note that naturalistic stimuli should not necessarily be
expected to yield identical results to traditional paradigms.
%
Traditional localizers aim to minimize inter-subject variability and reliably
localize functional areas in all healthy individuals.
%
The lack of demand characteristics of naturalistic stimuli presents challenges
when investigating brain responses assumed to be universal across all humans.
%
However, naturalistic paradigms allow participants to behave more genuinely
during an experiment, potentially revealing individual differences in perception
and cognition that may also be correlated with genuine behavior in the real
world.
%
Therefore, naturalistic stimuli should not seek to replace traditional paradigms
and it is important for researchers to acknowledge the strengths and limitations
of both paradigms.



\begin{comment}

\pagebreak

\section{Some backups}


\subsection{auditory PPA is in anterior visual PPA}

%
However, the usability of a purely auditory paradigm to localize the \ac{ppa} as
it is defined by a visual paradigm might be limited by our findings that suggest
that increased hemodynamic activity during auditory stimulation is spatially
restricted to the anterior \ac{ppa}.
%
Our results provide further evidence to studies in the field of
visual perception that suggest that the \ac{ppa} can be divided into
functionally subregions that are coactivate during the perception of visual
scenes but process different stimulus features
\citep{aminoff2007parahippocampal, baldassano2013differential}.
%
On the other hand, results encourage future studies to investigate response in
the parahippocampal region to auditory stimuli under more controlled conditions.
%
In case the controlled paradigm reveals less variation in reliability across
participants, future studies employing naturalistic stimuli could then
investigate factors that might have influenced reliability of individual results
in \citet{haeusler2022processing}:
%
a) stimulus-related factors like the number available events that can be modeled
and contrasted per stimulus segment, or the general confound structure,
%
b) modeling-related factors like the assumed shape of the hemodynamic response
%
c) subject-specific factors like alertness or engagement over the course of the
experiment.



\subsection{Brain \& behavior: "fingerprints"}
%
Maybe might be stable individual differences in cognitive tendencies or
cognitive abilities like susceptibility / predisposition [?] to attend to, [or]
recognize [or process] auditory spatial information.
% Kanai
In case the pattern is stable within individual subjects / is ``highly
consistent across different sessions [or experiments], then they are
characteristics of the individuals and may reflect differences in their brain
function'' \citep{kanai2011structural} [on structural diffences].
%
``Individual differences in topology (i.e. location, size, shape of functional
areas) and the activity within functional areas can also be considered to be
interesting cases of inter-individual variability to understand the neural basis
of human cognition and behavior, brain-phenotype relationships'', and ``present
useful phenotypes or biomarkers \citep{glasser2016multi,
vanhorn2008individual}''


\subsubsection{Brain \& behavior: example studies}

\todo[inline]{cf. also \citep{gordon2017individual, gordon2017precision}}
%
For example, \citet{kong2019spatial} suggested based on resting-state functional
connectivity measures ``that individual-specific network topography (i.e.,
location and spatial arrangement) might serve as a fingerprint of human behavior
that can predict behavioral phenotypes across cognition, personality, and
emotion'' \citep{kong2019spatial} [with modest accuary, comparable to previous
reports predicting phenotypes based on connectivity strength].

%
\citep{bijsterbosch2018relationship}'s ``results indicate that spatial variation
in the topography of functional regions across individuals is strongly
associated with behaviour'' \citep{bijsterbosch2018relationship}.
%
\citet{bijsterbosch2018relationship} found ``that the spatial arrangement of
functional regions is strongly predictive of non-imaging measures of behavior
and lifestyle'' [however shape \& exact location of brain regions interacted
strongly with  modeling of brain connectivity].
%
\citet{bijsterbosch2018relationship} found ``that individual differences in the
size, shape and exact position of the brain regions [as identified by
resting-state functional connectivity measures] was strongly linked to
individual differences in behavioral tests and questionnaires [including
intelligence, life satisfaction, drug use and aggression problems]''
\citep{bijsterbosch2018relationship}.

%
``The variations in spatial topographical features captured a more direct and
unique representation of subject variability than temporal correlations between
regions defined by group parcellation approaches (coupling).
%
Hence, the cross-subject information represented in commonly adopted
'connectivity fingerprints' could largely reflect spatial variability in the
location of functional regions across individuals, rather than variability in
coupling strength (at least for methods that directly map group-level
parcellations onto individual data)'' \citep{bijsterbosch2018relationship}.

%
``Depending on the employed spatial alignment algorithm and the amount of
removed spatial intersubject variability, the degree to which spatial
information may influence FC estimates possibly varies considerably across
studies.
%
In recent years, significant efforts have gone into the methods that more
accurately estimate the spatial location of functional parcels in individual
subjects [Chong et al., 2017; Glasser et al., 2016; Gordon et al., 2016; Hacker
et al., 2013; Harrison et al., 2015; Varoquaux et al., 2011; Wang et al., 2015],
and into advanced hyperalignment approaches [Chen et al., 2015; Guntupalli et
al., 2016; Guntupalli and Haxby, 2017]'' \citep{bijsterbosch2018relationship}.



\subsection{Dynamic localizers}
%
``Previous reports showing significant differences between topographies
estimated by static and dynamic localizers, especially in superior temporal and
frontal cortices [Fox et al., 2009; Pitcher et al., 2011]''
\citep{jiahui2022cross}.
%
``For all categories, the dynamic localizer elicited stronger and broader
category-selective activations than the static localizer''
\citep{jiahui2022cross}.
%
``For example, for the face-selective topographies, the dynamic localizer
activated more areas than the static localizer (e.g., in superior temporal and
frontal cortices)'' \citep{jiahui2022cross}.
%
``The searchlight analysis showed that the dynamic localizer had higher
reliabilities across the cortex, especially in regions that were selectively
responsive to the target category'' \citep{jiahui2022cross}.
%
``The low correlations were not because the prediction method failed but
reflected the difference in the topographies activated by different types of
localizers.'' \citep{jiahui2022cross}.


\end{comment}
