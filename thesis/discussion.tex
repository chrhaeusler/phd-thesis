\todo[inline]{it doesn't matter where I place the part on "open science": it's
an excursion \& doesn't fit in anywhere perfectly; at the moment it comes
before going into details about naturalistic stimuli as localizer}



\todo[inline]{delete subsection(s)}


Human brain mapping studies have traditionally averaged \ac{fmri} data across
participants.
%
However, data need to be assessed on the level of individual persons in order to
advance the field towards a clinical application.
% functional localizer
An established method to characterize the topography (i.e. the location, size,
and shape) of functional areas on the level of individuals are functional
localizers.
% contra localizers
However, traditional localizer paradigms employ selectively sampled, tightly
controlled stimuli, rely heavily on a participant's compliance, and can usually
map just one domain of brain functions.


\subsection{The usual rant about localizers}

\todo[inline]{keep it pretty short! cf. general intro \& SRM part: localizer is
standard, but problematic; it's reliable, but what is the construct?
ecologically validity?  boring, compliance, inefficient; therefor, naturalistic
stimulus)}


\subsection{Functional localization via naturalistic stimuli as functional localizer?}

\todo[inline]{prime that annotations are bottleneck and modeling
is "prohibitively" difficult? imo, it's not necessary}

\todo[inline]{maybe, cite \citet{bartels2004mapping} again}

% movies & narratives
Naturalistic stimuli like movies and auditory narratives \citep[cf.][for
reviews]{jaaskelainen2021movies, jaaskelainen2020neural} provide a time-locked
event structure that samples a broad range of brain states ranging from
low-level perception (e.g., luminance) to high-level cognition (e.g., social
cognition).
%
A localizer based on naturalistic stimuli could
%
a) provide higher external validity because they resemble how we perceive the
real world outside of the laboratory during everyday life more close and,
%
b) potentially map a variety of brain functions.

% goal of thesis
Therefore, the goal of this thesis was---while following the principles of open,
transparent, and reproducible science---to explore whether a movie and the
movie's audio-description could, in principle, substitute a traditional
localizer paradigm.
% PPA as proof of concept
As a proof of concept, we focused on the \ac{ppa}, a ``classic'' higher visual
area.
%
The \ac{ppa} exhibits increased hemodynamic activity when participants view
photos of landscapes, buildings or landmarks, compared to, e.g., photos of faces
or tools \citep[e.g.,][for reviews]{epstein2014neural, aminoff2013role}.
%
Moreover, results of \citep{aziz2008modulation} that compared hemodynamic
activity levels in the \ac{ppa} correlated with different categories presented
in spoken sentences suggest that activity level of the \ac{ppa} is also
modulated by semantic scene-related information.

%
Hence, we assessed the potential of both the movie and the audio-description
to substitute a visual localizer two ways.
% direct modeling
First, we adapted the method used to analyze data from traditional localizer
paradigms to the analysis of data from the two naturalistic paradigms:
%
hemodynamic responses correlating with the temporal structure of annotated
stimulus features \citep[cf.][]{haeusler2016cutanno, haeusler2021speechanno}
were modeled in order to create \ac{glm} $t$-contrasts that aimed at localizing
the \ac{ppa}.
% estimation
Second, we applied functional alignment procedure as a new method in order to
estimate results from the visual localizer \citep[cf.][]{sengupta2016extension},
movie and audio-description \citep[cf.][]{haeusler2022processing} in one
participant from results of participants in a reference group.


\pagebreak


\section{Open Science}

\todo[inline]{"open-source", "open data", "open science", "open access" are
defined in intro?}

\todo[inline]{I absolutely do not like it but provide an overview in the sense
of "I will first describe what was done and then evaluate pro's \& con's"?}

%
An overarching goal of this dissertation was to meet both the requirements of
open, shared, accessible, and transparent science \citep[cf.][]{watson2015will,
fecher2014open} as well as the requirements of a reproducible and replicable
research project. This goal included to a) utilize open data and open-source
software, and b) publish data, materials, code, and results openly available.


\subsection{Utilizing open data and open-source software}

%
The first subgoal was to use open data, open materials, and open-source
software.
%
The current thesis capitalized on publicly available
%
\ac{fmri} data \citep{hanke2014audiomovie, hanke2016simultaneous,
sengupta2016extension},
%
subject-specific \acp{roi} \citep{sengupta2016extension} and
%
stimulus annotations \citep{haeusler2016cutanno}
%
that are part of the studyforrest project
(\href{www.studyforrest.org}{\url{studyforrest.org}}).
%
In order to avoid creating an ``artificial paywall'' for rerunning the analyses
on the originally open data, all analyses are implemented in open-source
software packages\todo{FSL is not OS?}.
%
We benefited from established free software like
%
Python and
%
FSL \citep[\href{https://www.fmrib.ox.ac.uk/fsl}{FMRIB's Software
Library;}][]{smith2004fsl} that have been developed and debugged over years by
an collaborative effort,
%
but also from scientific software packages like
%
DataLad
\citep[\href{www.datalad.org}{\url{datalad.org}};][]{halchenko2021datalad} or
%
BrainIAK
\citep[\href{https://brainiak.org}{\url{brainiak.org}};][]{kumar2020brainiak,
kumar2020brainiaktutorial}
%
that emerged recently.

%
Preexisting software packages, data, and results from previous analyses enabled
us shift time and resources from software development and data collection to
subsequent stages of the project.
%
However, a too often neglected aspect of open data is that open data does not
exempt from the duty to familiarize yourself with the data.
% check the data
Dataset consumers need to assume that everything that is not explicitly
stated in the description of a dataset has not been considered by a dataset's
creators.
% laugh with many, don't trust any
Even if the data a from a renowned source, researchers should consider
themselves to be obliged to test and validate a dataset's quality according to
their standards and specific use cases.
%
Standards (quality, formats, parameters) and open sciences practices (e.g.,
documenting) might vary across scientific field, or within scientific fields
depending on a working group's knowledge and rigor.
%
Choices made during data collection and preprocessing -- despite being
state-of-the-art at the time of being published -- might not be optimal for
every use case or made obsolete by more advanced methods.

%
Moreover, the extent of raw data and decisions made during data collection,
preprocessing, and further analyses might influence the subsequently performed
analyses.
%
For example, we and \citet{sengupta2016extension} chose the \ac{ppa} among
possible candidates of ``scene-selective'' regions because it was the first area
to be discovered and is the most reliably activated region across studies that
investigate visual scene perception.
%
Like the \ac{ppa}, the \ac{rsc} and \ac{opa} have repeatedly shown increased
hemodynamic activity in studies investigating visual spatial perception and
navigation \citep{chrastil2018heterogeneity, bettencourt2013role,
dilks2013occipital, epstein2019scene}.
%
We assumed that results (at least of the audio-visual stimulus) could also yield
significant clusters in the \ac{rsc} and \ac{opa} but did not explicitly
hypothesize that fact.
%
Apart from the PPA, results show significantly increased activity in the
\ac{rsc} \ac{opa} and are an incentive for further studies.
% \citep[cf. algorithmic procedure in, e.g.,][]{julian2012algorithmic}.
However, in case of preexisting \acp{roi} of \citep{sengupta2016extension}, one
would have to replicate the non-automatized procedure of
\citep{sengupta2016extension}.
%
A point that also highlights that some stages or results may rely on human
decisions that cannot be replicated complicating updating or the extension of
datasets.
% pro & contra: opportunity costs
Hence, when considering using open data, researchers need to weigh the costs and
benefits of one path (e.g., preprocessing the same data differently than the
preprocessing performed as part of an open dataset) relative to an alternative
path (e.g., using the preprocessed data and performing new analyses), and choose
the path with the greater net return.



\subsection{Publishing data, materials, code, and results openly available}

\todo[inline]{speech anno paper is on github; ppa paper is on github but not
public; thesis is not on github}

%
%The annotation comprises, e.g., time-stamps of phonemes, words and sentences of
%all speakers, a grammatical tagging, and an annotation of syntactic
%dependencies and semantics.

%
The second subgoal was to publish data, materials, and results openly
accessible.
%
For example, the content of annotation of speech \citep{haeusler2021speechanno}
goes beyond what was necessary to perform the analyses in
\citet{haeusler2022processing} and serves as an extension of the studyforrest
dataset.
%
Consequently, the annotation widens the ``annotation bottleneck''
\citep{aliko2020naturalistic} of two naturalistic stimuli, and provides a
headstart for independent research that wish to model hemodynamic brain
responses that are correlated with different aspects of spoken language.
%
Moreover, in order to facilitate transparency, data and custom code generated
over the course of this dissertation are version-controlled, and changes made to
data and code were protocolled and documented.
%
Lastly, in order to facilitate reproducibility, processing steps ranging from
downloading input data to plotting figures are implemented in custom code that
can be rerun from the command line.

% contra
Creating data, materials, and code to be published requires a considerable about
of time and effort.
%
A dataset's content needs to be collected, described, stored and published in a
manner that attracts re-use by third parties.
%
Dataset creators need to anticipate use cases, collect the data according to
best practices, convert data into a standardized format (considering, e.g.,
naming conventions, folder structure, separating raw from analyzed data), and
create metadata.
%
Analyses pipelines need to be designed and tested to automatically and
reliably rerun the history of a dataset's stages.
%
% publication: findable, accessible, interoperable, reusable
Especially when data are supposed to be published, a researcher needs consider
legal issues (e.g. intellectual property rights, use license, statement of
agreement and anonymization of participant data,), facilitate discovery by
humans and web bots (e.g., via extensive description and machine-readable
metadata), and ensure long-term curation and accessibility at an appropriate
data host.

% pro
However, creating a dataset that is supposed to be published provides immediate
benefits to the dataset's creator.
%
Documenting every step and commenting on pros and cons of alternative procedural
paths lead[s] to better understanding.
%
Version-controlling steps diminishes the risk of look-ahead bias.
%
Extensively tracking and documenting the state and development of data and code
from the start to the final results can also be considered as a form of a lab
protocol that contains structured information for writing the corresponding
scientific article.
%
Hence, creating a dataset supposed to be published supports meticulous working
methods and good scientific practices.


\todo[inline]{summarize following paragraph and merge into above paragraph}
%
From the perspective of readers, all that bullshit helps independent researchers
to gain a better understanding from documented step-by-step workflow than the
often limited coverage of a regular publication's methods section, validate a
study's results, and extend published code to replicate findings in prospective
studies.
% readers get a better understanding
``Transparent and complete reporting of all facets of a study allows a critical
reader to evaluate the work and fully understand its strengths and limitations
%
and it facilitates subsequent research efforts by other investigators, who can
exactly follow (or carefully manipulate) each aspect of a study''
\citep{nichols2017best}.




\paragraph{Perceived dread: scooping}

\todo[inline]{probably, shift that (heavily shortened) into "personal
assessment"; à la: allay worries about being scooped by creating incentives}

%
Publishing data is associated with the risk of being ``scooped''
\citep[cf.][]{laine2017afraid}, i.e. that other working groups are using the
same data for a similar research question at the same time.
%
There is the concern that someone else might ``claim priority, usually through
publishing, to a research idea or result you yourself have been working on''
\citep{laine2017afraid}.
%
This risk is aggravated in case of early career scientists that created and
curate published datasets, pre-registered studies based on open data, or have to
stick to inflexible project plans \citep[cf.][]{toribio2021early}.

%
In case of a dataset creator's fear of being superseded / outrun, ``concerns can
be alleviated by delaying the sharing or using a data-sharing repository with an
embargo period'' \citep{nichols2017best}.



\pagebreak


\subsection{Personal assessment}

\todo[inline]{merge subsection "Personal assessment" into paragraphs above;
should be possible and circumvents a pretty personal story telling}


\subsubsection{Utilizing open data and open-source software}
%
Being able to use already existing data was convenient because not dealing with
ethic committee, participants' consent, anonymization, legal issues.
%
Especially, Covid-Pandemic has impressively shown that collecting data based on
human subjects can go dormant for almost 1.5 years.
%
Strictly, it was not "3rd party data" for my, because I was (somewhat) involved
in the data collection process, and hence somewhat familiar with the data
(provenience, location, quality, accessibility, storage format, performed
preprocessing steps).

DataLad \citet{halchenko2021datalad} is the technical foundation.
%
DataLad provided the functionality of managing provenance, distribution, and
version-control of code and data in order to allow the reproducibility of
current results and to facilitate the replicability of findings on other
datasets.


%
Know your data: plot, test, and check for errors.
%
Assume that everything that is not mentioned has not been considered.
%
It is too easy to switch the focus from the data collection, quality assessment,
and exploratory data analysis to "just pushing the data through the analysis
pipeline".



\subsubsection{Publishing data, materials, code, and results openly available}

%
Following the practices of open and reproducible science was not mandatory for
submitting the thesis but required additional work and time.
%
Standards to follow are not yet fully established and corresponding software
tools are still emerging / in a developmental state.
%
Since the best practices are not yet part of a graduate or PhD curriculum,
learning about the principles and standards and applying the corresponding
procedures and necessary tools was based on self-initiative and self-learning.

Automating recurring tasks gives yourself the possibility of reusing
certain data, code, documents, etc. in the future.

%
Automatization of downloading, processing \& analyzing, summarizing
results \& creating figures takes the most time compared to its immediate
benefit:
%
easier tracking bugs and errors, higher confidence in one's own work and the
reliability of results, or reuse of code in later projects.



\paragraph{For example the annotation of speech}


Trade-off that needed to be balanced between
%
a) doing the ``mere minimum'', and
%
b) putting time and effort in creating additional information that to provide a
sound/substantial groundwork for potential use-cases.

%
As in human language in general, an annotation of speech will always contain
ambiguities.
%
Anything that is not 100\% automatized (any human judgement and decision) is not
100\% reproducible, hard to extend, sadly because automatization takes a long
time for some stuff or is not possible for some stuff.
%
Any further processing step might be based on a decision that might not match
the requirement of a specific use case.
%
For example, an annotation of semantics might be based on a current state-of-the
art language model that might be superseded by future language models.


\pagebreak


\subsection{Interim summary: it needs to be done anyway}

\todo[inline]{cf. general introduction}

%
Open science in order to tackle the issue if ``reproducibility crisis'' or
``replication crisis''.

\paragraph{Create standards}
%
The problem is that standards are still emerging, they change, software tools
are in development, changes, functionality gets added constantly.
%
Generally the "landscape is moving too much" still; today's standards, tools
might be outdated quickly.

%
``OS still requires the establishment of clear guidelines for transparency and
openness of research at the international level.
%
Examples for guidelines for OA publishing [Nosek et al., 2015; Schiltz, 2018],
and collaborations [Gold et al., 2019] are already existing, and their use
should be promoted by governments and funding agencies, as well as integrated in
the training of ECRs by academic institutions.
%
Organizations and/or regulators in charge of overviewing the open scholarly
system need to be established [cf. Nicholas et al., 2019, 2020]''
\citep{toribio2021early}.


\paragraph{Educate}

% incentives like ``professional recognition or the allocation of extra funding
% [Kidwell et al., 2016; Fecher et al., 2015; Ali-Khan et al., 2018];
% Funding agencies already require publication of findings in OA schemes and
% data-sharing plans [Neylon, 2017]'' \citep{toribio2021early}.

In my opinion, risk, benefits, and practices of OS should be introduced trained
in the curriculum of undergraduates programs.
%
Hands-on training would not only increase the knowledge of OS practices but
familiarize user with emerging software tools.
%
Instead of compulsory requirements from funders, which might only lead
researchers to show minimal compliance [Neylon, 2017], more incentives to
conduct open science project needs to be established.



\paragraph{Create incentives (not just "gambling")}
%
Immediate benefits do not outweigh the required time and effort.
%
Open access publications might receive more citations than paywalled
publications [\citep{piwowar2018state}], open data might get cited, and promote
new collaborations [\citep{popkin2019data}].
%
Publishing a dataset with an assigned DOI might get re-used and cited in another
study.

``greater potential impact of a work when it may be cited not just for its
scientific findings but also when its data is reused in other works''
\citep{nichols2017best}.

% no incentive
``current incentives do not justify spending large amounts of time preparing
data for sharing, as institutional promotion panels or grant reviewers currently
do not adequately reward such efforts'' \citep{nichols2017best}.
%
``the weight that open science currently has for researchers' career advancement
is small'' \citep{toribio2021early}.
%
``investing additional effort in making research open (i.e., transparent and
reproducible) is unrewarded [Nicholas et al., 2017], such as conducting
replication studies that might not be considered for publication in high-impact
journals'' \citep{toribio2021early}.

%
Currently, playing be the ``old rules'' is the ``smarter way'' than gambling
getting cited when data or code get re-used, imo.

\todo[inline]{80\% of PhD students leave science anyway and do not give a shit
in the first place in case they know already}


\paragraph{Perceived dread: scooping}

\todo[inline]{probably, shift that (heavily shortened) into "personal
assessment"; à la: allay worries about being scooped by creating incentives}

%
Publishing data is associated with the risk of being ``scooped''
\citep[cf.][]{laine2017afraid}, i.e. that other working groups are using the
same data for a similar research question at the same time.
%
There is the concern that someone else might ``claim priority, usually through
publishing, to a research idea or result you yourself have been working on''
\citep{laine2017afraid}.
%
This risk is aggravated in case of early career scientists that created and
curate published datasets, pre-registered studies based on open data, or have to
stick to inflexible project plans \citep[cf.][]{toribio2021early}.

%
In case of a dataset creator's fear of being superseded / outrun, ``concerns can
be alleviated by delaying the sharing or using a data-sharing repository with an
embargo period'' \citep{nichols2017best}.


\paragraph{Reap benefits}

%
Open sciences makes researchers accountable to collect, document, process and
store data and materials according to best practices.
%
Published data and analysis pipelines allow external persons to check the data
and analyses for undiscovered errors, and replicate the results step by step.
%
Varying parameters and running different statistics on the data allows
inspection of robustness of results.
%
Benefits are increased robustness and reliability of science when all steps are
openly documented and data are openly available.

%
Multiple datasets can be combined to perform unanticipated use cases, and
extensively and openly documented results of multiple studies facilitate
performing meta-analyses to strengthen the claims of individual studies.
%
Open science promises increased efficiency (time and financial expense) of
making scientific progress, make advance, and promotes innovation.

%
Open access journals provides low-cost access to information.
%
Open transparent science is the way to make knowledge and technologies
widely accessible.
%
Increase reproducibility of study results and replicability of scientific
findings while increasing trust of the public into scientific process and its
results.



\pagebreak



\section{Naturalistic stimuli for functional localization?}

\todo[inline]{everything in line with Intro ("aims of thesis", "specific aims
and objectives"?) and discussion above ("The usual rant about localizers?)}

%
The \ac{ppa} is traditionally identified by contrasting hemodynamic responses to
blocks of pictures of scenes or landscapes to, e.g., blocks of pictures of tools
or faces.
%
Although the exact definition of the \ac{ppa} depends on the type of stimuli,
the task, and the $t$-contrast, the traditional localizer approach can reliably
delineate the \ac{ppa} bilaterally in a large proportion of subjects
\citep[e.g.,][]{zhen2017quantifying}.
%
For example, \citet{sengupta2016extension} successfully delineated the
left-hemispheric \ac{ppa} in 12 of 14 subjects and right-hemispheric \ac{ppa} in
14 of 14 subjects based on localizer data.
%
However, the highly controlled nature of the employed stimuli raises the
question whether the spatial localization of the isolated psychological
construct of "scene perception" generalizes to more ecological settings outside
of the laboratory (the neuronal correlate of the perception of black-and-white
landscape pictures).
%
Hence, we employed two naturalistic stimuli, a movie and its audio-description
that provides a continuous, complex, immersive, task-free paradigm that more
closely resembles our natural dynamic environment than traditional experimental
paradigms in order to assess the generalizability of inferences drawn from
highly controlled experiments to more naturalistic stimulation.



\subsection{Functional localization via modeling hemodynamic responses}

\todo[inline]{mih: worth stating again somewhere in the discussion that the
studyforrest dataset is not for this (diverse), but it is a small dataset, which
limits the generality}

% study in one sentence
In \citet{haeusler2022processing}, we explored whether an audio-visual
naturalistic stimulus and an exclusively auditory naturalistic stimulus could be
used in order to localize the \ac{ppa} as it was previously identified in the
same set of participants by a traditional block-design functional localizer that
employed static pictures \citep{sengupta2016extension}.


\paragraph{Method}
% stress similarity to localizer approach
Adopting the approach of traditional localizer, we modeled hemodynamic responses
to events in two naturalistic stimuli in order to create $t$-contrasts that
aimed to localize the \ac{ppa}.
% AV operationalization
For the model-based mass-univariate statistical analysis (i.e. \ac{glm}) of the
movie's data, we operationalized the perception of visual spatial information
based on an annotation of movie cuts and depicted locations
\citep{haeusler2016cutanno}.
% AD operationalization
For the \ac{glm} of the audio-description's data, we extended the annotation of
speech that we created and validated in \citep{haeusler2021speechanno} by
further annotating nouns that the narrator uses to describe the movie's absent
visual content.


\paragraph{Results}
% group results
On a group-average level, results demonstrate that increased activation in the
\ac{ppa} during the perception of static pictures generalizes to the perception
of spatial information embedded in an audio-visual movie and exclusively
auditory naturalistic stimulus \citep{haeusler2022processing}.
% glm analysis
Further, results show that a model-driven \ac{glm} analysis based on a
naturalistic stimulus' annotation can be used to replicate findings of studies
that employed traditional paradigms, and add evidence
\citep[cf.][]{bartels2004mapping} that functional specialization of cortical
areas is preserved during naturalistic stimulation.
% individual AD
On an individual level, the analysis of the movie yielded bilateral clusters of
increased hemodynamic activity in the \ac{ppa} of five participants and a
unilateral cluster in seven participants, whereas the analysis of the
audio-description revealed bilateral clusters in nine participants and one
unilateral cluster in one participant.
% conclusion
Results suggest that a movie and a exclusively auditory naturalistic stimulus
could potentially substitute a visual localizer as a diagnostic procedure to
assess brain functions in individual persons.


\paragraph{Contra: auditory response is different; sometime not reliable}

\todo[inline]{however: non-reliability might be reliable in some subjects}
%
However, the usability of a purely auditory paradigm to localize the \ac{ppa} as
it is defined by a visual paradigm might be limited by our findings that suggest
that increased hemodynamic activity during auditory stimulation is spatially
restricted to the anterior \ac{ppa}.
%
On the one hand, our results provide further evidence to studies in the field of
visual perception that suggest that the \ac{ppa} can be divided into
functionally subregions that are coactivate during the perception of visual
scenes but process different stimulus features
\citep{aminoff2007parahippocampal, baldassano2013differential}.
%
On the other hand, results encourage future studies to investigate response in
the parahippocampal region to auditory stimuli under more controlled conditions.
%
In case the controlled paradigm reveals less variation in reliability across
participants, future studies employing naturalistic stimuli could then
investigate factors that might have influenced reliability of individual results
in \citet{haeusler2022processing}:
%
a) stimulus-related factors like the number available events that can be modeled
and contrasted per stimulus segment, or the general confound structure,
%
b) modeling-related factors like the assumed shape of the hemodynamic response
function [?], or
%
c) subject-specific factors like alertness or engagement over the course of the
experiment.



\subsection{Interim summary \& future studies}

\todo[inline]{I assume this part will be a pretty personal opinion}

\todo[inline]{check the papers that claim "prohibitively difficult" (cf. general
intro) and state the point again differently phrased}

In summary, modeling hemodynamic responses during naturalistic stimulation to
investigate neural correlates of specific psychological constructs under more
ecologically valid conditions is challenging for a couple of reasons:
%
a) naturalistic stimuli offer a continuous, time-locked and complex stimulation
at the expense of a confounded feature space, which is why
%
b) there is no consensus on how to adopt model-based analyses from traditional
block or event-related experimental designs to naturalistic stimuli [attentional
focus, fMRI adaption, transient vs. non-transient responses etc.], which is hard
to establish
%
c) because creating and assessing the suitability of different model-based
analyses requires the feature space to be extensively annotated which is often
still tediously and time-consuming.

%
Consequently, 20 years after group-level findings of \citep{bartels2004mapping}
and despite the rising popularity of naturalistic stimuli in neuroscience no
localizer exists that is based on a movie or an auditory narrative.
%
Probably, the most ecologically valid localizers today are so called
\textit{dynamic} localizers \citep[e.g.,][]{pitcher2011differential,
fox2009defining}:
%
dynamic localizers employ blocks of short videos (each video lasting
$\approx$\unit[2-3]{s}) of scenes, faces etc., and lend themselves conveniently
to traditional modeling procedures.
%
However, advances in machine learning promise to increase the number of stimulus
features that can---at least preliminarily---be annotated automatically.
\citep[cf., for example,
\href{https://neuroscout.org/}{\url{neuroscout.org}};][]{delavega2022neuroscout}.
%
After all, easing the annotation bottleneck of naturalistic stimuli is probably
the biggest prerequisite to further investigate methodological issues, adapt
traditional and develop new methods, and evaluate their appropriateness to draw
valid inferences from naturalistic stimuli.



\subsection{Functional localization via estimation from reference group}

\todo[inline]{Write when SRM part is finished; (re)state goals explicitly}

%
Results from \citet{haeusler2022processing} suggest that the movie as well as
the audio-description sample hemodynamic responses that correlate with the
occurrence of spatial information.
%
Therefor, we did the following ...

% goal 1: new procedure
We estimated results of a dedicated localizer \citep{sengupta2016extension} via
functional alignment from results of a reference group.
% the problem
Considering practical and monetary constraints in a clinical context, a paradigm
lasting 90 to 120 minutes is inappropriate for even an extensive individual
diagnostic procedure, we also assessed the relationship between length of
naturalistic stimulation used to align the test participant to the fixed
\ac{cfs} and the estimation performance.



\subsection{Interim summary and future studies}

\todo[inline]{This topic is only touched in the SRM study's discussion;
probably, it is better to discuss it here more than in the SRM part}

\todo[inline]{Following are some "templates" outlining the general idea}

% examples of probabilistic atlasses: \citet{rosenke2021probabilistic}:
% Cortical atlases have been developed, which allow localization of visual areas
% ``in new subjects by leveraging ROI data from an independent set of typical
% participants: Frost and Goebel 2012;
% ventral temporal cortex (VTC) category selectivity: Julian et al. 2012,
% Zhen et al. 2017, Weiner et al. 2018; visual field maps: Benson et al. 2012,
% Benson and Winawer 2018; Wang et al. 2015''.


\subsubsection{Problem space}

%
``Identifying all of the currently known topographic regions of the human visual
system requires multiple scanning sessions'' \citep{wang2015probabilistic}.
%
``Given the expense and availability of fMRI, this is not always practical''
\citep{wang2015probabilistic}.
%
``Our approach has the potential to estimate an unlimited variety of functional
topographies at the individual level based on the responses to a single
naturalistic, dynamic stimulus'' \citep{jiahui2020predicting}.


\subsubsection{Database}

%
``A normative database of participants who were scanned during movie viewing and
during functional localizers for different perceptual and cognitive functions
would serve as a reference'' \citep{jiahui2020predicting}.
%
``There are numerous other functional localizers in other perceptual and
cognitive domains, such as simple visual motion, biological motion, tonotopy,
voice perception, music perception, language, calculations, working memory, and
theory of mind'' \citep{jiahui2020predicting}.

%
``A database from a normative group could allow researchers to estimate new
subjects' functional topographies by collecting only a movie-viewing data set
and then deriving the individualized topographies with the normative database''
\citep{jiahui2020predicting}.
%
The database ``may prove especially useful for predicting functional patterns in
case no localizer data are available, saving scanning time and expenses''
\citep{rosenke2021probabilistic}.


\subsubsection{Calibration}
%
A naturalistic stimulus like a move or audio-description could be used to align
a test subject to a \ac{cfs} created from data of a normative reference group.
%
Naturalistic stimuli ``engage in parallel multiple neural systems for vision,
audition, language, person perception, social cognition, and other functions''
\citep{jiahui2020predicting} and offer higher generalizability [and provide
higher validity?] of transformations matrices.



\subsubsection{Application: estimation}

%
Once a valid alignment is established, known functional properties of the
(normative) reference can then be projected into the respective individual voxel
space by mapping a variety $Z$-maps created from a variety of $t$-contrast from
a normative reference group onto an individual subjects and thus potentially
substitute a variety of localizers.
%
``A new subject's functional topographies could be estimated based only on that
subject's movie data and other subjects' localizer data from the normative
database that could be projected into that subject's cortical anatomy using
hyperalignment transformation matrices derived from movie data and could replace
tedious functional localizers with an engaging movie''
\citep{jiahui2020predicting}.

%
``Investigators would need to scan their participants only during movie viewing
and a wide range of idiosyncratic functional topographies could then be
estimated individually based on localizer data projected from the brains in the
normative sample into the new participants' cortical anatomies''
\citep{jiahui2020predicting}.
%
``Functional topographies could be mapped from a database containing a wide
range of perceptual and cognitive functions to new subjects based only on fMRI
data collected while watching an engaging, naturalistic stimulus and other
subjects' localizer data from a normative sample'' \citep{jiahui2020predicting}.

%
''Because naturalistic movies include people, human actions, conversations,
social interactions, background music etc., we predict that hyperalignment
transformation matrices based on these movies also will work for localizers of
functional topographies for audition, language, and social cognition''
\citep{jiahui2020predicting}.
%
``From a single movie dataset multiple functional topographies can be estimated
\citep{guntupalli2016model}, whereas different localizers are typically required
to map different functional topographies, making a thorough mapping of selective
topographies time-consuming and inefficient'' \citep{jiahui2020predicting}.


\subsubsection{Application: deviation}

\todo[inline]{cf. SRM discussion: quantify the deviation from the norm vs.
predict deviant pattern?}

\todo[inline]{\citet{silva2018challenges, szaflarski2017practice}}

%
That reference would enable an qualitative and quantitative description of an
individual's brain function with respect to such a norm, and consequently
progress the field towards neuroimaging studies of individual differences that
more closely resemble their psychological counterparts.


\paragraph{Clinical application?}

\todo[inline]{cf. general introduction}

\todo[inline]{Maybe, reduced to one sentence and just state in in the general
conclusion?}

\todo[inline]{\citet{silva2018challenges, szaflarski2017practice}}

``In the clinical context, fMRI plays an important role for planning surgery in
patients with tumors or epilepsies, as it aids the understanding of which parts
of the brain need to be spared in order to preserve sensory, motor or cognitive
abilities'' \citep{wegrzyn2018thought}.


\paragraph{Language lateralization}

\todo[inline]{I abandoned the idea to come up with language area asymmetry at
least in the SRM study; the problem in case of prediction is that most
interesting are cases of atypical language lateralization (problem for models,
and ROIs and searchlight spheres; templates from papers using \ac{fmri} to
localize language areas are outsourced to separate file}

%
For example \ac{fmri} could be used as an noninvasive alternative to map
language areas and potentially assess lateralization (or hemispheric asymmetry)
of functional brain topography related to language (sub)functions, in order to
guide pre- and perioperative assessment of neurosurgery, e.g., in case of
epilepsy.



\section{Conclusion}

\todo[inline]{Somehow manage to combine open science and naturalistic stuff?}

\todo[inline]{literature says it is impossible (but Alexander Hut) but how
"prohibitive" is it? How naive was it to do it? What did take the most time?}

%
Naturalistic stimuli are not a panacea but traditional paradigms and
naturalistic paradigms should be used in tandem / reciprocally to generate new
hypotheses and progress our understanding of the brain.
%
''Some high-level cognitive processes, such as calculation, working memory, and
logical reasoning, may be less well sampled by movie viewing, and further work
is necessary to test whether hyperalignment based on movie-viewing data can be
used to estimate topographies for these other domains of high-level cognition.
'' \citep{jiahui2020predicting}.
%
Challenging data data analysis, but create \& share annotation.
%
Audio-description lacks visual stimulation; Sampling of "executive functions"
during movie/audio-description;
%
Just an approximation of real life.
%
Setting is still the scanner.
%
Passive watching \& listening.

%
We re-used existing data as a foundation for a new investigation in
order to generate novel findings encourage further studies, and illustrate the
benefits of publicly and freely available datasets.
%
Extended studyforrest

%
In summary, naturalistic stimuli ``impose a meaningful timecourse across
subjects while still allowing for individual variation in brain activity and
behavioral responses, and lend themselves to a broader set of analyses than
either pure rest or pure event-related task designs'' \citep{finn2017can}.
%
``Naturalistic paradigms do not aim to replace the classic, controlled
neuroimaging paradigms (Sonkusare et al., 2019).
%
Due to their complexity and current limitations in understanding the statistical
properties of different features in naturalistic conditions, naturalistic
stimuli are not optimal for model development [see, e.g., Rust and Movshon,
2005].
%
Controlled experiments are still needed for hypothesis testing and developing
models, while naturalistic stimuli are best employed to test models in
ecologically valid settings and to expand them to situations where context
matters more'' \citep{saarimaki2021naturalistic}.



\pagebreak


\section{Some backups}


\subsection{Group-level vs individual-level analyses}

Backup of quotes for general discussion (or SRM study).  Studies that average
data across study participants may draw

\begin{itemize}

\item ``provide only an approximate view of any individual's brain organization,
    potentially obscuring meaningful individual differences in cortical
        organization'' \citep{laumann2015functional},

\item may just ``capture the common denominator of each individual cognitive
    circuit and lose a large amount of information''

\item ``obscure(s) patterns of brain organization specific to each individual''
    \citep{laumann2015functional}.

\end{itemize}


\subsection{Dynamic localizers}
%
``Previous reports showing significant differences between topographies
estimated by static and dynamic localizers, especially in superior temporal and
frontal cortices [Fox et al., 2009; Pitcher et al., 2011]''
\citep{jiahui2022cross}.
%
``For all categories, the dynamic localizer elicited stronger and broader
category-selective activations than the static localizer''
\citep{jiahui2022cross}.
%
``For example, for the face-selective topographies, the dynamic localizer
activated more areas than the static localizer (e.g., in superior temporal and
frontal cortices)'' \citep{jiahui2022cross}.
%
``The searchlight analysis showed that the dynamic localizer had higher
reliabilities across the cortex, especially in regions that were selectively
responsive to the target category'' \citep{jiahui2022cross}.
%
``The low correlations were not because the prediction method failed but
reflected the difference in the topographies activated by different types of
localizers.'' \citep{jiahui2022cross}.


\subsection{Brain \& behavior: "fingerprints"}

\todo[inline]{reliability of differences is premise for "fingerprints"}
%
Maybe might be stable individual differences in cognitive tendencies or
cognitive abilities like susceptibility / predisposition [?] to attend to, [or]
recognize [or process] auditory spatial information.
% kanai
In case the pattern is stable within individual subjects / is ``highly
consistent across different sessions [or experiments], then they are
characteristics of the individuals and may reflect differences in their brain
function'' \citep{kanai2011structural} [on structural diffences].
%
``Individual differences in topology (i.e. location, size, shape of functional
areas) and the activity within functional areas can also be considered to be
interesting cases of inter-individual variability to understand the neural basis
of human cognition and behavior, brain-phenotype relationships'', and ``present
useful phenotypes or biomarkers \citep{glasser2016multi,
vanhorn2008individual}''


\subsubsection{Brain \& behavior: example studies}

\todo[inline]{shorten heavily or drop altogether}

\todo[inline]{cf. also \citep{gordon2017individual, gordon2017precision}}
%
For example, \citet{kong2019spatial} suggested based on resting-state functional
connectivity measures ``that individual-specific network topography (i.e.,
location and spatial arrangement) might serve as a fingerprint of human behavior
that can predict behavioral phenotypes across cognition, personality, and
emotion'' \citep{kong2019spatial} [with modest accuary, comparable to previous
reports predicting phenotypes based on connectivity strength].

%
\citep{bijsterbosch2018relationship}'s ``results indicate that spatial variation
in the topography of functional regions across individuals is strongly
associated with behaviour'' \citep{bijsterbosch2018relationship}.
%
\citet{bijsterbosch2018relationship} found ``that the spatial arrangement of
functional regions is strongly predictive of non-imaging measures of behavior
and lifestyle'' [however shape \& exact location of brain regions interacted
strongly with  modeling of brain connectivity].
%
\citet{bijsterbosch2018relationship} found ``that individual differences in the
size, shape and exact position of the brain regions [as identified by
resting-state functional connectivity measures] was strongly linked to
individual differences in behavioral tests and questionnaires [including
intelligence, life satisfaction, drug use and aggression problems]''
\citep{bijsterbosch2018relationship}.

%
``The variations in spatial topographical features captured a more direct and
unique representation of subject variability than temporal correlations between
regions defined by group parcellation approaches (coupling).
%
Hence, the cross-subject information represented in commonly adopted
'connectivity fingerprints' could largely reflect spatial variability in the
location of functional regions across individuals, rather than variability in
coupling strength (at least for methods that directly map group-level
parcellations onto individual data)'' \citep{bijsterbosch2018relationship}.

\todo[inline]{drop following paragraph; just here to better understand paragraph
above}
%
``Depending on the employed spatial alignment algorithm and the amount of
removed spatial intersubject variability, the degree to which spatial
information may influence FC estimates possibly varies considerably across
studies.
%
In recent years, significant efforts have gone into the methods that more
accurately estimate the spatial location of functional parcels in individual
subjects [Chong et al., 2017; Glasser et al., 2016; Gordon et al., 2016; Hacker
et al., 2013; Harrison et al., 2015; Varoquaux et al., 2011; Wang et al., 2015],
and into advanced hyperalignment approaches [Chen et al., 2015; Guntupalli et
al., 2016; Guntupalli and Haxby, 2017]'' \citep{bijsterbosch2018relationship}.
