\todo[inline]{finalize figure texts (esp. note it's shuffled; cf. text in SRM part)}

\begin{figure*}[tbp]
\centering
\includegraphics[width=\linewidth]{figures/corr_vis-regressors-vs-cfs_sub-01_srm-ao-av-vis-shuffled_feat10-iter30_7123-7747.pdf}
    \caption{
    %
    \textbf{Mean similarity of hemodynamic responses modeled for the analysis of
    visual localizer in \citet{sengupta2016extension} and shared features
    in 1000 shared response models based on randomly shuffled runs
    in the first fold of the cross-validation.}
    %
    Before calculating the Pearson correlation coefficients between modeled
    responses and shared responses within one of the multi-paradigm \acp{cfs},
    the time series of the respective \ac{cfs}'s shared features
    were trimmed to match the corresponding \acp{tr} of the visual
    localizer paradigm \citep{sengupta2016extension}.
    %
    The modeled hemodynamic responses (i.e. regressors) represent predicted
    responses to the six categories of pictures that were presented in blocks.
    }
\label{fig:corr-vis-reg-srm-shuffled}
\end{figure*}


\begin{figure*}[tbp]
\centering
    \includegraphics[width=\linewidth]{figures/corr_av-regressors-vs-cfs_sub-01_srm-ao-av-vis-shuffled_feat10-iter30_3524-7123.pdf}
    \caption{
    %
    \textbf{Mean similarity of hemodynamic responses modeled for the analysis
    of the movie in \citet{haeusler2022processing} and shared features
    in 1000 shared response models based on randomly shuffled runs
    in the first fold of the cross-validation.}
    %
    Before calculating the Pearson correlation coefficients between modeled
    responses and shared responses within one of the multi-paradigm \acp{cfs},
    the time series of the respective \ac{cfs}'s shared features
    were trimmed to match the corresponding \acp{tr} of the movie
    \citep{hanke2016simultaneous}.
    %
    The modeled shared responses (i.e. regressors) \texttt{vse\_new} to
    \texttt{vno\_cut} are based on
    annotations of movie frames, whereas the regressors
    \texttt{fg\_av\_ger\_lr} to \texttt{fg\_av\_ger\_ud} represent low-level
    visual or auditory confounds
    \citep[cf. Table 3 in][]{haeusler2022processing}.
    %
    \texttt{vse\_new}: change of the camera position to a setting not depicted
    before;
    \texttt{vse\_old}: change of the camera position to a recurring setting;
    %
    \texttt{vlo\_ch}: change of the camera position to another locale within
    the same setting;
    %
    \texttt{vpe\_new}: change of the camera position within a locale not
    depicted before;
    %
    \texttt{vpe\_old}: change of the camera position within a recurring locale;
    %
    \texttt{vno\_cut}: a pseudorandomly selected frames within a continuous
    movie shot;
    %
    \texttt{fg\_av\_ger\_lr}: left-right luminance difference;
    %
    \texttt{fg\_av\_ger\_lrdiff}: left-right volume difference;
    %
    \texttt{fg\_av\_ger\_ml}: mean luminance;
    %
    \texttt{fg\_av\_ger\_pd}: perceptual difference;
    %
    \texttt{fg\_av\_ger\_rms}: root mean square volume;
    %
    \texttt{fg\_av\_ger\_ud}: upper-lower luminance difference.
    }
\label{fig:corr-av-reg-srm-shuffled}
\end{figure*}



\begin{figure*}[tbp]
\centering
    \includegraphics[width=\linewidth]{figures/corr_ao-regressors-vs-cfs_sub-01_srm-ao-av-vis-shuffled_feat10-iter30_0-3524.pdf}
    \caption{
    %
    \textbf{Mean similarity of hemodynamic responses modeled for the analysis
    of the audio-description in \citet{haeusler2022processing}
    and shared features in 1000 shared response models based on randomly
    shuffled runs in the first fold of the cross-validation.}
    %
    Before calculating the Pearson correlation coefficients between modeled
    responses and shared responses within one of the multi-paradigm \acp{cfs},
    the time series of the respective \ac{cfs}'s shared features
    were trimmed to match the corresponding \acp{tr} of the visual
    localizer paradigm \citep{sengupta2016extension}.
    %
    The modeled shared responses (i.e. regressors) \texttt{body} to
    \texttt{sex\_m} are based on
    annotated categories of nouns spoken by the audio-description's narrator,
    whereas the regressors \texttt{fg\_ad\_ger\_lrdiff} and
    \texttt{fg\_ad\_ger\_rms} represent low-level auditory confounds
    \citep[cf. Table 3 in][]{haeusler2022processing}.
    %
    \texttt{body}: trunk of the body; overlaid clothes;
    %
    \texttt{bpart}: limbs and trousers;
    %
    \texttt{fahead}: (parts) of the face or head;
    %
    \texttt{furn}: moveable furniture (insides \& outsides);
    %
    \texttt{geo}: immobile landmarks;
    %
    \texttt{groom}: rooms \& locales or geometry-defining elements;
    %
    \texttt{object}: moveable and countable entities with firm boundaries;
    %
    \texttt{se\_new}: a setting occurring for the first time;
    %
    \texttt{se\_old}: a recurring setting;
    %
    \texttt{sex\_f}: female name, female person(s);
    %
    \texttt{sex\_m}: male name, male person(s);
    %
    \texttt{fg\_ad\_lrdiff}: left-right volume difference;
    %
    \texttt{fg\_ad\_rms}: root mean square volume.
    %
    \texttt{geo\&groom} is a combination of regressors as used on the positive
    side of the primary contrasts aimed to localize the \ac{ppa}
    \citep[cf. Table 5 in][]{haeusler2022processing}.
    }
\label{fig:corr-ao-reg-srm-shuffled}
\end{figure*}

