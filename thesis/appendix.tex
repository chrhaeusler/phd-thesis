\todo[inline]{Update with plots (and text) showing mean correlations across 1000
models}

\todo[inline]{manuall add representation of time / model (cf. plots in SRM part)}

\todo[inline]{finalize text and note that is shuffled (cf. text in SRM part}

\begin{figure*}[tbp]
\centering
\includegraphics[width=\linewidth]{figures/corr_vis-regressors-vs-cfs_sub-01_srm-ao-av-vis-shuffled_feat10-iter30_7123-7747.pdf}
    \caption{
	%
	\textbf{Similarity of hemodynamic reponses modeled for the analysis of
    visual localizer in \citet{sengupta2016extension} and shared features
    calculated by the shared response model (SRM) for subject 01 in the first
    fold of the cross-validation.}
    %
    Before calculating the Pearson correlation coefficients plotted in the
    figure, the time series of the shared features within the multi-paradigm
    \ac{cfs} were trimmed to match the corresponding \acp{tr} of the visual
    localizer paradigm \citep{sengupta2016extension}.
    %
    The modeled hemodynamic responses represent predicted responses to
    the six categories of pictures that were presented in blocks.
    }

\label{fig:corr-vis-reg-srm-shuffled}
\end{figure*}


\begin{figure*}[tbp]
\centering
    \includegraphics[width=\linewidth]{figures/corr_av-regressors-vs-cfs_sub-01_srm-ao-av-vis-shuffled_feat10-iter30_3524-7123.pdf}
    \caption{
    %
    \textbf{Similarity of hemodynamic reponses modeled for the analysis of the
    movie in \citet{haeusler2022processing}
    and shared features calculated by
    the shared response model (SRM) for subject 01 in the first fold of the
    cross-validation.}
    %
    Before calculating the Pearson correlation coefficients plotted in the
    figure, the time series of the shared features within the multi-paradigm
    \ac{cfs} were trimmed to match the corresponding \acp{tr} of the movie
    \citep{hanke2016simultaneous}.
    %
    The modeled shared responses (i.e. regressors) \texttt{vse\_new} to 
    \texttt{vno\_cut} are based on
    annotations of movie frames, whereas the regressors
    \texttt{fg\_av\_ger\_lr} to \texttt{fg\_av\_ger\_ud} represent low-level
    visual or auditory confounds
    \citep[cf. Table 3 in][]{haeusler2022processing}.
    %
    \texttt{vse\_new}: change of the camera position to a setting not depicted
    before;
    \texttt{vse\_old}: change of the camera position to a recurring setting;
    %
    \texttt{vlo\_ch}: change of the camera position to another locale within
    the same setting;
    %
    \texttt{vpe\_new}: change of the camera position within a locale not
    depicted before;
    %
    \texttt{vpe\_old}: change of the camera position within a recurring locale;
    %
    \texttt{vno\_cut}: a pseudorandomly selected frames within a continuous
    movie shot;
    %
    \texttt{fg\_av\_ger\_lr}: left-right luminance difference;
    %
    \texttt{fg\_av\_ger\_lrdiff}: left-right volume difference;
    %
    \texttt{fg\_av\_ger\_ml}: mean luminance;
    %
    \texttt{fg\_av\_ger\_pd}: perceptual difference;
    %
    \texttt{fg\_av\_ger\_rms}: root mean square volume;
    %
    \texttt{fg\_av\_ger\_ud}: upper-lower luminance difference.
    }
\label{fig:corr-av-reg-srm-shuffled}
\end{figure*}



\begin{figure*}[tbp]
\centering
    \includegraphics[width=\linewidth]{figures/corr_ao-regressors-vs-cfs_sub-01_srm-ao-av-vis-shuffled_feat10-iter30_0-3524.pdf}
    \caption{
    %
    \textbf{Similarity of hemodynamic reponses modeled for the analysis of the
    audio-description in \citet{haeusler2022processing}
    and shared features calculated by
    the shared response model (SRM) for subject 01 in the first fold of the
    cross-validation.}
    %
    Before calculating the Pearson correlation coefficients plotted in the
    figure, the time series of the shared features within the multi-paradigm
    \ac{cfs} were trimmed to match the corresponding \acp{tr} of the
    audio-description \citep{hanke2014audiomovie}.
    %
    The modeled shared responses (i.e. regressors) \texttt{body} to 
    \texttt{sex\_m} are based on
    annotated categories of nouns spoken by the audio-description's narrator,
    whereas the regressors \texttt{fg\_ad\_ger\_lrdiff} and
    \texttt{fg\_ad\_ger\_rms} represent low-level auditory confounds
    \citep[cf. Table 3 in][]{haeusler2022processing}.
    %
    \texttt{body}: trunk of the body; overlaid clothes;
    %
    \texttt{bpart}: limbs and trousers;
    %
    \texttt{fahead}: (parts) of the face or head;
    %
    \texttt{furn}: moveable furniture (insides \& outsides);
    %
    \texttt{geo}: immobile landmarks;
    %
    \texttt{groom}: rooms \& locales or geometry-defining elements;
    %
    \texttt{object}: moveable and countable entities with firm boundaries;
    %
    \texttt{se\_new}: a setting occurring for the first time;
    %
    \texttt{se\_old}: a recurring setting;
    %
    \texttt{sex\_f}: female name, female person(s);
    %
    \texttt{sex\_m}: male name, male person(s);
    %
    \texttt{fg\_ad\_lrdiff}: left-right volume difference;
    %
    \texttt{fg\_ad\_rms}: root mean square volume.
    %
    \texttt{geo\&groom} is a combination of regressors as used on the positive
    side of the primary contrasts aimed to localize the \ac{ppa}
    \citep[cf. Table 5 in][]{haeusler2022processing}.
    }
\label{fig:corr-ao-reg-srm-shuffled}
\end{figure*}

