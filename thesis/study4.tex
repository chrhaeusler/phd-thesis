\section{Introduction}

\todo[inline]{mih: prime points of the discussion in intro to better frame the
problem space, challenges \& opportunities}

\todo[inline]{delete unnecessary sub(sub)sections / captions to turn them into
paragraphs}

% higher visual areas higher visual areas
In the domain of higher-visual perception, functionally defined,
category-selective brain regions like the \ac{ppa} \citep{epstein1998ppa}, the
\ac{ffa} \citep{kanwisher1997ffa}, or \ac{eba} \citep{downing2001bodyarea}
exhibit significantly increased \ac{bold} activity correlated with a
``preferred'' \citep{debeck2008interpreting} stimulus class.
%
The topographies (i.e. the location, size and shape) of these category-selective
areas are similarly distributed across individuals but the exact topographies
vary interindividually \citep{rosenke2021probabilistic, zhen2017quantifying,
zhen2015quantifying, frost2012measuring}.


\subsection{Localizers (= problem)}

\todo[inline]{not mentioned here:
    "tacit assumption";
    what does the localizer actually do?
    does it what we want it to do?
    }

\todo[inline]{imo, should be mentioned after part about naturalistic stimuli \&
functional alignment (s. below)}

% definition of localizer
In order to identify the topography of functional areas in individual persons,
block-design \textit{functional localizer} paradigms are traditionally used that
contrast regressors of modeled hemodynamic responses correlating with the
corresponding stimulus classes (i.e. landscapes, faces, or bodies).
% problem: one localizer for one domain
Functional localizers are designed to maximize detection power and thus
dedicated to map just one domain of brain functions like, for example,
retinotopic visual areas \citep{wang2015probabilistic}, scene-selective regions
\citep{stigliani2015temporal}, theory of mind \citep{spunt2014validating}, or
semantic processes \citep{fedorenko2010new, fernandez2001language}.
% which gets messy
However, if one wants to map a variety of domains, the approach ``one paradigm
for one domain of functions'' gets time-consuming and impractical.
% localizer batteries: intro
Researchers have tried to tackle that issue by creating time-efficient
multi-functional \textit{localizer batteries} \citep[e.g.,][]{barch2013function,
drobyshevsky2006rapid, pinel2007fast}.
% task based = shit
Nevertheless, the diagnostic quality of localizer paradigms rely heavily on a
participant's comprehension of the task instructions and general compliance, a
criterion that can be difficult to meet in clinical or pediatric populations
\citep{eickhoff2020towards, vanderwal2019movies}.


\subsection{Estimation from reference group (= solution)}

\subsubsection{Intro (incl. recapitulation of \citet{haeusler2022processing})}

% ppa via audio-description
% Results also suggest that a naturally engaging, purely auditory paradigm like
% an audio-description could, in principle, substitute a visual localizer as a
% diagnostic procedure to assess brain functions in visually impaired %
% individuals \citep{haeusler2022processing}.

% ppa via movie
In \citet{haeusler2022processing}, we have shown that a functionally
defined region, such as the \ac{ppa}, can be localized using a model-driven
\ac{glm} analysis that is based on the annotated temporal structure of a
two-hour long naturalistic stimulus.
% full feature film is too long
However, a two-hour long paradigm is unsuitable for a clinical application due
to practical and monetary reasons.
% hence, predict from reference
An approach to reduce time and costs is to identify a functional area in an
individual person based on data collected from an independent sample of
different persons (i.e. data from a \textit{reference group}).



\subsubsection{Anatomical alignment}

% intro: estimation via common anatomical space
Previous studies estimated the most probable location of a functional area in a
person's anatomy from a reference group by performing a volume-based
\citep[e.g.,][]{zhen2017quantifying, zhen2015quantifying} or surface-based
\citep[e.g.,][]{frost2012measuring, weiner2018defining,
rosenke2021probabilistic, wang2015probabilistic} \textit{anatomical alignment}.
%
First, in order to address the issue of anatomical variability across persons,
functional data of persons in the reference group are anatomically aligned to
(i.e.  projected into) a \textit{common anatomical space} (e.g., Montreal
Neurological Institute brain atlas; \citep[MNI152,][]{fonov2011unbiased}).
% project into test subject to estimate
Then, data are projected from the common anatomical space into the individual
person's brain anatomy serving as an estimation of a functional region's
location.

% volume-based alignment in one sentence
Volume-based anatomical alignment \citep[s.][for a review]{klein2009evaluation}
aligns voxels to a three-dimensional common anatomical space \citep[e.g., MNI152
atlas;][]{fonov2011unbiased}.
% surface-based alignment in one sentence
Surface-based anatomical alignment \citep{fischl1999cortical, yeo2009spherical}
aligns vertices to a two-dimensional common anatomical space \citep[e.g.,
FreeSurfer's fsaverage template;][]{fischl1999high}.
% difference in one sentence
Whereas volume-based alignment does not account for individual sulcal and gyral
folding patterns, surface-based alignment respects interindividual variability
of the cortical surface.
% surface-based estimation works better
Consequently, previous studies compared  [linear / affine] volume-based and
[nonlinear] surface-based alignment to estimate the location of functional
regions have shown that surface-based alignment lead to reduced inter-subject
variability, and thus increased estimation performance
\citep{rosenke2021probabilistic, frost2012measuring, wang2015probabilistic,
weiner2018defining}.
% remaining variability after surface-based alignment
However, even after surface-based alignment the anatomical location of
functional regions varies anatomically across persons
\citep[e.g.,][]{coalson2018impact, benson2014correction, natu2021sulcal,
wang2015probabilistic, frost2012measuring, langers2014assessment, weiner2014mid,
rosenke2021probabilistic}.
% frost as an example
For example, \citet{frost2012measuring} localized 13 functional areas of the
high-level visual cortex and ``found a large variability in the degree to which
functional areas respect macro-anatomical boundaries''
\citep{frost2012measuring}.
% functional--anatomical correspondence
The remaining variability indicates that functional areas a not necessarily
bound to anatomical landmarks, and reflects the degree of
\textit{functional--anatomical correspondence} between a brain function and its
underlying anatomical location.


% case of PPA
% cf. also \citet{frost2012measuring, rosenke2021probabilistic}
% \citet{weiner2018defining} showed ``that cortical folding patterns and
% probabilistic predictions reliably identify place-selective voxels in medial
% VTC across individuals and experiments''.
%
% However, ``this structural-functional coupling is not always perfect and there
% is inter-subject variability as to how much the place-selective voxels extend
% within the parahippocampal gyrus, as well as the lingual gyrus and medial
% aspects of the fusiform gyrus.
%
% Despite this inter-subject variability, place-selective voxels are always
%located within the collateral sulcus across participants.''
% \citep{weiner2018defining}.


\subsubsection{Functional alignment}
%
Since anatomical alignment addresses the issue of anatomical variability but not
functional-anatomical variability across subjects, algorithms---like
\textit{hyperalignment} \citep{haxby2011common, guntupalli2016model} or the
\textit{shared response model} \citep{chen2015reduced, zhang2016searchlight}---
have been developed that perform a \textit{functional alignment}.
%
Whereas anatomical alignment aligns voxels (or vertices) that share the same
anatomical location to a common anatomical space, functional alignment aligns
voxels (or vertices)\todo{unclear?} that share similar functional properties to
a \textit{common functional space} (CFS).
%
Functional alignment algorithms are usually used to construct both a
high-dimensional, functional brain template (i.e. the \ac{cfs}) from study
participants' functional data as well as subject-specific transformation
matrices.
%
A subject's transformation matrix allows a mapping of functional data from a
subject's three-dimensional voxel space into the \ac{cfs}, or to project data
from the \ac{cfs} into a subject's voxel space \citep{haxby2020hyperalignment,
kumar2020brainiak}.
%
The \ac{cfs} and transformation matrix can be created (i.e.  \textit{trained})
based on the maximization of the inter-subject similarity of \ac{bold} response
time series correlating with a time-locked external stimulation
\citep{haxby2011common, chen2015reduced, sabuncu2010function}, or based on the
inter-subject similarity of connectivity profiles \citep{feilong2018reliable,
guntupalli2018computational, nastase2019leveraging}.
%
Tough functional alignment algorithms can be applied to \ac{fmri} time series
data from paradigms employing simplified stimuli, data from naturalistic stimuli
provide increased generalizability of the \ac{cfs} and transformation matrices
to novel stimuli or tasks, presumably because naturalistic stimuli sample a
broader range of brain states \citep{haxby2011common, guntupalli2016model}.




\subsubsection{Estimation via functional alignment}
%
Hence, a more recent procedure \citep[e.g., ][]{jiahui2020predicting,
guntupalli2016model, haxby2011common} to estimate the most probable location of
a functional area in a person's anatomy from a reference group performs an
functional alignment.
% solve functional-anatomical variability
First, functional data from persons in the reference group are anatomical
aligned to a common anatomical space.
%
Second, in order to address the issue of functional-anatomical variability
across persons, functional data are functionally aligned (i.e. projected into) a
\ac{cfs}.
%
Then, data are projected from the \ac{cfs} into the individual person's brain
anatomy serving as an estimation of a functional region's location.

% Jiahui
For example, \citet{jiahui2020predicting} calculated both a \ac{cfs} and
transformation matrices based on data from a) the movie ``Grand Budapest Hotel''
($\sim$\unit[50]{m}; \ac{tr}=\unit[1]{s}), and b) ``Forrest Gump''
($\sim$\unit[120]{m}; \ac{tr}=\unit[2]{s}).
% summary of results
Results revealed that the empirical results of a visual localizer's $t$-contrast
that aimed at localizing the \ac{ffa} correlate more highly with contrast maps
that were estimated from other subjects' data based on hyperalignment than with
contrast maps that were estimated based on surface-based anatomical alignment
\citep{jiahui2020predicting}.



\subsection{Here, we...}

\todo[inline]{constrain to voxels in the mask is not mentioned; should this be
mentioned here?}

% focus: ppa
Here, we focus on the \ac{ppa} \citep[e.g.,][for reviews]{epstein2014neural,
aminoff2013role}, and explore whether we can estimate the results of
$t$-contrasts (i.e. $Z$-maps) that were created to localize the \ac{ppa} using
functional data of three different paradigms:
%
1) a classic visual localizer \citep{sengupta2016extension} as the assumed
``gold standard'',
%
2) a movie \citep{haeusler2022processing}, and
%
3) an auditory narrative \citep{haeusler2022processing}.


\subsubsection{SRM}

% math stuff from citep{vodrahalli2018mapping}
% ``SRM learns $N$ maps $W_{i}$ with orthogonal columns such that
% $||X_{i}-W_{i}S||_{F}$ is minimized over $\left\{ W_{i}\right\} _{i=1}^{N},S$,
% where $X_{i}\in\mathbb{R}^{v\times{T}}$ is the $i^{th}$ subject's fMRI
% response ($v$ voxels by $T$ repetition times) and
% $S\in\mathbb{R}^{k\times{T}}$ is a feature time-series in a $k$-dimensional
% shared space'' \citep{vodrahalli2018mapping}.

% Inverse vs. transpose of a matrix:
% for orthogonal transformations (like we should have here, i.e. only rotation,
% expansion) these two are one and the same thing:
% https://www.quora.com/When-is-the-inverse-of-a-matrix-equal-to-its-transpose

% why SRM
Our volume-based functional alignment approach utilizes the \ac{srm} algorithm
\citep{chen2015reduced, richard2019fast} as implemented in the open-source
software package BrainIAK \citep[Brain Imaging Analysis Kit;
\href{https://brainiak.org}{\url{brainiak.org}};][]{kumar2020brainiak,
kumar2020brainiaktutorial}.
% general overview of SRM
The \ac{srm} is an unsupervised probabilistic latent-factor model that
decomposes \ac{bold} \ac{fmri} response time series of participants experiencing
the same stimulus into a \ac{cfs} of \textit{shared features} \citep[also called
``\textit{shared feature space}'';][]{chen2015reduced} and subject-specific
linear transformations matrices.
% math stuff
More specifically, the \ac{srm} algorithm uses each $n^{th}$ training subject's
response time series represented as matrix $X_{n}$ ({$v$} voxels by $t$ time
points) to calculate the \ac{cfs} $C$ ($k$ shared responses by $t$ time points)
and subject-specific, transformation matrices $W_{n}$ ($v$ voxels by $k$ shared
responses) with orthonormal columns ($W_{n}^{T}W_{n}=I_{k}$).
% iteratively fitted
The algorithm randomly initializes and fits the transformation matrices over
iterations to minimize the error in explaining the participants' data, while
also learning the time course of the shared responses (s.
\href{https://brainiak.org/tutorials/11-SRM/}{\url{brainiak.org/tutorials/11-SRM}}).
% number of dimensions
In contrast to hyperalignment, the number of dimensions of the \ac{cfs} is not
set by the number of voxels but is set by the researcher to a number lower than
the number of voxels, a procedure that also filters out noise and reduces
overfitting \citep{chen2015reduced}.
% phrase math in words
Hence, each shared feature can be understood as a weighted sum of many voxels
across subjects \citep{kumar2020brainiak}.
% result = alignment
A subject-specific transformation matrix can be understood as the weight of each
voxel in a subject's voxel space on each shared feature, and allows to
functionally align a subject's functional data to the \ac{cfs} by projecting
responses within the voxels into the $k$-dimensional \ac{cfs}.


\paragraph{Multi-stimulus model; three ``predictors''}

\todo[inline]{check \citet{jiahui2020predicting, guntupalli2016model,
haxby2011common} again for relevant text; and, maybe, also their newer studies}

% Multi-stimulus model
Contrary to previous studies \citep[e.g.][]{jiahui2020predicting,
guntupalli2016model, haxby2011common} that created a \ac{cfs} based on data from
a single paradigm, we calculate a \textit{multi-stimulus \ac{cfs}}:
%
Following an exhaustive leave-one-out cross-validation (N$=$14 subjects), we
train a shared response model (i.e. the \ac{cfs}) based on concatenated
response time series to a movie, an audio-description and a visual
localizer from $N-1$ \textit{training subjects}.
%


In the present study, we aim to investigate three aspects:


\paragraph{Three criteria}
%
First, in order to investigate the validity and generalizability of our
multi-stimulus \ac{cfs}, we predict a left-out \textit{test subject}'s results
from the analysis of
%
a) the localizer \citep{sengupta2016extension}
%
b) the movie \citep{haeusler2022processing}, and
%
c) the auditory narrative \citep{haeusler2022processing}.


\paragraph{Three predictors}
%
Second, in order to investigate the validity and generalizability of a test
subject's transformation matrix based on data from different paradigms, we use a
test subject's response time series to each of the three paradigms independently
to align the test subject with the corresponding \acp{tr} within the \ac{cfs}
(i.e. one \textit{within-experiment} prediction, and two
\textit{cross-experiment} predictions).


\paragraph{Partial alignment}
%
Third, since using a complete naturalistic stimulus to align a test subject is
impractical in a clinical setting, we also investigate the relationship between
the estimation performance of the $t$-contrast's results and the quantity of
data from each of the three paradigms used to functionally align the subject
with the multi-stimulus \ac{cfs}.


\paragraph{Anatomical alignment as benchmark}
%
Lastly, we compare the performance of your volume-based, functional alignment
procedures to the performance of a volume-based, anatomical alignment
approach that serves as a benchmark.




\subsection{Hypotheses}

\subsubsection{Questions (as discussed during our meeting)}

\todo[inline]{tbh, I do not get all points discussed during our meeting anymore}

\begin{itemize}
    \item can I predict classic localizer?  SRM could just do a denoising, too;
    \item question: What is causing the difference?
    \item a) is it the quality of the alignment? or:
        b) is the model doing a better prediction?
        i.e. is the criterion doing an individual overfit?
    \item How do I know if this (i.e. visual PPA) is the "gold standard"?
        "tacit assumption";
        what does the localizer actually do?
        does it what we want it to do?
    \item mention: higher reliability (and validity?) of localizers using video
        (snippets), and higher generalizability of models (we: matrices) using
        naturalistic stimuli
    \item bonus: can I predict movie PPA and auditory PPA?
\end{itemize}

%
We hypothesized that an increased quantity of data used to calculate the
transformation matrices of the test subjects would lead to an increasing
prediction performance.
%
Further, we hypothesized that functional alignment procedure would eventually
outperform an estimation based on an anatomical alignment procedure.


\subsection{Summary of results}

\todo[inline]{at the end of intros, papers provide 2-3 sentences summarizing
results and often also a 1-2 sentence conclusion}

\todo[inline]{so far, just some building block that were shifted from other
parts to here}

%
Our results provide evidence that transformation matrices calculated based on
data from naturalistic stimuli promise an increased validity of derived
transformation for functional alignment over transformation matrices based on
data (of the same!) paradigm based on simplified stimuli.



\subsection{Conclusion \& Vision}

\todo[inline]{2-3 sentences are enough here; better write more in discussion}

Our results suggest that it is possible to ``scan once, estimate many''...


\section{Methods}

% we get the data from the naturalistic PPA paper (its subdataset)
% datalad get -n inputs/studyforrest-ppa-analysis/inputs/studyforrest-data-aligned
% datalad get inputs/studyforrest-ppa-analysis/inputs/studyforrest-data-aligned/sub-??/in\_bold3Tp2/sub-??\_task-a?movie\_run-?\_bold*.*

% reference to PPA-Paper
For the current study, we used the same subset of the studyforrest dataset that
was used in study 2 \citep{haeusler2022processing}:
%
the same subjects ($N=14$) were
% VIS
a) participating in a dedicated six-category block-design visual localizer
\citep{sengupta2016extension},
% AV
b) watching the audio-visual movie ``Forrest Gump''
\citep{hanke2016simultaneous}, and
% AD
c) listening to the movie's audio-description \citep{hanke2014audiomovie}.
% see corresponding papers for details
An exhaustive description of participants, stimulus creation, procedure,
stimulation setup, and fMRI acquisition can be found in the corresponding
publications, whereas a summary is provided in \citet{haeusler2022processing}.



\subsection{Preprocessing}

% data sources
The current analyses were carried out on the same preprocessed fMRI data (s.
\href{https://github.com/psychoinformatics-de/studyforrest-data-aligned
}{\url{github.com/psychoinformatics-de/studyforrest-data-aligned}}) that were
used for
%
a) the technical validation of the dataset \citep{hanke2016simultaneous},
%
b) the localization of higher-visual areas \citep{sengupta2016extension}, and
%
c) the investigation of responses of the \ac{ppa} correlating with naturalistic
spatial information in study 2 \citep{haeusler2022processing}.

%
We reran the preprocessing and analyses steps performed in
\citet{sengupta2016extension} and \citet{haeusler2022processing} using FEAT
v6.00 \citep[FMRI Expert Analysis Tool;][]{woolrich2001autocorr} as shipped with
FSL v5.0.9 \citep[\href{https://www.fmrib.ox.ac.uk/fsl}{FMRIB's Software
Library;}][]{smith2004fsl} in order to reproduce both the time series that
served as final input for the statistical analyses in the two previous studies
as well as their results (i.e. the statistical $Z$-maps).
% temporal filtering
In summary, high-pass temporal filtering was applied using a Gaussian-weighted
least-squares straight line to every run of the visual localizer (cutoff period
of \unit[100]{s}; sigma= \unit[100]{s}/2)\todo{???}, and every segment of the
movie and audio-description (\unit[150]{s}; sigma=\unit[75.0]{s}).
% brain extraction
Brains were extracted from surrounding tissues using BET \citep{smith2002bet}.
% spatial smoothing
As in the previous studies, data from all three paradigms were spatially
smoothed (Gaussian kernel with full width at half maximum of \unit[4.0]{mm}).
% grand mean normalization
A grand-mean intensity normalization was applied to each run of the functional
localizer and each segment of the naturalistic stimuli.

%
Further analyses on theses reproduced times series were performed via Python
scripts that relied on
%
NiBabel v3.2.1 (\href{https://nipy.org}{\url{nipy.org}}),
%
NumPy v1.20.2 (\href{https://numpy.org}{\url{numpy.org}}),
%
Pandas v1.2.3 (\href{https://pandas.pydata.org}{\url{pandas.pydata.org}}),
%
Scipy v1.6.2 (\href{https://scipy.org}{\url{scipy.org}}),
%
scikit-learn v1.0 (\href{https://scikit-learn.org}{\url{scikit-learn.org}}),
%
BrainIAK v0.11
\citep[\href{https://brainiak.org}{\url{brainiak.org}}][]{kumar2020brainiak,
kumar2020brainiaktutorial},
%
Matplotlib v3.4.0 (\href{https://matplotlib.org}{\url{matplotlib.org}}),
%
seaborn v0.11.2 (\href{https://seaborn.pydata.org}{\url{seaborn.pydata.org}}),
%
and calling command line functions of FSL.

%\paragraph{Fixing FSL output}

% grand_mean_for_4d.py (formerly: data_normalize_4d.py):
% is not necessary anymore: FSL has applied grand mean scaling to
% 'filtered_func_data.nii.gz'

% input: 'sub-*/run-?.feat/filtered_func_data.nii.gz' (of VIS, AO & AV)
% output: saved to 'sub-??_task-*_run-?_bold_filtered.nii.gz'

% FSL adds back the mean value for each voxel's time course at the end of the
% preprocessing;
% hence, the script substracts that mean again but multiplies it by 10000
% (like FSL does it, too)

% definition of grand mean scaling for 4d data:
% voxel values in every image are divided by the average global mean
% intensity of the whole session. This effectively removes any mean global
% differences in intensity between sessions.

% FSL User Guide:
% filtered_func_data will normally have been temporally high-pass filtered,
% it is not zero mean; the mean value for each voxel's time course has been
% added back in for various practical reasons.
% When FILM begins the linear modeling, it starts by removing this mean.


\subsubsection{Region of Interest}

\todo[inline]{Plot of "number of voxels" is added (despite not conveying a lot
of information); the table with the exact numbers is removed}

\todo[inline]{it is a sample; better speak of $\overline{X}=1592$, $SD=188$, and
not of $\mu=1592$, $\sigma=188$}.

\todo[inline]{problem 1: grpPPA contains N=14 subject, not N-1 subjects}

\todo[inline]{problem 2: voxels outside of PPA-mask; probably, because of
warping procedures}

% masks-from-mni-to-bold3Tp2.py:
% - merges unilateral ROIs overlaps (already in MNI) to bilateral ROI
% - output: 'masks/in_mni/PPA_overlap_prob.nii.gz'
% - warps union of ROIs from MNI into each subjects space
% output: 'sub-*/masks/in_bold3Tp2/grp_PPA_bin.nii.gz' + audio_fov.nii.gz dilate
% the ROI masks by 1 voxel; output: 'grp_PPA_bin_dil.nii.gz'

% masks-from-mni-to-bold3Tp2.py:
% warp MNI masks into individual bold3Tp2 spaces

% masks-from-t1w-to-bold3Tp2.py:
% transforms 'inputs/tnt/sub-*/t1w/brain_seg*.nii.gz'
% into individual's bold3Tp2
% output: 'sub-*/masks/in_bold3Tp2/brain_seg*.nii.gz'

% mask-builder-voxel-counter.py:
% builds different individual masks by dilating, merging other masks
% creates a FoV of AO stimulus for every subject from 4d time-series of AO run
% output: sub-*/masks/in_bold3Tp2/audio_fov.nii.gz'
% counts the voxels
% long story short: we cannot used all gyri that contain PPA to some degree
% even if the mask by FoV of AO stimulus and individual gray matter mask

% data_mask_concat_runs.py:
% masks are not dilated and not masked with subject-specific gray matter mask
% outputs:
% 'sub-*_task_aomovie-avmovie_run-1-8_bold-filtered.npy
% 'sub-*_task_visloc_run-1-4_bold-filtered.npy'

% reason why we do it
The \ac{srm} requires that the number of samples (i.e. the number of \acp{tr})
exceed the number of features (the number of voxels).
%
In order to restrict the number of voxels, we created bilateral \acp{roi} for
each subject by warping the union of individual \acp{ppa}
\citep[s.][]{haeusler2022processing} from MNI space into each subjects' voxel
space using previously computed subject-specific, non-linear transformation
matrices
\citep[][\href{https://github.com/psychoinformatics-de/studyforrest-data-templatetransforms
}{\url{github.com/psychoinformatics-de/studyforrest-data-templatetransforms}}]{hanke2014audiomovie}.
% applying masks
Each subject's time series data were then masked by the union of individual
\acp{ppa} and the subject-specific \ac{fov} of the audio-description.
% voxels = [1665, 1732, 1400, 1575, 1664, 1951, 1376, 1383, 1683, 1887, 1441,
% 1729, 1369, 1437]
%
The number of remaining voxels per subject (range 1369--1951,
$\overline{X}=1592$, $SD=188$) can be seen in Fig.~\ref{fig:plot_voxel-counts}.

\todo[inline]{it is a sample, better not speak of $\mu=1592$, $\sigma=188$)}

\begin{figure*}[tbp]
\centering
    \includegraphics[width=\linewidth]{figures/plot_voxel-counts.pdf}
    \caption{
    %
    \textbf{Number of voxels per subject.}
    %
    Add legend for the median; maybe, add mean, too?
    Write description of the masks:
    union of individual \acp{ppa} \citet{haeusler2022processing}
    and field of view.
    }
    \label{fig:plot_voxel-counts}
\end{figure*}


\begin{comment}

The number of remaining voxels per subject can be seen in Table
\ref{tab:ppamaskvoxels} (range 1369--1951, $\overline{X}=1592$, $SD=188$).


\begin{table*}[btp]
    \caption{
    %
    \textbf{Table heading.}
    %
    Number of remaining voxels after time series data of each paradigm
    and subject were masked with the union of individual \acp{ppa} that was
    warped from MNI space into each individual's subjects-space and the
    subject-specific field of view of audio-description.}

\label{tab:ppamaskvoxels}
\begin{tabular}{ll}
    \toprule
    \textbf{Subject} & \textbf{no. of voxels} \\
    \midrule
    sub-01 & 1665 \tabularnewline
    sub-02 & 1732 \tabularnewline
    sub-03 & 1400 \tabularnewline
    sub-04 & 1575 \tabularnewline
    sub-05 & 1664 \tabularnewline
    sub-06 & 1951 \tabularnewline
    sub-14 & 1376 \tabularnewline
    sub-09 & 1383 \tabularnewline
    sub-15 & 1683 \tabularnewline
    sub-16 & 1887 \tabularnewline
    sub-17 & 1441 \tabularnewline
    sub-18 & 1729 \tabularnewline
    sub-19 & 1369 \tabularnewline
    sub-20 & 1437 \tabularnewline
    \bottomrule
\end{tabular}
\caption*{The legend text goes here.}
\end{table*}

\end{comment}



\subsubsection{Concatenation of time series}

\todo[inline]{I z-scored the runs runwise, concatenated them, and z-scored
again}

% normalization
Data of every run were independently normalized ($z$-scored) to a mean of zero
($\overline{X}=0$) and a standard deviation of one ($SD=1$).
%
The last 75 \acp{tr} of the audio-description were missing in subject 04 due to
an image reconstruction problem \citep[s.][]{hanke2014audiomovie}.
%
The \ac{srm} allows the number of voxels to be different across subjects but the
number of \acp{tr} must be the same.
%
Hence, we removed the last 75 \acp{tr} of the audio-description from the all
other subjects' time series.
% summary; AO + AV = 7123 TRs (not 7198 TRs anymore); localizer has 4 x 156 TRs
As a result, the data to fit the \ac{srm} in the following step comprised 3599
\acp{tr} of the movie, 3524 \acp{tr} of the audio-description, and 624 \acp{tr}
of the visual localizer experiment (7747 \acp{tr} in total).
%% concatenate and z-score
The time series of all three paradigms were concatenated and $z$-scored.

\todo[inline]{well, probably I should have cut the last 75TRs of AO first, and
then z-scored the last segment but anyway...; does not make much difference}

\todo[inline]{yes, I performed a second z-scoring but across all runs/paradigms}



\subsection{Estimation via anatomical alignment}

\todo[inline]{transition from preprocessing to alignment missing?}

\todo[inline]{was it transpose of the matrix to warp from MNI into subject, or
a separate one?}

%
As a baseline, we performed a prediction of the $t$-contrast's \textit{empirical
$Z$-maps} via an anatomical alignment procedure:
%
Results from the analysis of
%
the visual localizer \citep{sengupta2016extension},
%
the movie \citep{haeusler2022processing}, and
%
the audio-description \citep{haeusler2022processing}
%
were estimated based on the training subjects' results of the same paradigm
(hence, a within-paradigm prediction).

% anatomical alignment; into MNI
We used previously computed transformation matrices
\citep[][\href{https://github.com/psychoinformatics-de/studyforrest-data-templatetransforms}{\url{github.com/psychoinformatics-de/studyforrest-data-templatetransforms}}]{hanke2014audiomovie}
to project the respective $t$-contrast's masked $z$-map via a non-linear
transformation from each training subject's voxel space into the MNI space.
% from MNI into subject
Then, we  used the transpose of the transformation matrix [or was it another
matrix?] to project the data from MNI space into the test subject's voxel space.
% take the mean
For each of the three $t$-contrast, the arithmetic mean of the respective
projected $Z$-maps served as an estimation (hence, a \textit{predicted $Z$-map})
of the test subject's empirical $Z$-map.


\paragraph{old text}

% overview
We then estimated a test subject's localizer results (the empirical $Z$-map) by
projecting all training subjects' empirical $Z$-maps from their voxel space
trough the common space (i.e. through the \ac{cfs} in case of functional
alignment; through MNI152 space in case of anatomical alignment) into the test
subject's voxel space.


\paragraph{Masking}

\todo[inline]{adjust to new phrasing}
%
First, empirical $Z$-maps of the training subjects' localizer contrasts were
masked with the same mask as the time series data that were used to generate the
\ac{cfs}.
%
Thus, $Z$-maps were masked in the respective subject's voxel space by the union
of individual \acp{ppa} \citep[cf.][that was warped from MNI152 space into each
subjects' voxel space]{haeusler2022processing} and the subject-specific \ac{fov}
of the audio-description.



\subsection{Estimation via functional alignment}
%
Our procedure to estimate the $t$-contrasts' empirical $Z$-maps via functional
alignment is conducted in four steps:
% create CFS and training subjects' matrices
first, for every fold of a leave-one-out cross-validation (N$=$14 subjects), we
trained a \ac{srm} on $N-1$ training subjects' response time series
of [to?] the movie, the audio-description, and the visual localizer.
% results in...
This first step provides both a \ac{cfs} for every fold of the cross-validation
and an orthonormal transformation matrix for each training subject.
% align test subject
Second, we used time series data from the visual localizer, the movie, or the
audio-description to align the test subject to the corresponding \acp{tr} within
the \ac{cfs}.
%
Therefore, this second step provides different transformation matrices for the
test subject based on data from different paradigms.
% quantity vs. performance
Moreover, we wanted to investigate the relationship between the estimation
performance [of the $t$-contrast's results] and the quantity of data used to
acquire a transformation matrix.
% therefore
Therefore, we also varied the number of runs of the paradigms used to align the
test subject resulting in different transformation matrices based on different
amounts of \ac{tr}.
% project into CFS
In the third step, we used the training subjects' transformations matrices to
perform a mapping of the training subjects' empirical $Z$-maps from their
respective voxel space into the \ac{cfs}.
% project from CFS into test subject
In the fourth step, we used the transpose of the test subject's transformation
matrix to project the training subjects' $Z$-maps from the \ac{cfs} into the
test subject's voxel space.
% actual prediction
For each of the three $t$-contrasts, the arithmetic mean of the projected
$Z$-maps serves as a test subject's predicted $Z$-map.



\subsubsection{Fitting the shared response model (SRM)}

\todo[inline]{add a figure of the \ac{cfs} created from different stimuli}

\todo[inline]{mention that I also tested calculating the \ac{cfs} based on just
data from 'ao \& av' and not VIS data? results: minimally "worse"; can probably
be dropped because there are no TRs in the model to align the localizer TRs to}

%
In order to acquire the \ac{cfs} and the training subjects' transformation
matrices, we used the probabilistic \ac{srm} algorithm that is implemented in
BrainIAK v.11 \citep[Brain Imaging Analysis Kit;][]{kumar2020brainiak,
kumar2020brainiaktutorial}, and approximates the \ac{srm} based on the
Expectation Maximization (EM) algorithm as proposed by \citet{chen2015reduced}
and optimized by \citet{anderson2016enabling}.


\paragraph{Number of dimensions}

\todo[inline]{description of \citet{haxby2011common}'s probably too long}

% ``The effect of number of PCs on BSC was similar for models that were based
% only on Princeton (n = 10) or Dartmouth (n = 11) data, suggesting that this
% estimate of dimensionality is robust across differences in scanning hardware
% and scanning parameters'' \citep{haxby2011common}.
%
% ``These dimensionality estimates are a function of the spatial and temporal
% resolution of fMRI and the number and variety of response vectors used to
% derive the common space'' \citep{guntupalli2016model}.
%
% ``The true dimensionality of representation in human cortex surely involves
% vastly more distinct tuning functions. Estimates of the dimensionality of
% cortical representation, therefore, will almost certainly be much higher as
% data with higher spatial and temporal resolution for larger and more varied
% samples of response vectors are used to build new common models''
% \citep{guntupalli2016model}.

% features
For the number of shared responses (i.e. the number of the \ac{cfs}'s
dimensions), we chose a value of $k=10$ considering a) the temporal and spatial
resolution of our data (\ac{tr} = \unit[2]{s}; \unit[2.5 $\times$ 2.5 $\times$
2.5]{mm}), b) the average number of voxels per \acp{roi}, b) and findings from
\citet{haxby2011common}.
%
\citet{haxby2011common} first used hyperalignment to create a \ac{cfs} of 1,000
dimensions based of functional data (\ac{tr} = \unit[3]{s}) of voxels (of size
\unit[3 $\times$ 3 $\times$ 3]{mm}) located in the ventral temporal cortex.
%
Then, \citet{haxby2011common} reduced the dimensionality of the \ac{cfs} by
applying a \ac{pca} in order to determine the subspace that is sufficient to
capture the full range of response-pattern distinctions.
%
Results revealed that approximately 35 principal components (i.e. dimensions)
were sufficient to represent the information content of a one-hour movie from
which the \ac{cfs} was derived.
%
Results also showed that the cortical topographies of category-selective brain
regions was preserved in the 35-dimensional \ac{cfs} \citep{haxby2011common}.
%
In the current study, we also computed \acp{cfs} of $k=5, 20, 30, 40, 50$ but
prediction performance based on these \acp{cfs} barely varied from a
10-dimensional \ac{cfs}.
% iterations:
The number of iterations for the algorithm to minimize the error was set to 30.

\todo[inline]{I created the "other-dimensional" \acp{cfs} and printed the
Pearon's r's to file; judge by eye balling results were not "better"}


\paragraph{Correlation of regressors used in our previous studies with shared
responses}

\todo[inline]{mih: spell out regressor labels; coh: that will get pretty messy;
cf. Table 3 in \citep{haeusler2022processing}}

\todo[inline]{make more clear that this is an example for an CFS for sub-01;
funnily: the correlations even among shared responses change depending the 13
subjects used for each test subject's \ac{cfs}}


% Intro
We calculated the Pearson correlation coefficients between shared responses
within the \ac{cfs} and the regressors that were previously modeled
\citep{sengupta2016extension, haeusler2022processing} to investigate hemodynamic
responses to the three stimuli (movie, audio-description, audio-description).


%
Correlation of shared responses (occurring during TRs of the visual localizer)
with modeled responses (regressors) used in \citet{sengupta2016extension}: see
Fig.~\ref{fig:corr-vis-reg-srm}.

%
Correlation of shared responses (occurring during TRs of the movie) with modeled
responses (regressors) to visual stimulus features as used in
\citet{haeusler2022processing}: Fig.~\ref{fig:corr-av-reg-srm}.

%
Correlation of shared responses (occurring during TRs of the audio-description)
with modeled responses (regressors) to auditory stimulus features as used in
\citet{haeusler2022processing}: Fig.~\ref{fig:corr-ao-reg-srm}.



\begin{figure*}[tbp]
\centering
\includegraphics[width=\linewidth]{figures/corr_vis-regressors-vs-cfs_sub-01_srm-ao-av-vis_feat10-iter30_7123-7747.pdf}
    \caption{
    %
    \textbf{Correlations of shared responses and regressors of the visual
    localizer.
    }
    %
    Pearson correlation coefficients between a) shared responses (sh. res.)
    within the \ac{cfs} that was calculated for subject 01 and b) regressors
    created in \citet{sengupta2016extension} to model hemodynamic responses
    during the six-category visual localizer paradigm.
    %
    The time series of the \ac{cfs} were sliced to match the TRs of the
    visual localizer.
    }
    \label{fig:corr-vis-reg-srm}
\end{figure*}


\begin{figure*}[tbp]
\centering
    \includegraphics[width=\linewidth]{figures/corr_av-regressors-vs-cfs_sub-01_srm-ao-av-vis_feat10-iter30_3524-7123.pdf}
    \caption{
    %
    \textbf{Correlations of shared responses and regressors of the movie.}
    %
    Pearson correlation coefficients between a) shared responses (sh. res.)
    within the \ac{cfs} that was calculated for subject 01 and b) regressors
    created in \citet{haeusler2022processing} to model hemodynamic responses to
    stimulus features of the movie.
    %
    The time series of the \ac{cfs} were sliced to match the TRs of the
    movie.
    }
    \label{fig:corr-av-reg-srm}
\end{figure*}



\begin{figure*}[tbp]
\centering
    \includegraphics[width=\linewidth]{figures/corr_ao-regressors-vs-cfs_sub-01_srm-ao-av-vis_feat10-iter30_0-3524.pdf}
    \caption{
    %
    \textbf{Correlations of shared responses and regressors of the audio-description.}
    %
    Pearson correlation coefficients between a) shared responses (sh. res.)
    within the \ac{cfs} that was calculated for subject 01 and b) regressors
    created in \citet{haeusler2022processing} to model hemodynamic responses to
    stimulus features of the audio-description.
    %
    \texttt{geo\&groom} is a combination of
    regressors as used on the positive side of the primary contrasts aimed to
    localize the \ac{ppa} (cf. Table 5 in \citet{haeusler2022processing}.
    %
    The time series of the \ac{cfs} were sliced to match the TRs of the
    audio-description.
    }
    \label{fig:corr-ao-reg-srm}
\end{figure*}




\todo[inline]{Mention negative control?}

\paragraph{Negative control}
% shuffle runs
As a negative control, we randomly shuffled the order of segments of the movie
and audio-description, and the runs of the visual localizer for each training
subject independently before fitting a \ac{srm} to the time series.
% results
Calculations of correlations revealed no or minor correlations between the
shared responses that were calculated based on shuffled time series and the
regressors used in the previous studies.


\subsubsection{Alignment of the test subject}

\todo[inline]{How is it done? srm.transform\_subject calls np.linalg.svd()}

\todo[inline]{in-code documentation says: ``Solve the Procrustes problem''}

% AO: 0-451, 0-892, 0-1330, 0-1818, 0-2280, 0-2719, 0-3261, 0-3524
% AV: 3524-3975, 3524-4416, 3524-4854, 3524-5342, 3524-5804, 3524-6243,
%     3524-6785, 3524-7123
% AO+AV: 0-7123

%
We then used the test subject's response time series of [to?] the visual
localizer, the movie, or the audio-description to align the test subject to the
corresponding \acp{tr} within the \ac{cfs}.
%
For the time series of each paradigm independently, we let the algorithm learn a
orthonormal transformation matrix $W_{n}$ that performs a mapping of the
responses in the test subject's voxel space during the respective paradigm into
the \ac{cfs}.
%
In order to investigate the relationship between the estimation performance [of
the t-contrast's results] and the quantity of data used to acquire a
transformation matrix, we also varied the number of runs per paradigm.
%
In case of \acp{tr} of the visual localizer, we used one up to four runs (each
lasting \unit[5.2]{m} to align the test subject to the corresponding \acp{tr}
within the \ac{cfs}.
%
In case of the naturalistic stimuli, we used one up to eight segments (each
lasting $\sim$\unit[15]{m}) [to align the test subject to the corresponding
\acp{tr} within the \ac{cfs}].
%
Consequently, for every test subject, we obtained four matrices from data of the
visual localizer, and eight different matrices per naturalistic stimulus.
%
Each of transformation matrices has a size of $v$ voxels by $k$ shared responses
but is based on an increasing quantity of data used to calculate the mapping.


\subsubsection{Estimation of $t$-contrasts' results}

\todo[inline]{Not mentioned: I tested averaging data in \ac{cfs}: similar
results; in case of anatomical alignment, I did not test averaging data in
MNI152 space; marked green by mih probably means it should be mentioned}

\todo[inline]{Mention masking shortly (adjust first for anatomical alignment)}

% overview
We then estimated the empirical $Z$-maps of the test subject by projecting all
training subjects' empirical $Z$-maps from their voxel space trough the \ac{cfs}
into the test subject's voxel space.
% functional alignment; into CFS (calling srm.transform(masked\_zmaps))
First, we used the training subjects' transformation matrices that were derived
during training of the \ac{cfs} to perform a mapping of the \textbf{masked}
empirical $Z$-maps from each training subject's voxel space into the \ac{cfs}.
% into subject
Then, we used the transpose of a transformation matrix that was acquired from
the alignment of the test subject in order to project the $Z$-maps from the
\ac{cfs} into the test subject's voxel space.
% take the mean
The arithmetic mean of $N-1$ the projected empirical $Z$-maps served as the
predicted $Z$-map that estimates the test subject's empirical $Z$-map.



\subsection{Pearson \& Cronbach's alpha}

\todo[inline]{merge similar phrased parts}

\todo[inline]{adjust to match contrasts from all paradigms}
%
The prediction performance is assessed by calculating the Pearson's correlation
coefficient between a left-out subject's empirical $Z$-map and predicted
$Z$-map, and compared to the prediction performance based on a voxel-based
anatomical alignment procedure.

% Pearson's
In order to quantify the estimation performance based on the functional and
anatomical alignment procedure, we calculated the Pearson's correlation
coefficients as a measure of similarity between the empirical $Z$-maps gained
from the localizer experiment and the predicted $Z$-maps.

% Cronbach's Alpha
Further, we calculating Cronbach's Alpha across the four runs of the localizer
as a measure of internal consistency (i.e.  reliability) and proxy for noise
ceiling of the visual localizer.
%
``We reasoned that across-subject variability cannot be expected to be lower
than within-subject variability over time (reproducibility)''
\citep{rosenke2021probabilistic}.


\subsection{Backup: alternative template creation}

\todo[inline]{imo, this part should be dropped but anyway...}

\todo[inline]{iirc, I projected all subjects' localizer time series through
model space into test subject voxel space; then, calculated the contrast
with these data}

\todo[inline]{s. scripts 'test/data\_denoise-vis.py' \& 'test/data\_srm-vis-to-ind.py'}

\todo[inline]{the problem was: if one wants to test the different transformation
matrices (I only did it with one; imo, based on alignment using the whole
audio-description) it gets totally messy \& computational intensive}

\todo[inline]{results: performance was the same if not slightly worse}



\section{Results}

\todo[inline]{as I see it, this section is (gonna be) pretty short...}

\todo[inline]{statistical test of differences for prediction from alignment via
localizer runs}

\todo[inline]{finalize 'statistics\_t-test-correlations.py' (!), and write the
text/numbers here; do not forget to mention that correlations were
Fisher-transformed (which Jiahu did not)}


Unthresholded $Z$-maps [in each subject's voxel space] can be found at
\href{https://identifiers.org/neurovault.collection:12340}{\url{neurovault.org/collections/12340}}.
%
Pearson correlation coefficients between empirical $Z$-maps (results of
localizer; y-axis) and estimated $Z$-maps (see Fig.~\ref{fig:stripplot}).



\begin{figure*}[tbp] \centering
    \includegraphics[width=\linewidth]{figures/stripplot.pdf} \caption{
    %
    \textbf{Correlations between empirical and predicted
    \textit{\textbf{Z}}-maps.}
    %
    Grey dots: A left-out subject's $Z$-map was estimated by projecting all
    other subjects ($N = 13$) $Z$-maps through the MNI152 space into the
    left-out subject space and averaging values across subject; correlations
    between empirical values from the localizer \& the predicted values using
    anatomical alignment.
    %
    Green dots: estimation from visual localizer.
    %
    Blue dots: transformation matrices computed based on an increasing number of
    segments of the audio-description; correlations between empirical values \&
    the predicted values using parts of the audio-description.
    %
    Red dots: transformation matrices computed based on an increasing number of
    segments of the movie; correlations between empirical values \& the
    predicted values using parts of the movie.
}
\label{fig:stripplot}
\end{figure*}


\subsection{Template(s) from from \citet{jiahui2020predicting}}

%
``After 2-step hyperalignment, the mean Pearson correlation values between
face-selectivity maps based on a participant's own localizer data and the
predicted map after hyperalignment were 0.55 (N = 15, S.D. = 0.08).
%
With surface alignment, the average Pearson correlation values across
participants were 0.40 (N = 15, S.D. = 0.08) in the studyforrest dataset (Fig.
3).
%
The difference between the hyperaligned and the surface-aligned mean correlation
values was highly significant (studyforrest: t(14) = 17.39, p < 0.001)''
\citep{jiahui2020predicting}.



\subsubsection{Cronbach's Alpha}

\todo[inline]{Cronbach's alpha could be plotted as dot per subject in the
stripplot (which is gonna be messy) or the average (Fisher's transformed?)
could be plotted as a horizontal line (s. Fig 2 in
\citet{jiahui2020predicting})}


\paragraph{Template from \citet{jiahui2020predicting}}
%
``We compared the correlations between maps estimated from a participant's own
data and maps estimated from other participants' data to the reliability of the
localizer.
%
We computed the reliability of the contrast maps with Cronbach's Alpha based on
variability across the four localizer runs for each set.
%
The mean Cronbach's Alpha between the four localizer runs was 0.60 (N = 15, S.D.
= 0.14)'' \citep{jiahui2020predicting}.

%
``These results mean that if we scan each participant for another 4 localizer
runs, and compute the correlation between the two maps (4 runs vs. 4 runs), the
correlation would be 0.60 on average in the studyforrest''
\citep{jiahui2020predicting}.
%
``Cronbach's alpha indicates that the predicted contrast map based on
hyperalignment is close to or as good as the real contrast map based on four
localizer runs (studyforrest: t(14) = 0.61, p = 0.55; Grand Budapest: t(20) =
3.02, p = 0.007)'' \citep{jiahui2020predicting}.

%
``The predicted contrast map based on hyperalignment was better than the
contrast map based on data from three out of four localizer runs in other
participants (t(14) = 2.36, p = 0.03) and in Grand Budapest, the predicted
contrast map was comparable to the contrast map based on three localizer runs in
other participants (t(20) = 0.48, p = 0.63)''
\citep{jiahui2020predicting}.\todo{what?}


\subsection{plot\_bland-altman.py}

\todo[inline]{I hate that script! Hence, it should not be included ;-).}

\todo[inline]{mih: but results?}

\subsection{Plots of brain slices?}

\todo[inline]{iirc, we agreed on that it's not necessary}





\section{Discussion}

\todo[inline]{mih: many points discussed in the discussion should already be
primed in the intro to better frame the problem space, challenges, and
opportunities}


\subsection{Short summary of aims \& hypotheses, method, results}

\todo[inline]{to be written}

%
\paragraph{Methods} We used the union of individual \ac{ppa} ROIs as an
probabilistic functional atlas in order to restrict the number of voxels to
voxels that have shown to be located in the \ac{ppa} \ac{roi} of at least one
subject.


\subsection{We created one "multi-stimulus" model}

\subsubsection{Previous studies}

Previous studies \citep{guntupalli2016model, haxby2020hyperalignment} that
focused on the validity and generalizability of the \ac{cfs} have shown that:
%
``The algorithm also can be applied to simpler, controlled experimental data,
but our previous results showed that the sampling of response vectors from these
experiments is impoverished and produces a model representational space that
does not generalize well to new stimuli in other experiments (Haxby et al.
2011)'' \citep{guntupalli2016model}.
%
``Hyperalignment of data using a set of stimuli that is less diverse than the
movie is effective, but the resultant common space has validity that is limited
to a small subspace of the representational space in VT cortex''
\citep{haxby2011common}
%
``Estimating the parameters to transform high-dimensional spaces from individual
brains into a common high-dimensional space requires a rich set of data that
samples a wide variety of cortical patterns in order to generalize to novel
stimuli or tasks'' \citep{haxby2020hyperalignment}, ``presumably because such
experiments sample a sparser range of brain states
\citep{guntupalli2016model}''.


\subsubsection{We: "multi-stimulus" model}

We create one \ac{cfs} (for every fold) based on time-series of three stimuli
that were concatenated before model fitting.

%
Results indicate that we are able to use data from a group of 13 participants to
learn a 10-dimensional shared space.
%
Enabled us to have cross-subject, cross-experiment, [and cross-scanner
prediction]
%
Movie data and visual localizer are from the same scanner but not from the same
session [???].


\subsubsection{We: alignment via three paradigms}

The \ac{srm} algorithm can be applied to functional data from traditional
paradigms using controlled stimuli.
%
However, previous studies \citep{guntupalli2016model, haxby2011common} that
suggest that \acp{cfs} and transformation matrices derived from traditional
paradigms are of diminished validity and a diminished generalizability to other
paradigms, presumably because traditional paradigms sample a sparser range of
brain states than naturalistic stimuli.
%
Hence, we let the \ac{srm} derive a test subject's transformation matrix from
data of the visual localizer paradigm, and compare prediction based on these
matrices to the prediction performance based on transformation matrices that
we derive from the naturalistic stimulus paradigms.


\subsubsection{We: partial alignment}

\todo[inline]{to predict using the model you don't need the same amount of data;
I checked how much data you need (s. Figure in results)}

%
We also performed functional alignment based on a stimulation paradigm using
simplified stimuli [the localizer].
%
Our results provide evidence that transformation matrices calculated based on
data from naturalistic stimuli promise an increased validity of derived
transformation for functional alignment over transformation matrices based on
data (of the same!) paradigm based on simplified stimuli.



\subsection{Estimation of visual localizer}

\todo[inline]{Evaluation of same modality / criterion (visual localizer)
using different predictors (localizer, movie, audio-description)}

\todo[inline]{How good is which stimulus to perform alignment to that model?}

\subsubsection{Assumption that localizer is "ground truth"}

%
``The PPA definition may depend on the type of experiment, task, and stimuli
used'' \citet{weiner2018defining}.
% usually, visual PPA works pretty well
The visual \ac{ppa} can be reliably localized using a localizer.
%
For example, \citet{zhen2017quantifying} successfully delineated the left- and
right hemispheric \acp{ppa} in 97.5\% of 202 subjects.
% localizer data
\citet{sengupta2016extension} successfully delineated the left-hemispheric
\ac{ppa} in X of X subjects and right-hemispheric \ac{ppa} in X of X subjects
based on localizer data


\subsubsection{visual localizer via localizer runs}


\subsubsection{visual localizer via movie segments}

%
Results indicate that $\sim$15 minutes of movie watching used for functional
alignment outperform prediction using anatomical alignment.
%
Prediction performance further increases when $\sim$30 minutes of movie data
submitted to the algorithm to calculate the subject-specific transformation
matrices.
%
However, more than $\sim$45 minutes do not lead to an significantly increased
estimation performance suggesting a decreasing benefit of longer scanning time
than 30 minutes during audio-visual naturalistic stimulation.


\subsubsection{visual localizer via audio-description segments}



\subsection{Interim summary \& transition to movie \& audio PPA}


\subsubsection{One "multi-stimulus" model}

\todo[inline]{Naturalistic is awesome for the model; cf. literature}

Generalizability



\subsubsection{Partial alignment}

\todo[inline]{Naturalistic is awesome for alignment, too}

%
Data efficiency; reduced costs.

%
There is a benefit of shared parts of naturalistic stimuli across datasets;
shared stimulus part is easier than shared subjects
\citep[e.g.][]{zhang2018transfer}.


\subsubsection{Naturalistic stimuli are awesome}

% from project proposal
Compared to paradigms with simplified stimuli, naturalistic stimuli sample a
broad range of brain states \citep{guntupalli2016model, haxby2011common} that
reflect (confound) statistics of the natural environment, promising an increased
validity of transformations of functional alignment, and enable investigation of
the acquired data for a variety of research questions to research
questions/domains/paradigms (e.g.  visual or auditory perception, spatial
cognition; emotion; music, speech or social perception).



\subsection{Estimation of movie PPA}

\todo[inline]{evaluation of other modality / criterion (movie \& audio PPA)}

\todo[inline]{Well, how reliable is the localization of movie PPA across
segments?}

% movie
Despite an adventurous operationalization, \citet{haeusler2022processing}
delineated the left-hemispheric \ac{ppa} in X of X subjects and
right-hemispheric \ac{ppa} in X of X subjects based on movie data.
%
Which actually should not matter, because the \ac{srm}/transformation matrices
do not care about the operationalization but about a voxels responses time
series across the whole stimulus.

\subsubsection{movie PPA via movie segments}

\subsubsection{movie PPA via localizer runs}

\subsubsection{movie PPA via audio segments}

\subsubsection{Interim summary of movie PPA}



\subsection{Estimation of audio PPA}

\todo[inline]{check subjects who do not have an "auditory PPA":
    is prediction performance also worse in the (audio-)visual \acp{ppa}?
    a) is the (average) response to spatial events just poorly modeled in
    \citet{haeusler2022processing} (wrong assumption of process and / or
    relevant events?), or
    b) is the response pattern simply not captured by the \ac{srm}
    }

% audio-description
Using the audio-description's data, \citet{haeusler2022processing} delineated
the left-hemispheric \ac{ppa} in X of X subjects and right-hemispheric \ac{ppa}
in X of X subjects.
%
Results of \citet{haeusler2022processing} suggest that selected events embedded
in an auditory stimulation is correlated with increased hemodynamic activity in
the anterior parts of the \ac{ppa} as it was defined by the localizer.
%
Results could be influenced by paradigm and methodological choices.
%
For example, we might have modeled the time course of "spatial responses"
"insufficiently" in \citep{haeusler2022processing}.
%
However, our current results suggest that ``the training stimuli or trials
strongly and variably engage that process in a way that is reliable across
participants'' in such a way that the ``SRM will improve sensitivity for
detecting a cognitive process of interest in the test data''
\citep{cohen2017computational}.


\subsubsection{audio PPA via audio segments}

\subsubsection{audio PPA via movie segments}

\subsubsection{audio PPA via localizer runs}

\subsubsection{Interim summary of audio PPA}

\todo[inline]{movie works better for movie and localizer \ac{ppa}}
\todo[inline]{audio-description works better for audio \ac{ppa}}

%
Present results add evidence that the responses to auditory spatial information
lead to different activity patterns than visual stimulation [cf. interpretation
in \citet{haeusler2022processing}] and results in \citet{haeusler2022processing}
are not based on the modeling choices?



\paragraph{Individual differences}

\todo[inline]{the text regarding individual differences in brain
activation possibly correlating with behavior is in general discussion}

%
Responses in \ac{ppa} during auditory stimulation might (actually / reliably) be
different (and not just a result that depends on the paradigm and the hilarious
modeling approach in \citet{haeusler2022processing}).
%
If the response pattern is reliably not occurring in these subjects then
individual differences in brain patterns might reflect differences in behavior.
%
Do the subjects simply do not give a shit about auditory spatial information?
%
Are they simply not attending to it? Or are they simply incapable to process it?


\subsubsection{Application of narrative for visually impaired?}

\todo[inline]{Better, if at all, mention that in thesis' general discussion}


\begin{itemize}

\item congenitally blind:
    Mahon et al. 2009;
    Bedny et al. 2011;
    Striem-Amit, Cohen, et al. 2012a;
    van den Hurk et al. 2017
    [cf. \citet{rosenke2021probabilistic}]

\item individuals with visual agnosia/prosopagnosia:
    Schiltz and Rossion 2006;
    Steeves et al. 2006;
    Sorger et al. 2007;
    Barton 2008;
    Gilaie-Dotan et al. 2009;
    Susilo et al. 2015
    [cf. \citet{rosenke2021probabilistic}]

\end{itemize}

\subsection{Discussion across predicted localizer, movie PPA \& audio PPA}


\subsubsection{Vision: functional atlas}

\todo[inline]{mih: this chapter does not need its own outlook; outlook will
be in the general discussion anyway (and is more interesting there)}

\todo[inline]{a smallish text should be sufficient here; shift most stuff into
general discussion (and write intro in general intro)}

\todo[inline]{check discussion of \citet{jiahui2020predicting} as last resource}


\subsubsection{Time, money, questionable compliance / capability}

``Identifying all of the currently known topographic regions of the human visual
system requires multiple scanning sessions.
%
Given the expense and availability of fMRI, this is not always practical.
%
An atlas can be used under conditions in which collecting the data to define
maps in individual subjects is impractical or not feasible
%
For example, time-limitations and subject-fatigue both potentially limit the
time researchers may be able to spend with patients suffering from neurological
or neuropsychological disorders, or with implanted subdural or deep electrodes
(e.g., ECoG)'' \citep{wang2015probabilistic}.


\paragraph{Probabilistic (anatomical) atlases: use cases}
%
``One way to address limitations [of conducting many localizers] is to create an
atlas in a standard space that links individual points in that space with
functionally defined regions.
%
Given the anatomical and functional variability across subjects, this atlas
should be "probabilistic":
%
it defines the likelihood of a given coordinate being associated with a given
functional region. [our functional alignment procedure can improve these atlases
by providing $z$-values]
%
Such an atlas could be used to infer the topographic location in the visual
system for the results obtained from any independent dataset once transformed
into the same standard space as the atlas'' \citep{wang2015probabilistic}.

%
``Individual \acp{roi} and associated features could serve as a database of the
\acp{roi} in a healthy population.
%
The accumulated data in the atlas could be used as a norm to quantify the degree
of deviation of the FSRs in a new subject and thereby have the potential to
detect deficits in patients'' \citep{zhen2015quantifying}.

%
Atlases ``may prove especially useful for predicting an ROI when no localizer
data is available, saving scanning time and expenses, or
%
patient populations, such as patients who
%
\begin{enumerate}

\item are blind [
        Mahon et al. 2009;
        Bedny et al. 2011;
        Striem-Amit, Dakwar, et al. 2012b;
        van den Hurk et al. 2017
    ] \citep{rosenke2021probabilistic}

\item have a brain lesion [
        Schiltz and Rossion 2006;
        Steeves et al. 2006;
        Sorger et al. 2007;
        Barton 2008;
        Gilaie-Dotan et al. 2009;
        de Heering and Rossion 2015
    ] \citep{rosenke2021probabilistic}

\item are even more blind [
        Amedi et al., 2007;
        He et al., 2013;
        Mahon et al., 2009;
        Wolbers et al., 2011
    ] \citep{weiner2018defining}

\item undergo intracranial studies in which it it may not be possible to obtain
    fMRI data, but high resolution anatomical MRI data are typically obtained [
        Bastin et al., 2013;
        Davidesco et al., 2013;
        Engell and McCarthy, 2010;
        Jacques et al., 2015;
        Megevand et al., 2014;
        Murphey et al., 2009;
        Rangarajan et al., 2014
    ] \citep{weiner2018defining}

\end{enumerate}


``Cortical atlases have been developed, which allow localization of visual areas
in new subjects by leveraging ROI data from an independent set of typical
participants [
    %
    Frost and Goebel 2012;
    %
    ventral temporal cortex (VTC) category selectivity:
    %
    Julian et al. 2012;
    Zhen et al. 2017;
    Weiner et al. 2018;
    %
    visual field maps:
    Benson et al. 2012;
    Benson and Winawer 2018;
    Wang et al. 2015]'' \citep{rosenke2021probabilistic}.



\subsubsection{Now: functional alignment}
%
Previous studies used anatomical alignment in order to project data from
probabilistic functional atlases (aligned to a \ac{cas}) onto individual
subjects in order to predict the location of functional areas in new/unknown
subjects.
%
Anatomical alignment (used to create the probabilistic atlases above) relies on
data of an anatomical MRI scan that performed as an standard routine
before/after functional brain scans using fMRI.
%
Our procedure relies on data of a functional scan session during naturalistic
stimulation.
%
But...


\paragraph{We do not just provide binary decision}

\todo[inline]{Why is estimation of pattern better than just estimation of ROI
yes vs. no?}

%
We provide patterns that allow more than just localization but e.g.,
classification and...?


\paragraph{Partial alignment would lower scanning time}
%
Our results suggest that a \textit{calibration scan} could be used to align a
subject to a fixed \ac{cfs} based on extensive scans and analyses of other
subjects' data serving as a reference / functional atlas.
%
Similar to the standard procedure of a anatomical scan, additional 15 minutes
functional scanning using an engaging naturalistic stimuli could provide
sufficient data to perform a functional alignment to a functional atlas.

\subsubsection{\ac{fmri} scan session using naturalistic stimulus could
substitute multiple localizers}


\paragraph{Database with naturalistic stimulus as main stimulus...}
%
Naturalistic stimuli ``engage in parallel multiple neural systems for vision,
audition, language, person perception, social cognition, and other functions''
\citep{jiahui2020predicting} and offer higher generalizability [and provide
higher validity?] of transformations matrices.

%
A naturalistic stimulus like a move or audio-description could be used to align
a test subject to a \ac{cfs} created from data of a normative reference group.
%
The reference group requires a ``database of data for movies and a range of
functional localizers in a normative group of subjects''
\citep{jiahui2020predicting}.

%
Once a valid alignment is established, known functional properties of the
(normative) reference can then be projected into the respective individual voxel
space (s. Fig. 1 in \citep{nishimoto2016lining}) by mapping a variety $Z$-maps
created from a variety of $t$-contrast from a normative reference group onto an
individual subjects and thus potentially substitute a variety of localizers.

%
``A new subject's functional topographies could be estimated based only on that
subject's movie data and other subjects' localizer data from the normative
database that could be projected into that subject's cortical anatomy using
hyperalignment transformation matrices derived from movie data and could replace
tedious functional localizers with an engaging movie''
\citep{jiahui2020predicting}.

%
``Functional topographies could be mapped from a database containing a wide
range of perceptual and cognitive functions to new subjects based only on fMRI
data collected while watching an engaging, naturalistic stimulus and other
subjects' localizer data from a normative sample'' \citep{jiahui2020predicting}.

% from Jiahu
``From a single movie dataset multiple functional topographies can be estimated
\citep{guntupalli2016model}, whereas different localizers are typically required
to map different functional topographies, making a thorough mapping of selective
topographies time-consuming and inefficient'' \citep{jiahui2020predicting}.

%
That reference would enable an qualitative and quantitative description of an
individual's brain function with respect to such a norm, and consequently
progress the field towards neuroimaging studies of individual differences that
more closely resemble their psychological counterparts.


\paragraph{Additional advantages of naturalistic stimuli: compliance!}
%
``Compared with functional localizers, naturalistic stimuli provide several
advantages such as stronger and widespread brain activation, greater engagement,
and increased subject compliance'' \citep{jiahui2020predicting}.
%
``Movies are more engaging and result in better compliance
\citep{vanderwal2015inscapes}.
%
Movie viewing can also be used in subject populations, such as children
\citep{richardson2018development} or patients, that may have trouble maintaining
attention during repetitions of a tedious localizer task''
\citep{jiahui2020predicting}.

%
On the one hand, an engaging naturalistic stimulus before the main experiment
would have the benefit of putting a study participant at ease and letting the
subject accommodate to the scanner environment).
%
On the other hand, an engaging naturalistic stimulus after the main experiment
would not suffer less from fatigue than a one localizer or even a localizer
battery demanding voluntary attention and handling a repetitive task.


\subsubsection{Clinical Application}

\todo[inline]{cf. general introduction}

``To be useful for clinical diagnostics and prognostics, fMRI data must be
interpretable on the level of the individual case \citep{dubois2016building}.
%
In the clinical context, fMRI plays an important role for planning surgery in
patients with tumors or epilepsies, as it aids the understanding of which parts
of the brain need to be spared in order to preserve sensory, motor or cognitive
abilities'' \citep{wegrzyn2018thought}.



\subsection{Differences to studies creating probabilistic atlases}

\todo[inline]{Following are "notes" that can heavily be shortened to 1-2
paragraphs}

\subsubsection{We need fMRI not just MRI}

\todo[inline]{should already be clear from discussion on partial alignment}

%
Compared to estimation procedures based on anatomical alignment (i.e.
\citep{weiner2018defining}), the current estimation procedure needs an
additional functional scan.


\subsubsection{No cherry picking of subjects}

\todo[inline]{actually, that's pretty cool; could be mentioned at some
locations}

%
Compared to other studies [which studies did it?], we did no cherry picking by
excluding subjects that did not provide a functional \ac{roi} in one or both
hemisphere in the functional localizer [or naturalistic stimulus paradigms]
before calculating the \ac{cfs}.


\subsubsection{$Z$-maps in a \ac{roi}}

\todo[inline]{what could you do with $Z$-maps except creating binary ROIs:
classification etc.?}



%
We estimate $Z$-maps, whereas other estimate based on a binary decision if a
voxels belongs to the \ac{roi} or not.
%
Our approach does not only ``contain unique tiling of cortical regions
but also allows for multiple functional clusters to occupy overlapping
areas'' [phrasing taken from \citet{rosenke2021probabilistic}].


\subsubsection{Others: hand-picked \acp{roi}}

%
``ROIs where manually defined in individual subjects on their cortical surface
reconstruction in anatomically plausible locations''
\citep{rosenke2021probabilistic}.

%
``Functional areas of interest were determined by selecting the activity cluster
on the surface falling in the region reported in previous standard localizer
studies'' \citep{frost2012measuring}.

%
``We used the conventional approach of drawing are borders by hand.
%
At least 2 experimenters experienced in retinotopic mapping drew borders
independently using the same set of published criteria (detailed below)''
\citep{wang2015probabilistic}.

%
``Subject-specific scene-selective regions were delineated manually in the
parcel unit based on the individual activation map from the contrast of scenes
versus objects'' \citep{zhen2017quantifying}.


\paragraph{Threshold is problematic}

%
``The choice of the threshold in localizing the face-selective regions
inevitably influenced the amount of variation in the location of the
face-selective regions'' \citep{zhen2015quantifying}.

%
``In the outlined procedure the extent of identified clusters (and thus the
overlap calculation) depended on subjectively determined thresholds''
\citep{frost2012measuring}.

%
``Decisions such as the statistical threshold used, the precise contrast, or the
amount of spatial smoothing influence the spatial extent of the (p)ROI on the
cortical surface'' \citep{weiner2018defining}.
%
\citet{weiner2018defining} identified place-selective voxels ``within each
subject's native brain anatomy using a common threshold (t > 3, voxel-level)''.

%
\citet{rosenke2021probabilistic} ``selected a statistical threshold of t=3 for a
whole-brain map''.


%
``The subject-specific activation image was first thresholded (Z>2.3,
uncorrected).
%
Thresholded activation images were partitioned into many small parcels using the
watershed algorithm [Meyer, 1994].
%
Raters handpicked the parcels on the individual activation map to construct the
scene-selective regions following a standard procedure:
%
1) gyri and sulci from MNI152 template were used as the anatomical landmarks to
locate the scene-selective regions.
%
2) we used the scene-selective regions group labels (the functional landmark) as
a spatial extent reference (the major part of each candidate parcel overlapped
with or neighbored to the corresponding functional label).
%
3) From the parcels that showed good correspondence to both anatomical and
functional landmarks, we identified the one with the strongest scene-selective
activation as the center of a scene-selective region, and iteratively merged the
parcels which connected with the selected parcels into the regions until no
candidate parcels met the criteria'' \citep{zhen2017quantifying}.


\subsubsection{Others: probabilistic atlas in common common anatomical space
(CAS)}

%
``Probabilistic maps were generated by summing the 12 fROIs [from 12
participants] at each point along the cortical surface of the FreeSurfer average
brain and dividing by the number of participants.
%
Each vertex within the map reflects the proportion of participants exhibiting
place selectivity at that location on the cortical surface''
\citep{weiner2018defining}.

%
``Probabilistic ROIs were generated using three different thresholds to test if
and how different threshold values influence the predictability of place
selectivity in a new group of participants.
%
(1) unthresholded,
%
(2) thresholded by 33\% overlapping participants, or
%
(3) thresholded by 66\% overlapping participants.
%
Since the 33\% thresholded pROI performed the best in the prior analyses [Weiner
et al., 2017], we used this threshold for the present (and subsequent)
analyses'' \citep{weiner2018defining}.

%
``Results revealed high predictability in the right and left hemisphere (about
0.70), which was not different than the ceiling performance (all ts < .7, all ps
> .5; Fig. 2D).
%
Cross-validated performance from 23 participants is not significantly different
than the ceiling performance.
%
This provides statistical evidence supporting that the structural-functional
predictability from our participants likely reflects a predictability that is
reflective of the general population'' \citep{weiner2018defining}.

%
``We computed the overlap of functional areas across subjects for vertices
belonging to a POI of at least one subject to constitute the probabilistic map
for a particular localized region-of-interest using the formula: Nv/N.
%
Nv is the number of subjects whose functional area includes vertex v,
%
N is the number of subjects.
%
An overall probabilistic map is obtained by adding the resulting overlap vertex
values for all included POIs.
%
A threshold of N=10\% is applied to all probabilistic maps to avoid depicting
regions as "overlap" where only one subject has a functional area''
\citep{frost2012measuring}.


%
``A probabilistic atlas (or map) was created for each scene-selective region by
calculating the frequency of a respective SSR being present at a given position
across all subjects'' \citep{zhen2017quantifying}.
%
``The map coded the occurrence probability of each voxel being located in the
SSR, and provides a voxel-wise description for inter-individual variability in
the location and extent'' \citep{zhen2017quantifying}.


%
``For each FSR, a probabilistic map was created to characterize the likelihood
that a given voxel belonged to that FSR.
%
The subject-specific FSR delineated in individual brains were averaged in the
MNI152 space so that the value at any voxel coded the likelihood of the voxel
being located in the FSR, thus giving a measure of the variability in location
and extent of the FSR over subjects at voxel-level resolution''
\citep{zhen2015quantifying}.
%
``
High interindividual variability was observed for all FSRs: no one voxel showed
a 100-percent chance of being in one of the FSRs across subjects.
%
Maximum probability that a voxel belonged to an FSR ranged from 0.24 (left aFFA)
to 0.74 (right pSTS) (Table 1)'' \citet{zhen2015quantifying}.



\subsubsection{Others: binary prediction (quantified by Dice)}

%
``The atlas accurately predicts the location [but just the location] of an
independent dataset of ventral temporal cortex ROIs''
\citep{rosenke2021probabilistic}.

%
``We identify and predict the most probable location of place-selective voxels
within medial VTC of an individual brain'' \citep{weiner2018defining}.
%
``Results suggest that our pROI of place selectivity provides a robust
prediction of the location of high place selectivity within medial VTC''
\citep{weiner2018defining}.


%
\citet{weiner2018defining} ``calculated the Dice coefficient to assess the
correspondence between the probabilistic ROI and individually-defined ROIs in
independent participants'' and ``to quantify how well pROIs predict
functionally-defined ROIs in an independent group of participants.''
\citep{weiner2018defining}.
%
``The Dice coefficient is a measure of similarity of two sample and calculated
with the following formula:
%
P is the surface area of the probabilistic ROI.
%
A is the surface area of the actual ROI in an individual subject.
%
Perfect alignment between the probabilistic prediction and the actual ROI in
individual subjects would result in a Dice coefficient of 1 (perfect
predictability) and complete misclassification would result in a Dice
coefficient of 0 (no predictability)'' \citep{weiner2018defining}.
%
We measured cross-validation performance at three threshold level:
%
a) no threshold, b) 33\%, and c) 66\%
%
using group pROIs from Study 1 and individual ROIs from Study 2 and vice versa.
%
The ceiling Dice coefficient in our data is 0.73 in the left hemisphere and 0.72
the right hemisphere'' \citep{weiner2018defining}.

``Results of the cross-validation analysis reveal that our pROI predicts
individual ROIs with high accuracy across hemispheres.
%
The unthresholded ROI had the lowest predictability (about 0.56 left and right)
%
The 66\% thresholded ROI had an intermediate predictability (about 0.60 left and
right)
%
All were significantly lower than the ceiling performance (all ts > 4.5, all ps
< 10-4).
%
At a threshold of 33\%, the Dice coefficient is 0.70 +/- 0.03 in the right
hemisphere and 0.65 +/- 0.03 in the left'' \citep{weiner2018defining}.

%
``We calculated the Dice coefficient using different thresholds for the
probabilistic group map:
%
from a liberal unthreshold: one subject at a given voxel/vertex is enough to
assign it to the group map;
%
to a conservative threshold: all N-1 subjects had to share a voxel/vertex to be
assigned to the group map'' \citet{rosenke2021probabilistic}.


\paragraph{Probabilistic atlas is problematic when \acp{roi} overlap}
%
``We generated a maximum probability map (MPM) of each area in order to assign a
unique functional label to each vertex in the atlas by comparing the
probabilities of all areas at that node and assigning the node to the area with
the highest probability.
%
We determined which vertices were shared by more than one probabilistic fROI and
assigned these vertices to a single fROI based on the area that showed the
highest probability at that vertex'' \citep{rosenke2021probabilistic}.
%
``
In the case of an activation cluster transitioning into an adjacent one of the
same visual category, we divided those clusters into separate ROIs by following
the spatial gradient of t-values and separating the two areas at the lowest
t-value'' \citep{rosenke2021probabilistic}.


%
``Because the probabilistic maps of adjacent scene-selective regions (e.g., PPA
and RSC) overlapped to some degree in the periphery, a maximum-probability map
(MPM) was then created to obtain an integrated, non-overlapping map for all
scene-selective regions'' \citep{zhen2017quantifying}.
%
Maximum-probability maps define the most likely scene-selective region to
which each voxel belonged.
%
Each MPM integrates the multiple probabilistic scene-selective region maps into
one map, and to characterize the spatial relations among SSRs:
%
We compared each voxel's values from each probabilistic map, and assigned that
voxel to the SSR which showed the highest probability at the voxel.
%
The voxels with a maximal probability below 10\% were set to 0, indicating that
they most likely did not belong to any SSR'' \citep{zhen2017quantifying}.


\paragraph{Selectivity-map by \citet{weiner2018defining}}
%
``The question is whether this pROI captures the 'peak' voxels exhibiting the
highest place selectivity in medial VTC.
%
The map of pROIs across subjects is generated after assigning either a 1 (if the
ROI is present) or a 0 (if the ROI is not present) at vertices of the FS average
surface.
%
In the pROI case, there is a threshold and the group map does not reflect
selectivity and instead represents the percentage of overlap across subjects at
each vertex.
%
We generated an average map of selectivity in which vertices are assigned
continuous values of place selectivity rather than a binary distinction as in
the probability maps from the prior analyses.
%
The selectivity map reflects a continuous metric in which a vertex is assigned a
selectivity value (a t-statistic) first for each subject and then averaged
across subjects.
%
The selectivity map is not thresholded and the group map directly indicates
selectivity (each vertex reflects the average t-value across subjects)
%
We then visualized the group place selectivity map relative to the group pROI
from all 24 participants (Fig. 4).
%
Weakly place-selective voxels (t-values greater than 0 and less than 2) extend
into the medial fusiform gyrus and more posteriorly along the CoS.
%
The locus ("hotspot") of peak place selectivity is near the medial lip of the
CoS in the right hemisphere and close to the center of our pROI near the fundus
of the CoS in the left hemisphere (Fig. 4A)'' \citep{weiner2018defining}.
%
``Examining the location of our pROI relative to the peak cluster of place
selectivity in individual participants shows that there are individual
differences in the location of voxels with highest place selectivity (Fig.
4B-C):
%
Voxels with the highest place selectivity are not always located within the same
exact location in the pROI for each participant and small clusters of high place
selectivity can also extend outside of the pROI.
%
Despite these individual differences, all participants have voxels with the
highest place selectivity within the pROI''
\citep{weiner2018defining}.


\subsection{Shortcomings}


\subsubsection{Sample size}

\todo[inline]{cf. variability of the \ac{cfs}}

\todo[inline]{can/should that variability somehow be quantified?}

% what is the case
The correlations of shared responses within the \acp{cfs} created from $N-1$
training subjects varied across the folds of the cross-validation.
% interpretation
That means, a change of 1/13 of the data for every subject's analysis is causing
the estimates to vary [how much?].
% conclusion
Future studies, should create a \ac{cfs} based on data from more subjects and
investigate the relationship between number of participants, variability of
parameters, and estimation performance.



\subsubsection{Leakage of test data in union of individual \acp{ppa}}
%
We used the union of individual \acp{ppa} as spatial constrain for $Z$-maps.
%
But we have a leakage of test data (test subject is in data for the mask).
%
We might miss some voxels (of some participants) at the borders of the \ac{roi},
because the subject-specific, binary masks are based on a ("titrated")
threshold.  \citep{sengupta2016extension}
%
In the future, an independent probabilistic atlas should be used, the \ac{roi}
dilated, [and a separate model calculated for each hemisphere].



\subsubsection{Shared responses are problematic in case of atypical organization
/ outliers}

\todo[inline]{Fits in here or in "future question" regarding "other functional
alignment algorithms". In any case, it's a nice transition from "shortcomings"
to "future questions"}

\todo[inline]{We: matrices for individual mapping; but onto shared responses}

\todo[inline]{Maybe, we get a pattern of "what it should look like if the person
was an average person"? What could you do with that (in a clinical context?)}

We have a non-clinical sample of subjects but variability (especially in case of
auditory PPA).


\paragraph{Rationale of SRM}

%
``The flip side of focusing on shared responses is to focus on responses that
are idiosyncratic to individuals'' \citep{cohen2017computational}.
%
``Although these idiosyncratic responses are excluded in SRM, they are not
necessarily noise and may in fact be highly reliable within participants''
\citep{cohen2017computational}.
%
``SRM can be used to isolate participant-unique responses by examining the
residuals after removing shared group responses, or it can be applied
hierarchically to the residuals to identify subgroups [\citet{chen2017shared}]
'' \citep{cohen2017computational}.

%
``In cases where each subject's unique response is of more interest than the
shared signal, SRM can be used to factor out the shared component thereby
isolating the idiosyncratic response for each subject
[\citep{chen2015reduced}]'' \citep{kumar2020brainiak}.

%
``Recognizing that signal exists beyond the average or shared response of a
group, such studies exploit idiosyncratic but stable responses to account for
previously unexplained variance in brain function, behavioral performance and
clinical measures [e.g., Finn (2015). Functional fingerprinting (based on
connectivity)]'' \citep{cohen2017computational}.


\paragraph{Applied to our results}

\todo[inline]{Following are just some templates for inspirational purposes}

%
``Variability was observed from a cohort of homogeneous young adults with a
narrow age range, which limits the generalization of the variability observed
here to people with different ages, especially children and the elderly''
\citet{zhen2017quantifying}.


\citet{benson2018bayesian}: ``We developed using data from a small subset of the
population (8 subjects).
%
It is unclear how our method would cope with subjects whose retinotopic
organizations are much different than those that are typically assumed in vision
science.
%
Such edge-case subjects could include members of clinical populations, such as
individuals lacking an optic chiasm [Hoffmann et al., 2012; Bao et al., 2015;
Olman et al., 2018], or healthy individuals whose retinotopic boundaries are
merely unusual [Van Essen and Glasser, 2018]'' \citep{benson2018bayesian}.



\subsection{Future questions}

\todo[inline]{cf. \citet{bazeille2021template}'s dissertation}

The SRM is computationally less demanding [= "computationally more efficient"?]
than hyperalignment, an advantage for scientists who want to replicate our
results but do not have access to a high-performance computer cluster [or
"high-throughput computer cluster" or simply "specialized hardware"?].


\subsubsection{Volume- vs surface-based}

\todo[inline]{imo, should not be a problem; our approach might even be "better"
because more "sparse": we are nearer on the raw data 'cause we work with voxels
(not vertices), and both our anatomical and functional alignment use voxels as
input (i.e. it is not mixed)}

\todo[inline]{funnily, most studies that estimated functional areas compared
surface-based alignment to affine volume-based alignment...}

We compare volume-based [nonlinear] anatomical alignment to volume-based
functional alignment.
%
Future work could compare surface-based alignment that respects cortical folding
structure -- that out-performs predictions based on [affine] volume-based
anatomical alignment \citep{weiner2018defining} -- to surface-based functional
alignment.


\subsubsection{ROI vs. whole-brain (i.e. searchlight)}

\todo[inline]{searchlight SRM \citep{zhang2016searchlight}}

\todo[inline]{negative: more parameters to vary and to assess}

``Searchlight functional alignment [\citep{zhang2016searchlight,
guntupalli2016model}] learns local transformations and aggregates them into a
single large-scale alignment.
%
The searchlight scheme [Kriegeskorte, 2006, Information-based functional brain
mapping], popular in brain imaging [Guntupalli et al., 2018; 2016], has been
used as a way to divide the cortex into small overlapping spheres of a field
radius.
%
This method allows researchers to remain agnostic as to the location of
functional or anatomical boundaries, such as those suggested by
parcellation-based approaches.
%
A local transform can then be learned in each sphere and the full alignment is
obtained by aggregating (e.g. summing as in \citep{guntupalli2016model} or
averaging) across overlapping transforms.
%
The aggregated transformation produced is no longer guaranteed to bear the type
of regularity (e.g orthogonality, isometry, or diffeomorphicity enforced during
the local neighborhood fit)'' \citep{bazeille2021empirical}.
%
``In the case of searchlight Procrustes, we selected searchlight parameters to
match those used in Guntupalli et al. (2016):
%
each searchlight had 5 voxel radius, with a 3 voxel distance between searchlight
centers'' \citep{bazeille2021empirical}.


\subsubsection{Time series vs connectivity-based}

\todo[inline]{kind of a killer cause you do not need intersection of
time series}

\todo[inline]{wtf did \citep{nastase2019leveraging} do?}


``Hyperalignment projects cortical pattern vectors into a common,
high-dimensional information space \citep{haxby2020hyperalignment}.
%
Derivation of this common space can be based on either neural response profiles
(e.g. data collected during tasks, such as movie viewing (Haxby et al., 2011))
or functional connectivity profiles files \citep{guntupalli2018computational}''
\citep{busch2021hybrid}.

``The number of voxels that can be considered simultaneously for functional BOLD
response time series alignment is limited by the number of timepoints in the
calibration scan (about 300-400 voxels for a 15min scan with a 2s TR,
corresponding to a local cortical neighborhood of about 1cm in diameter for a
standard resolution).
%
This limitation does not exist in this form for a functional alignment that is
based on connectivity vectors.
%
The length of these connectivity vectors is determined by the number of
reference (or seed) regions in the brain'' [project proposal].


% Kumar on Nastase's ugly mofo paper
``Estimating the SRM from functional connectivity data rather than response time
series circumvents the need for a single shared stimulus across subjects.
%
Connectivity SRM allows us to derive a single shared response space across
different stimuli with a shared connectivity profile
\citep{nastase2019leveraging}'' \citep{kumar2020brainiak}.

%
``The sampling of connectivity vector space is defined by the selection of
connectivity targets, but the richness and reliability of connectivity estimates
depends on the variety of brain states over which connectivity is estimated''
\citep{haxby2020hyperalignment}.

%
``Both connectivity hyperalignment and response hyperalignment increased ISCs
and bsMVPC classification accuracies significantly over anatomy-based alignment,
but each algorithm achieves better alignment for the information that it uses to
derive a common model, namely connectivity profiles and patterns of response,
respectively'' \citep{guntupalli2018computational}.



\subsubsection{Studyforrest dataset: other localizer t-contrasts}

\todo[inline]{in audio-description, the condition ``faces'' was especially hard
to model; good for a master student's project (with an additional twist?)}

%
Asymptotic ``performance curve'' might be different for another brain region
(temporal receptive fields?); retinotopic mapping vs. ``higher'' cognition  vs.
executive functions (prefrontal cortex)?


The studyforrest dataset's visual localizer \citep{sengupta2016extension} offers
other contrasts (and thus \acp{roi} masks) aimed at localizing the \ac{ffa} and
\ac{ofa} that are associated with face perception \citep{kanwisher1997ffa,
pitcher2011occipitalfacearea}, the \ac{eba} that is associated with the
perception of human bodies \citep{downing2001bodyarea}, and the \ac{loc} that is
associated with the perception of (small) objects (like tools or toys)
\citep{malach1995loc}.



\subsubsection{New dataset}

\paragraph{other localizers / t-contrasts}

What is the limit of what we can estimate reliably?
%
Retinotopy, language, executive functions (from low-level perception to higher
cognition which might not even be sampled by a movie).

``Results show that the computational principles underlying this common
model have broad general validity for representational spaces in occipital,
temporal, parietal, and frontal cortices'' \citep{guntupalli2016model}.


\paragraph{Functional-anatomical correspondence is different across ROIs}

% Zhen 2017
``Scene-selective regions showed larger interindividual variability [after
nonlinear volume-based alignment] than the face-selective regions in both
spatial topography and functional selectivity'' \citet{zhen2017quantifying}.


% category-specific areas
Similar to nonlinear volume-based alignment, similarity across person is higher
after surface-based alignment ``for retinotopically defined regions, with
character-selective regions showing the lowest consistency for both alignments,
closely followed by mFus- and IOG-faces'' \citep{rosenke2021probabilistic}.
%

%
``We localized 13 widely studied functional areas and found a large variability
in the degree to which functional areas respect macro-anatomical boundaries
across the cortex'' \citep{frost2012measuring}.
%
``The percent gain in overlap [after surface-based alignment] differed greatly
across the different functional regions throughout the cortex''
\citep{frost2012measuring}.
%
``There is a strong structural-functional correspondence in some areas whilst in
others the spatial location of the functional area varies greatly across
subjects within a cortical area'' \citep{frost2012measuring}.
%
``There is a surprising amount of variability in that not all functional areas
are tightly bound to anatomical landmarks'' \citep{frost2012measuring}.
%
``Surface-based alignment is able to separate functional regions which are more
prone to blur together if individual anatomical curvature patterns are not
accounted for'' \citep{frost2012measuring}.

%
``Some areas, such as the frontal eye fields (FEF) are strongly bound to a
macro-anatomical location.
%
``Both the sensory and motor hand areas (bank of the central sulcus) were much
better aligned after surface-based alignment'' \citep{frost2012measuring}.
%
``Language areas were found to vary greatly across subjects whilst a high degree
of overlap was observed in sensory and motor areas'' \citep{frost2012measuring}.

%
``The area which shows the most gain in overlap of these regions is V5 / hMT+
with 70.9\% gain in the left hemisphere and 55.6\% gain in the right
hemisphere'' \citep{frost2012measuring}.
%
``Area LOC also showed increased overlap after CBA with a 62.7\% gain in the
left hemisphere and 38.4\% on the right'' \citep{frost2012measuring}.
%
Finally PPA exhibit more gain in the right hemisphere with 27.7\% gain, than on
the left with 17.6\%'' \citep{frost2012measuring}.
%
``FFA varies in its location along the length of the fusiform gyrus even though
the gyri themselves are well aligned across subjects''
%
The FFA did not exhibit the same strong structural-functional correspondence and
saw more modest increases in overlap after macro-anatomical alignment with
44.1\% and 12\% gain for the left and right hemispheres''
\citep{frost2012measuring}.


\paragraph{Sample size}

\todo[inline]{cf. shortcomings}

\todo[inline]{can/should that variability somehow be quantified?}

Because size matter in the dataset measuring contest!



\paragraph{Shared stimulus}

%
We demonstrated that 15 to 30 minutes of naturalistic stimulation is sufficient
to estimate $Z$-maps of a localizer paradigm.
%
A future study of a larger sample size could use just a part of the movie or
audio-description.
%
Stimuli can more conveniently be shared across studies than participants across
studies \citep[cf.][an extension of the \ac{srm} for shared subjects across
datasets]{zhang2018transfer}.







\subsection{Conclusion}

``We have cross-validated our pROI across participants and studies collected
with different voxel resolutions, stimuli, tasks, scanners, and analysis
methods.
%
Thus, our result is generalizable across many different methodological decisions
spanning experimental design, as well as fMRI data acquisition and analyses''
\citep{weiner2018defining}.


\section{Data Availability}

\todo[inline]{all from PPA-Paper but with new GIN link leading to an empty repo}

% \href{https://gin.g-node.org/chaeusler/studyforrest-ppa-analysis}{\url{gin.g-node.org/chaeusler/studyforrest-ppa-analysis}}

% new; PPA analysis
All fMRI data and results are available as Datalad \citep{halchenko2021datalad}
datasets, published to or linked from the \emph{G-Node GIN} repository
(\href{https://gin.g-node.org/chaeusler/studyforrest-ppa-srm}{\url{gin.g-node.org/chaeusler/studyforrest-ppa-srm}}).
% original
Raw data of the audio-description, movie and visual localizer were originally
published on the \emph{OpenfMRI} portal
(\url{https://legacy.openfmri.org/dataset/ds000113}; \citep{Hanke2014ds000113},
\space \url{https://legacy.openfmri.org/dataset/ds000113d};
\citep{hanke2016ds000113d}).
% visual localizer
Results from the localization of higher visual areas are available as Datalad
datasets at \emph{GitHub}
(\href{https://github.com/psychoinformatics-de/studyforrest-data-visualrois}{\url{github.com/psychoinformatics-de/studyforrest-data-visualrois}}).
% raw data
The realigned participant-specific time series that were used in the current
analyses were derived from the raw data releases and are available as Datalad
datasets at \emph{GitHub}
(\href{https://github.com/psychoinformatics-de/studyforrest-data-aligned}{\url{github.com/psychoinformatics-de/studyforrest-data-aligned}}).
% OpenNeuro
The same data are available in a modified and merged form on OpenNeuro at
\url{https://openneuro.org/datasets/ds000113}.
% NeuroVault for z-maps of SRM
Unthresholded $Z$-maps of all contrasts can be found at
\href{https://identifiers.org/neurovault.collection:12340}{\url{neurovault.org/collections/12340}}.


\section*{Code Availability}

Scripts to generate the results as Datalad \citep{halchenko2021datalad} datasets
are available in a \emph{G-Node GIN} repository
(\href{https://gin.g-node.org/chaeusler/studyforrest-ppa-srm}{\url{gin.g-node.org/chaeusler/studyforrest-ppa-srm}}).
