\todo[inline]{speaking of ``topography'' is little overstatement; topography =
spatial configuration  organisation (i.e. shape, size, and position) of
functional regions \citep{bijsterbosch2018relationship}}


\section{Introduction}

% higher visual areas higher visual areas
In the domain of higher-visual perception, functionally defined,
category-selective brain regions like the \ac{ppa} \citep{epstein1998ppa}, the
\ac{ffa} \citep{kanwisher1997ffa}, or \ac{eba} \citep{downing2001bodyarea}
exhibit significantly increased \ac{bold} activity correlated with a
``preferred'' \citep{debeck2008interpreting} stimulus class.
%
The topographies (i.e. the location, size and shape) of these category-selective
areas are similarly distributed across individuals but the exact location, size
and shape vary interindividually \citep{rosenke2021probabilistic,
zhen2017quantifying, zhen2015quantifying, frost2012measuring}.


\subsection{Localizers (= problem)}

\todo[inline]{Streamline with general intro \& general discussion}

% definition of localizer
In order to identify the topography of functional areas in individual persons,
block-design \textit{functional localizer} paradigms are traditionally used that
contrast regressors of modeled hemodynamic responses correlating with the
corresponding stimulus classes (i.e. landscapes, faces, or bodies).
% problem: one localizer for one domain
Functional localizers are designed to maximize detection power and thus
dedicated to map just one domain of brain functions like, for example,
retinotopic visual areas \citep{wang2015probabilistic}, scene-selective regions
\citep{stigliani2015temporal}, theory of mind \citep{spunt2014validating}, or
semantic processes \citep{fernandez2001language}.
% which gets messy
However, if one wants to map a variety of domains, the approach ``one paradigm
for one domain of functions'' gets time-consuming and inefficient.
% localizer batteries: intro
Researchers have tried to tackle that issue by creating time-efficient
multi-functional \textit{localizer batteries} \citep[e.g.,][]{barch2013function,
drobyshevsky2006rapid, pinel2007fast}.
% task based = shit
Nevertheless, the diagnostic quality of localizer batteries relies heavily on a
participant's comprehension of the task instructions and general compliance, a
criterion that can be difficult to meet in clinical or pediatric populations
\citep{eickhoff2020towards, vanderwal2019movies}.


\subsection{Estimation from reference group (= solution)}

\subsubsection{Intro (incl. recapitulation of study 2)}

\todo[inline]{Streamline with general intro \& general discussion}

% ppa via movie
In study 2 \citep{haeusler2022processing}, we have shown that a functionally
defined region, such as the \ac{ppa}, can be localized using a model-driven
\ac{glm} analysis that is based on the annotated temporal structure of a
two-hour long naturalistic stimulus.
% ppa via audio-description
Results also suggest that a naturally engaging, purely auditory paradigm like an
audio-description could, in principle, substitute a visual localizer as a
diagnostic procedure to assess brain functions in visually impaired individuals
\citep{haeusler2022processing}.
% full feature film is too long
However, a two-hour long paradigm is unsuitable for a clinical application due
to practical and monetary reasons.
% hence, predict from reference
An approach to reduce time and costs is to identify a functional area in an
individual person based on data collected from an independent sample of
different persons (i.e. a \textit{reference group}).


\subsubsection{Anatomical alignment}

% intro: estimation via common anatomical space
Previous studies estimated the most probable location of a functional area in a
person's anatomy from a reference group by performing a volume-based
\citep[e.g.,][]{zhen2017quantifying, zhen2015quantifying} or surface-based
\citep[e.g.,][]{frost2012measuring, weiner2018defining,
rosenke2021probabilistic, wang2015probabilistic} \textit{anatomical alignment}.
%
First, in order to address the issue of anatomical variability across persons,
functional data of persons in the reference group are anatomically aligned to
(i.e.  projected into) a \textit{common anatomical space}.
% project into test subject to estimate
Then, data are projected from the common anatomical space into the individual
person's brain anatomy serving as an estimation of a functional region's
location.

% volume-based alignment in one sentence
Volume-based anatomical alignment \citep[s.][for a review]{klein2009evaluation}
aligns voxel-wise data to a three-dimensional common anatomical space
\citep[e.g., MNI152 template;][]{fonov2011unbiased}.
% surface-based alignment in one sentence
Surface-based anatomical alignment \citep{fischl1999cortical, yeo2009spherical}
aligns vertex-wise data to a two-dimensional common anatomical space
\citep[e.g., FreeSurfer fsaverage template;][]{fischl1999high}.
% difference in one sentence
Whereas volume-based alignment does not account for individual sulcal and gyral
folding patterns, surface-based alignment respects interindividual variability
of the cortical surface.
% surface-based estimation works better
Consequently, previous studies that estimated the locations of functional
regions based on both [linear / affine] volume-based and [nonlinear]
surface-based alignment have shown that surface-based alignment reduces
between-subject variability resulting in an increased estimation performance
\citep{rosenke2021probabilistic, frost2012measuring, wang2015probabilistic,
weiner2018defining}.


\paragraph{But: remaining variability \& functional-anatomical correspondence}

% remaining variability after surface-based alignment
However, even after surface-based alignment the anatomical location of
functional regions varies anatomically across persons
\citep[e.g.,][]{coalson2018impact, benson2014correction, natu2021sulcal,
wang2015probabilistic, frost2012measuring, langers2014assessment, weiner2014mid,
rosenke2021probabilistic}.
% frost as an example
For example, \citet{frost2012measuring} localized 13 functional areas of the
high-level visual cortex and ``found a large variability in the degree to which
functional areas respect macro-anatomical boundaries''
\citep{frost2012measuring}.
% functional--anatomical correspondence
The remaining variability indicates that functional areas a not necessarily
bound to anatomical landmarks, and reflects the degree of
\textit{functional--anatomical correspondence} between a brain function and the
underlying anatomical location.


\todo[inline]{imo, reference to \citet{weiner2018defining} below can be dropped;
study is about PPA, though}

%
\citet{weiner2018defining} showed ``that cortical folding patterns and
probabilistic predictions reliably identify place-selective voxels in medial VTC
across individuals and experiments''.
%
However, ``this structural-functional coupling is not always perfect and there
is inter-subject variability as to how much the place-selective voxels extend
within the PHG, as well as the LG and medial aspects of the fusiform gyrus.
%
Despite this inter-subject variability, place-selective voxels are always
located within the CoS across participants.'' \citep{weiner2018defining}.



\subsubsection{Functional alignment}

%
Since anatomical alignment addresses the issue of anatomical variability but not
functional-anatomical variability across subjects, algorithms --- like
\textit{hyperalignment} \citep{haxby2011common, guntupalli2016model} or the
\textit{shared response model} \citep{chen2015reduced, zhang2016searchlight} ---
have been developed that perform a \textit{functional alignment}.
%
Whereas anatomical alignment aligns voxels (or vertices) that share the same
anatomical location to a common anatomical space, functional alignment aligns
voxels (or vertices) that share similar functional properties to a
\textit{common functional space} (CFS).
%
Functional alignment algorithms are usually used to construct both a
high-dimensional, functional brain template (i.e. the \ac{cfs}) from study
participants' functional data as well as subject-specific transformation
matrices.
%
A subject's transformation matrix allows a linear mapping of functional data
from a subject's anatomical space [or native brain space] into the \ac{cfs}, or
to project data from the \ac{cfs} into a subject's anatomical space [or brain
space] \citep{haxby2020hyperalignment}.

%
The \ac{cfs} and transformation matrix can be created (i.e.  \textit{trained})
based on the maximization of the inter-subject similarity of \ac{bold} response
time series correlating with a time-locked external stimulation
\citep{haxby2011common, chen2015reduced, sabuncu2010function}, or based on the
inter-subject similarity of connectivity profiles \citep{feilong2018reliable,
guntupalli2018computational, nastase2019leveraging}.
%
Tough functional alignment algorithms can be applied to \ac{fmri} data from
paradigms employing simplified stimuli, data from naturalistic stimuli provide
increased validity of the \ac{cfs} and increased generalizability of
transformation matrices to novel stimuli or tasks, presumably because
naturalistic stimuli sample a broader range of brain states
\citep{haxby2011common, guntupalli2016model}.

\todo[inline]{what does increased validity of a \ac{cfs} actually mean?}

\subsubsection{Estimation via functional alignment}
%
Hence, a more recent procedure \citep[e.g., ][]{jiahui2020predicting,
guntupalli2016model, haxby2011common} to estimate the most probable location of
a functional area in a person's anatomy from a reference group performs an
functional alignment.
% solve functional-anatomical variability
First, in order to address the issue of functional-anatomical variability across
persons, functional data from persons in the reference group are functionally
aligned to (i.e. projected into) a \ac{cfs}.
%
Then, data are projected from the \ac{cfs} into the individual person's brain
anatomy serving as an estimation of a functional region's location.

% Jiahui
For example, \citep{jiahui2020predicting} constructed a \ac{cfs} and
transformation matrices based on data from a) the movie ``Grand Budapest Hotel''
($\sim$\unit[50]{m}; \ac{tr}=\unit[1]{s}), and b) ``Forrest Gump''
($\sim$\unit[120]{m}; \ac{tr}=\unit[2]{s}).
% summary of results
Results revealed that the empirical results of a visual localizer's $t$-contrast
aimed to localize the \ac{ffa} correlate more highly with contrast maps that
were estimated from other subjects' data based on hyperalignment than with
contrast maps that were estimated based on surface-based anatomical alignment
\citep{jiahui2020predicting}.


\subsection{Here, we}

\todo[inline]{We do way too much!}

\todo[inline]{Emphasize (partial) alignment via movie segments}

\todo[inline]{more a bonus:
%
a) prediction of "auditory PPA" (via movie \& audio-description),
%
b) alignment via functional localizer}

\todo[inline]{Part on cross-validation is now pretty short here; cf. general
intro (\& SRM method section)}

% focus: ppa
As a proof of concept, we focus on the \ac{ppa} \citep[e.g.,][for
reviews]{epstein2014neural, aminoff2013role}, and explore whether we can
estimate results of a visual localizer's $t$-contrast in a subject from other
subjects' data.
%
Following an exhaustive leave-one-out cross-validation, we employ a traditional
volume-based, anatomical alignment procedure and compare its estimation
performance to the performance of a volume-based, functional alignment procedure
% partially alignment = difference to \citep{jiahui2020predicting}
[Critically,] we also assess the relationship between the estimation performance
and the quantity of functional data used to functionally align a test subject to
the \ac{cfs}.


\subsubsection{SRM}

\todo[inline]{I decided to not explain the SRM in the general part on functional
alignment above 'cause it gets way too messy there}


\paragraph{Overview}

\todo[inline]{revise reasoning / phrasing}

% why SRM
Our functional alignment approach utilizes the \ac{srm} algorithm
\citep{chen2015reduced, richard2019fast} that is implemented in the open-source
software package BrainIAK (Brain Imaging Analysis Kit;
\href{https://brainiak.org}{\url{brainiak.org}}) and computationally less
demanding [= "computationally more efficient"?] than hyperalignment, an
advantage for scientists who want to replicate our results but do not have
access to a high-performance computer cluster [or "high-throughput computer
cluster" or simply "specialized hardware"?].

% general overview of SRM
The \ac{srm} is an unsupervised probabilistic latent-factor model that
decomposes \ac{bold} \ac{fmri} response time series of participants experiencing
the same stimulus into a \ac{cfs} of \textit{shared features} (also called
``\textit{shared feature space}'' \citet{chen2015reduced}) and subject-specific
linear transformations matrices that represent the loadings of voxels onto the
shared responses \citep{kumar2020brainiak, cohen2017computational}.
% number of dimensions
In contrast to hyperalignment \citep{haxby2011common, guntupalli2016model}, the
number of dimensions of the \ac{cfs} is not set by the number of voxels (or
surface vertices) but is specified by the researcher to a number lower than the
number of voxels, a procedure that also filters out noise and reduces
overfitting \citep{chen2015reduced}.


\paragraph{Math stuff}
% math stuff from citep{vodrahalli2018mapping}
% ``SRM learns $N$ maps $W_{i}$ with orthogonal columns such that
% $||X_{i}-W_{i}S||_{F}$ is minimized over $\left\{ W_{i}\right\} _{i=1}^{N},S$,
% where $X_{i}\in\mathbb{R}^{v\times{T}}$ is the $i^{th}$ subject's fMRI
% response ($v$ voxels by $T$ repetition times) and
% $S\in\mathbb{R}^{k\times{T}}$ is a feature time-series in a $k$-dimensional
% shared space'' \citep{vodrahalli2018mapping}.

% math stuff
More specifically, the \ac{srm} algorithm uses each $n^{th}$ training subject's
response time series represented as matrix $X_{n}$ ({$v$} voxels by $t$ time
points) to calculate the \ac{cfs} $C$ ($k$ shared responses by $t$ time points)
and subject-specific, orthogonal transformation matrices $T_{n}$ ($v$ voxels by
$k$ shared responses).
% iteratively fitted
The algorithm randomly initializes and fits the transformation matrices over
iterations to minimize the error in explaining the participants' data, while
also learning the time course of the shared responses (s.
\href{https://brainiak.org/tutorials/11-SRM/}{\url{brainiak.org/tutorials/11-SRM}}).


\paragraph{Result}
% result = alignment
Eventually, each transformation matrix represents a subject-specific functional
topography of {$v$} voxels that allows to functionally align a subject's
functional data to the \ac{cfs} by projecting responses within the {$v$} voxels
into the $k$-dimensional \ac{cfs}.

% explanation of shared features
%Thus, each shared feature that can be understood as a weighted sum of many
%voxels across subjects \citep{kumar2020brainiak}, whereas a subject-specific
%transformation matrix represent each subject-specific voxel's weight on each
%shared feature.


\subsubsection{Our functional alignment procedure}

%
In the current study, our approach to estimate a test subject's localizer result
(i.e. a test subject's \textit{empirical $Z$-map}) via functional alignment is
conducted in four steps.
% create CFS and training subjects' matrices
First, for every fold of the cross-validation, we train a shared response model
on $N-1$ training subjects' response time series of the movie, audio-description
and visual localizer in order to acquire both a \ac{cfs} (i.e.  the shared
feature space) and subject-specific transformation matrices.
% project into CFS
Second, we use the subject-specific transformation matrices in order to perform
a mapping of the visual localizer's results (i.e. the training subjects'
\textit{empirical $Z$-maps}) from each training subject's voxel space into the
\ac{cfs}.
% align test subject
Third, in order to acquire the test subject's transformation matrix, we use time
series data from the naturalistic stimuli to align the test subject to the
\ac{cfs} (that was derived from the training subjects' data)
% project from CFS into test subject
Last, the transpose of the test subject's transformation matrix is used to
project the training subjects' functional localizer results from the \ac{cfs}
into the test subject's voxel space.
% actual prediction
The average of these projected results serves as an estimation (hence, a
\textit{predicted $Z$-map}) of the test subject's localizer results (i.e. the
empirical $Z$-map).


\paragraph{Partial alignment}
%
Given that a two-hour long stimulation is unsuitable for a clinical setting, we
also assess the relationship between the length of the naturalistic stimulus
used to align the test subject to the \ac{cfs} and the estimation performance.
%
Therefore, we use an increasing number of segments of the naturalistic stimuli
(each lasting \unit[15]{m}) to align the test subject to the corresponding
segments' time points within the \ac{cfs}.


\subsubsection{Assessment via Pearson's}
%
The prediction performance is assessed by calculating the Pearson's Coefficient
between a left-out subject's empirical $Z$-map and predicted $Z$-map.


\paragraph{Anatomical alignment as benchmark}

\todo[inline]{very shortly state how anatomical alignment is performed}

\todo[inline]{cf. general introduction \& introduction above}


\subsubsection{Alignment via localizer runs}

\todo[inline]{imo, mentioning this here further increases complexity; should be
sufficient to mention it in method section \& shortly discuss it in discussion}

%
We also test alignment based on one to four localizer runs (each lasting
 $\sim$\unit[5.2]{m}) of data from the visual localizer to acquire the
transformation matrices and perform a cross-subject-prediction (vs.
cross-subject-cross-experiment-prediction).


\subsubsection{Prediction of "auditory PPA"}

\todo[inline]{Following text is more a placeholder than actual text; as said, it
gets pretty messy; prediction of auditory PPA was more kind of a side note /
sanity check?}

\todo[inline]{results: SRM "fails" in case a subject has atypical results in
study 2 (i.e. subject has no auditory PPA) independent of which naturalistic
stimulus was used for alignment}

\todo[inline]{should be discussed in the discussion, though}

%
Results of our previous study \citep{haeusler2022processing} suggest that not
just the dedicated visual localizer \citep{sengupta2016extension} but also the
audio-visual movie Forrest Gump \citep{hanke2016simultaneous} and the movie's
audio-description \citep{hanke2014audiomovie} sample the response vector space
of hemodynamic responses to ``spatial information'' in a time-locked manner
across subjects.
%
Hence, we also test whether we can use the runs of the movie and
audio-description to estimate the results of study 2.


\subsection{Hypotheses}

\todo[inline]{draft; s. also general introduction}

\todo[inline]{at the moment, no hypothesis regarding alignment via localizer
runs to predict localizer}

\todo[inline]{at the moment, no hypothesis regarding prediction of "auditory
PPA"}

%
We hypothesized that an increased quantity of data used to calculate the
transformation matrices of the test subjects would lead to an increasing
prediction performance.
%
Further, we hypothesized that functional alignment procedure would eventually
outperform an estimation based on anatomical alignment.


\subsection{Summary of results}

\todo[inline]{at the end of the intro, papers provide 2-3 sentences summarizing
results and also a 1-2 sentence conclusion in the intro}

%
Results show...


\subsection{Conclusion \& Vision}

\todo[inline]{2-3 sentences are enough here; better write more in discussion}

Our results suggest that it is possible to ``scan once, estimate many''...



\section{Methods}

% we get the data from the naturalistic PPA paper (its subdataset)
% datalad get -n inputs/studyforrest-ppa-analysis/inputs/studyforrest-data-aligned
% datalad get inputs/studyforrest-ppa-analysis/inputs/studyforrest-data-aligned/sub-??/in\_bold3Tp2/sub-??\_task-a?movie\_run-?\_bold*.*

% reference to PPA-Paper
For the current study, we used the same subset of the studyforrest dataset that
was used in study 2 \citep{haeusler2022processing}:
%
the same subjects ($N=14$) were
% VIS
a) participating in a dedicated six-category block-design visual localizer
\citep{sengupta2016extension},
% AV
b) watching the audio-visual movie ``Forrest Gump''
\citep{hanke2016simultaneous}, and
% AD
c) listening to the movie's audio-description \citep{hanke2014audiomovie}.
% see corresponding papers for details
An exhaustive description of participants, stimulus creation, procedure,
stimulation setup, and fMRI acquisition can be found in the corresponding
publications, whereas a summary is provided in \citet{haeusler2022processing}.

\todo[inline]{...which means the following about studyforrest data is pretty
short now}



\subsection{Preprocessing}

% data sources
The current analyses were carried out on the same preprocessed fMRI data (s.
\href{https://github.com/psychoinformatics-de/studyforrest-data-aligned
}{\url{github.com/psychoinformatics-de/studyforrest-data-aligned}}) that were
used for
%
a) the technical validation of the dataset \citep{hanke2016simultaneous},
%
b) the localization of higher-visual areas \citep{sengupta2016extension}, and
%
c) the investigation of responses of the \ac{ppa} correlating with naturalistic
spatial information in study 2 \citep{haeusler2022processing}.

%
We reran the preprocessing and analyses steps performed in
\citet{sengupta2016extension} and \citet{haeusler2022processing} using FEAT
v6.00 \citep[FMRI Expert Analysis Tool;][]{woolrich2001autocorr} as shipped with
FSL v5.0.9 \citep[\href{https://www.fmrib.ox.ac.uk/fsl}{FMRIB's Software
Library;}][]{smith2004fsl} in order to reproduce both the time series that
served as final input for the statistical analyses in the two previous studies
as well as their results (i.e. the statistical $Z$-maps).
% temporal filtering
In summary, high-pass temporal filtering was applied using a Gaussian-weighted
least-squares straight line to every run of the visual localizer (cutoff period
of \unit[100]{s}; sigma= \unit[100]{s}/2) \todo{???}, and every segment of the
movie and audio-description (\unit[150]{s}; sigma=\unit[75.0]{s}).
% brain extraction
Brains were extracted from surrounding tissues using BET \citep{smith2002bet}.
% spatial smoothing
As in the previous studies, data from all three paradigms were spatially
smoothed (Gaussian kernel with full width at half maximum of \unit[4.0]{mm}).
% grand mean normalization
A grand-mean intensity normalization was applied to each run of the functional
localizer and each segment of the naturalistic stimuli.


\subsection{Modeling of the \ac{cfs}}

On these reproduced time series data, we then performed further analyses steps
via Python scripts that relied on
%
NiBabel v3.2.1 (\href{https://nipy.org}{\url{nipy.org}}),
%
NumPy v1.20.2 (\href{https://numpy.org}{\url{numpy.org}}),
%
Pandas v1.2.3 (\href{https://pandas.pydata.org}{\url{pandas.pydata.org}}),
%
Scipy v1.6.2 (\href{https://scipy.org}{\url{scipy.org}}),
%
scikit-learn v1.0 (\href{https://scikit-learn.org}{\url{scikit-learn.org}}),
%
BrainIAK v0.11 (\href{https://brainiak.org}{\url{brainiak.org}}),
%
Matplotlib v3.4.0 (\href{https://matplotlib.org}{\url{matplotlib.org}}),
%
seaborn v0.11.2 (\href{https://seaborn.pydata.org}{\url{seaborn.pydata.org}}),
%
and calling command line functions of FSL.

%\paragraph{Fixing FSL output}

% grand_mean_for_4d.py (formerly: data_normalize_4d.py):
% is not necessary anymore: FSL has applied grand mean scaling to
% 'filtered_func_data.nii.gz'

% input: 'sub-*/run-?.feat/filtered_func_data.nii.gz' (of VIS, AO & AV)
% output: saved to 'sub-??_task-*_run-?_bold_filtered.nii.gz'

% FSL adds back the mean value for each voxel's time course at the end of the
% preprocessing;
% hence, the script substracts that mean again but multiplies it by 10000
% (like FSL does it, too)

% definition of grand mean scaling for 4d data:
% voxel values in every image are divided by the average global mean
% intensity of the whole session. This effectively removes any mean global
% differences in intensity between sessions.

% FSL User Guide:
% filtered_func_data will normally have been temporally high-pass filtered,
% it is not zero mean; the mean value for each voxel's time course has been
% added back in for various practical reasons.
% When FILM begins the linear modeling, it starts by removing this mean.


\paragraph{Getting the data in shape}

% masks-from-mni-to-bold3Tp2.py:
% - merges unilateral ROIs overlaps (already in MNI) to bilateral ROI
% - output: 'masks/in_mni/PPA_overlap_prob.nii.gz'
% - warps union of ROIs from MNI into each subjects space
% output: 'sub-*/masks/in_bold3Tp2/grp_PPA_bin.nii.gz' + audio_fov.nii.gz dilate
% the ROI masks by 1 voxel; output: 'grp_PPA_bin_dil.nii.gz'

% masks-from-mni-to-bold3Tp2.py:
% warp MNI masks into individual bold3Tp2 spaces

% masks-from-t1w-to-bold3Tp2.py:
% transforms 'inputs/tnt/sub-*/t1w/brain_seg*.nii.gz'
% into individual's bold3Tp2
% output: 'sub-*/masks/in_bold3Tp2/brain_seg*.nii.gz'

% mask-builder-voxel-counter.py:
% builds different individual masks by dilating, merging other masks
% creates a FoV of AO stimulus for every subject from 4d time-series of AO run
% output: sub-*/masks/in_bold3Tp2/audio_fov.nii.gz'
% counts the voxels
% long story short: we cannot used all gyri that contain PPA to some degree
% even if the mask by FoV of AO stimulus and individual gray matter mask

% data_mask_concat_runs.py:
% masks are not dilated and not masked with subject-specific gray matter mask
% outputs:
% 'sub-*_task_aomovie-avmovie_run-1-8_bold-filtered.npy
% 'sub-*_task_visloc_run-1-4_bold-filtered.npy'

\todo[inline]{problem 1: grpPPA contains N=14 subject, not N-1 subjects}

\todo[inline]{problem 2: voxels outside of PPA-mask; probably, because of
warping procedures}

% reason why we do it
The \ac{srm} requires that the number of samples (i.e. the number of \acp{tr})
exceed the number of features (the number of voxels).
%
In order to restrict the number of voxels, we created bilateral \acp{roi} for
each subject by warping the union of individual \acp{ppa}
\citep[s.][]{haeusler2022processing} from MNI space into each subjects' voxel
space using previously computed subject-specific, non-linear transformation
matrices
\citep[][\href{https://github.com/psychoinformatics-de/studyforrest-data-templatetransforms
}{\url{github.com/psychoinformatics-de/studyforrest-data-templatetransforms}}]{hanke2014audiomovie}.
% applying masks
Each subject's time series data were then masked by the union of individual
\acp{ppa} and the subject-specific \ac{fov} of the audio-description.
% voxels = [1665, 1732, 1400, 1575, 1664, 1951, 1376, 1383, 1683, 1887, 1441,
% 1729, 1369, 1437]
The number of remaining voxels (range: 1369--1951, $\mu=1592$, $\sigma=188$) for
each subject can be seen in Table \ref{tab:ppamaskvoxels}.

\todo[inline]{table stating remaining voxels per subject can probably be
deleted}

\todo[inline]{I z-scored the runs runwise, concatenated them, and z-scored
again}

% normalization
Data of every run were independently normalized ($z$-scored) to a mean of zero
and a standard deviation of one ($\mu=0$, $\sigma=1$).
%
The last 75 \acp{tr} of the audio-description were missing in subject-04 due to
an image reconstruction problem \citep[s.][]{hanke2014audiomovie}.
%
The \ac{srm} allows the number of voxels to be different across subjects but the
number of samples must be the same.
%
Hence, we removed the last 75 \acp{tr} of the audio-description from the other
subjects' time series.
% summary; AO + AV = 7123 TRs (not 7198 TRs anymore); localizer has 4 x 156 TRs
As a result, the data to fit the \ac{srm} in the following step comprised 3599
\acp{tr} of the movie, 3524 \acp{tr} of the audio-description, and 624 \acp{tr}
of the visual localizer experiment (7747 \acp{tr} in total).
%% concatenate and z-score
The time series of all three paradigms were concatenated and $z$-scored.

\todo[inline]{well, probably I should have cut the last 75TRs of AO first, and
then z-scored the last segment but anyway...; does not make much difference}

\todo[inline]{yes, I performed a second z-scoring but across all runs/paradigms}

\todo[inline]{Table stating the number of voxels per subject could be dropped,
imo}

\begin{table*}[btp]
    \caption{
    %
    \textbf{Table heading.}
    %
    Number of remaining voxels after time series data of each paradigm
    and subject were masked with the union of individual \acp{ppa} that was
    warped from MNI space into each individual's subjects-space and the
    subject-specific field of view of audio-description.}

\label{tab:ppamaskvoxels}
\begin{tabular}{ll}
    \toprule
    \textbf{Subject} & \textbf{no. of voxels} \\
    \midrule
    sub-01 & 1665 \tabularnewline
    sub-02 & 1732 \tabularnewline
    sub-03 & 1400 \tabularnewline
    sub-04 & 1575 \tabularnewline
    sub-05 & 1664 \tabularnewline
    sub-06 & 1951 \tabularnewline
    sub-14 & 1376 \tabularnewline
    sub-09 & 1383 \tabularnewline
    sub-15 & 1683 \tabularnewline
    sub-16 & 1887 \tabularnewline
    sub-17 & 1441 \tabularnewline
    sub-18 & 1729 \tabularnewline
    sub-19 & 1369 \tabularnewline
    sub-20 & 1437 \tabularnewline
    \bottomrule
\end{tabular}
\caption*{The legend text goes here.}
\end{table*}


\paragraph{Fitting of shared response model: intro}

\todo[inline]{mention that I also tested calculating the \ac{cfs} based on just
data from 'ao \& av' and not VIS data? results: minimally "worse"}

In order to compute the \ac{cfs} and the transformation matrices for the
training subjects, we used the probabilistic \ac{srm} algorithm that
approximates the \ac{srm} based on the Expectation Maximization (EM) algorithm
as proposed by \citep{chen2015reduced}, optimized by
\citet{anderson2016enabling}, and implemented in BrainIAK v.11 \citep[Brain
Imaging Analysis Kit;][]{kumar2020brainiak, kumar2020brainiaktutorial}.


\paragraph{Cross-validation}

%
For every fold of the leave-one-out cross-validation, we used the $N-1$ training
subjects' \ac{bold} \ac{fmri} responses to the movie, audio-description, and
functional localizer to let the algorithm calculate the \ac{cfs} and
transformation matrices.


\paragraph{Number of dimensions}

% ``The effect of number of PCs on BSC was similar for models that were based
% only on Princeton (n = 10) or Dartmouth (n = 11) data, suggesting that this
% estimate of dimensionality is robust across differences in scanning hardware
% and scanning parameters'' \citep{haxby2011common}.
%
% ``These dimensionality estimates are a function of the spatial and temporal
% resolution of fMRI and the number and variety of response vectors used to
% derive the common space'' \citep{guntupalli2016model}.
%
% ``The true dimensionality of representation in human cortex surely involves
% vastly more distinct tuning functions. Estimates of the dimensionality of
% cortical representation, therefore, will almost certainly be much higher as
% data with higher spatial and temporal resolution for larger and more varied
% samples of response vectors are used to build new common models''
% \citep{guntupalli2016model}.

% features
For the number of shared responses (i.e. the number of the \ac{cfs}'s
dimensions), we chose a value of $k=10$ considering a) the temporal and spatial
resolution of our data (\ac{tr} = \unit[2]{s}; \unit[2.5 $\times$ 2.5 $\times$
2.5]{mm}), b) the average number of voxels per \acp{roi}, b) and findings from
\citet{haxby2011common}.

\todo[inline]{shorten procedure of \citet{haxby2011common}?}

\citet{haxby2011common} first used hyperalignment to create a \ac{cfs} of 1,000
dimensions based of functional data (\ac{tr} = \unit[3]{s}) of voxels (of size
\unit[3 $\times$ 3 $\times$ 3]{mm}) located in the ventral temporal cortex.
%
Then, \citet{haxby2011common} reduced the dimensionality of the \ac{cfs} by
applying a \ac{pca} in order to determine the subspace that is sufficient to
capture the full range of response-pattern distinctions.
%
Results revealed that approximately 35 principal components (i.e. dimensions)
were sufficient to represent the information content of a one-hour movie from
which the \ac{cfs} was derived.
%
Results also showed that the cortical topographies of category-selective brain
regions was preserved in the 35-dimensional \ac{cfs} \citep{haxby2011common}.
%
In the current study, we also explored \acp{cfs} of $k=5, 20, 30, 40, 50$ but
results barely varied from a 10-dimensional \ac{cfs}.
% iterations:
The number of iterations for the algorithm to minimize the error was set to 30.



\paragraph{Correlation of regressors used in our previous studies with shared
responses}

\todo[inline]{Plots of correlation matrices should be presented here (cf. method
section of PPA paper), not in results}

\todo[inline]{What to adjust in the plots? Regressors of low-level confounds
might be dropped? imo, should be kept 'cause the are correlations}

\todo[inline]{Plot of AO regressors: remove combination of regressors
\texttt{geo\&groom\&furn} because \texttt{furn} was not used in any contrast}

\todo[inline]{CFS for sub-01 as an example; funnily: the correlations even among
shared responses change depending the 13 subjects used for each test subject's
\ac{cfs}}


% Intro
We calculated the correlations (Pearson's r) between shared responses within the
\ac{cfs} and the regressors that were previously modeled
\citep{sengupta2016extension, haeusler2022processing} to investigate hemodynamic
responses to the three stimuli (movie, audio-description, audio-description).

%
Correlation of shared responses (occurring during TRs of the movie) with modeled
responses (regressors) to visual stimulus features as used in
\citep{haeusler2022processing}: Fig.~\ref{fig:corr-av-reg-srm}.

%
Correlation of shared responses (occurring during TRs of the audio-description )
with modeled responses (regressors) to auditory stimulus features as used in
\citep{haeusler2022processing}: Fig.~\ref{fig:corr-ao-reg-srm}.

%
Correlation of shared responses (occurring during TRs of the visual localizer)
with modeled responses (regressors) used in \citep{sengupta2016extension}: see
Fig.~\ref{fig:corr-vis-reg-srm}.



\begin{figure*}[tbp]
\centering
    \includegraphics[width=\linewidth]{figures/corr_av-regressors-vs-cfs_sub-01_srm-ao-av-vis_feat10-iter30_3524-7123.pdf}
    \caption{
    %
    \textbf{Correlations of shared responses and regressors of the movie.}
    %
    Pearson correlation coefficients between a) shared responses (sh. res.)
    within the \ac{cfs} that was calculated for subject 01 and b) regressors
    created in \citet{haeusler2022processing} to model hemodynamic responses to
    stimulus features of the movie.
    %
    The time series of the \ac{cfs} were sliced to match the TRs of the
    movie.
    }
    \label{fig:corr-av-reg-srm}
\end{figure*}



\begin{figure*}[tbp]
\centering
    \includegraphics[width=\linewidth]{figures/corr_ao-regressors-vs-cfs_sub-01_srm-ao-av-vis_feat10-iter30_0-3524.pdf}
    \caption{
    %
    \textbf{Correlations of shared responses and regressors of the audio-description.}
    %
    Pearson correlation coefficients between a) shared responses (sh. res.)
    within the \ac{cfs} that was calculated for subject 01 and b) regressors
    created in \citet{haeusler2022processing} to model hemodynamic responses to
    stimulus features of the audio-description.
    %
    \texttt{geo\&groom} [and \texttt{geo\&groom\&furn}] is a combination of
    regressors as used on the positive side of the primary contrasts aimed to
    localize the \ac{ppa} (cf. Table 5 in \citet{haeusler2022processing}.
    %
    The time series of the \ac{cfs} were sliced to match the TRs of the
    audio-description.
    }
    \label{fig:corr-ao-reg-srm}
\end{figure*}



\begin{figure*}[tbp]
\centering
\includegraphics[width=\linewidth]{figures/corr_vis-regressors-vs-cfs_sub-01_srm-ao-av-vis_feat10-iter30_7123-7747.pdf}
    \caption{
    %
    \textbf{Correlations of shared responses and regressors of the visual
    localizer.
    }
    %
    Pearson correlation coefficients between a) shared responses (sh. res.)
    within the \ac{cfs} that was calculated for subject 01 and b) regressors
    created in \citet{sengupta2016extension} to model hemodynamic responses
    during the six-category visual localizer paradigm.
    %
    The time series of the \ac{cfs} were sliced to match the TRs of the
    visual localizer.
}
    \label{fig:corr-vis-reg-srm}
\end{figure*}

\paragraph{Negative control}
% shuffle runs
As negative control, we randomly shuffled the order of runs of the visual
localizer, and the segments of the movie and audio-description for each training
subject independently before fitting a \ac{srm} to the time series.
% calculate coefficients
We calculated the correlations (Pearson's r) between shared responses within the
\ac{cfs} and the regressors that were previously modeled
\citep{sengupta2016extension, haeusler2022processing} to investigate hemodynamic
responses to the three stimuli (localizer, movie, audio-description)
% results
Results revealed [minor to] no correlations between the regressors and the
shared responses that were calculated based on shuffled time series.


\subsection{Alignment of test subjects to a fixed \ac{cfs}}

% AO: 0-451, 0-892, 0-1330, 0-1818, 0-2280, 0-2719, 0-3261, 0-3524
% AV: 3524-3975, 3524-4416, 3524-4854, 3524-5342, 3524-5804, 3524-6243,
%     3524-6785, 3524-7123
% AO+AV: 0-7123

\todo[inline]{How is it done? srm.transform\_subject calls np.linalg.svd()}

\todo[inline]{in-code documentation says: ``Solve the Procrustes problem''}

% Learn the mapping
We then aligned the test subject's data to the \ac{cfs} by letting the algorithm
learn a transformation matrix $T_{n}$ that performs an orthogonal mapping from
the test subject's anatomical voxel space into the \ac{cfs}.


\subsubsection{(Partial) alignment via movie \& audio-description}

\todo[inline]{Revise (shorten) according to the new text in the introduction}

% intro
In order evaluate the relationship between estimation performance of the
empirical $Z$-maps and the length of stimulation used to align the test subject
to the \ac{cfs}, we varied the quantity of data used to let the algorithm learn
the transformation matrices.
%
For each naturalistic stimulus, we used one up to eight segments (each lasting
$\sim$\unit[15]{m}) to let the algorithm learn an orthogonal mapping of a test
subject's functional data to the corresponding \acs{tr} within the \ac{cfs}.
%
For every test subject, we obtained eight different transformation matrices per
naturalistic stimulus.
%
Each of transformation matrices has a size of $v$ voxels by $k$ shared responses
but is based on an increasing quantity of data used to calculate the mapping.


\subsubsection{(Partial) alignment via localizer}

The algorithm can also be applied to functional data of traditional paradigms
using controlled stimuli.
%
However, results of previous studies \citep{guntupalli2016model,
haxby2011common} suggest transformations based on data from traditional
paradigms are of diminished validity [and diminished generalizability to new
stimuli in other experiments], presumably because traditional paradigms sample a
sparser range of brain states than naturalistic stimuli.
%
In order to compare the estimation performance based on matrices derived from
naturalistic stimuli (across-experiment prediction) to the estimation
performance based on matrices derived from the visual localizer
(within-experiment prediction), we also used data from the traditional localizer
to learn a mapping from the test subject's brain space to the \ac{cfs}.
%
For each test subject, we calculated four transformation matrices based on one
up to four runs (each lasting \unit[5.2]{m}).



\subsection{Prediction of localizer}

\todo[inline]{Not mentioned: I tested averaging data in \ac{cfs}: similar
results; in case of anatomical alignment, I did not test averaging data in
MNI152 space}

% overview
We then estimated a test subject's localizer results (the empirical $Z$-map) by
projecting all training subjects' empirical $Z$-maps from their voxel space
trough the common space (i.e. through the \ac{cfs} in case of functional
alignment; through MNI space in case of anatomical alignment) into the test
subject's voxel space.


\paragraph{Masking}
%
First, empirical $Z$-maps of the training subjects' localizer contrasts were
masked with the same mask as the time series data that were used to generate the
\ac{cfs}.
%
Thus, voxels were restricted to voxels located within the union of individual
\acp{ppa} \citep[s.][]{haeusler2022processing} that was warped from group space
\todo[inline]{"group space" is too vague!} into each subjects' voxel space, and
the subject-specific \ac{fov} of the audio-description.


\paragraph{Estimation via functional alignment}
% functional alignment; into CFS (calling srm.transform(masked\_zmaps))
In the case of estimation via functional alignment, we then used the
transformation matrices that were derived during training of the \ac{cfs} in
order to project the masked empirical $Z$-maps from each training subject's
voxel space into the \ac{cfs}.
% into subject
In order to project the data from the \ac{cfs} into the test subject's
voxel space, we then used the transpose of the transformation matrix
that we acquired during the alignment of the test subject.
% take the mean
The arithmetic mean of $N-1$ the projected empirical $Z$-maps served as the
predicted $Z$-map estimating the test subject's empirical $Z$-map.


\paragraph{Estimation via anatomical alignment}

\todo[inline]{was it transpose of the matrix to warp from MNI into subject, or
a separate one?}

% anatomical alignment; into MNI
In case of estimation via anatomical alignment, we used previously computed
transformation matrices
\citep[][\href{https://github.com/psychoinformatics-de/studyforrest-data-templatetransforms}{\url{github.com/psychoinformatics-de/studyforrest-data-templatetransforms}}]{hanke2014audiomovie}
in order to project the data via a non-linear transformation from each training
subject's voxel space into the MNI space.
% from MNI into subject
In order to project the data from MNI space into the test subject's voxel space,
we then used the transpose of the transformation matrix [did I? or was it
another matrix?].
% take the mean
As in the case of functional alignment, the arithmetic mean of the projected
$Z$-maps served as a test subject's predicted $Z$-map.


\subsection{Prediction of auditory PPA}

\todo[inline]{We also estimate $Z$-maps from \citet{haeusler2022processing}}

\todo[inline]{add text here}


\subsection{Pearson \& Cronbach's alpha}
% Pearson's
In order to quantify the estimation performance based on the functional and
anatomical alignment procedure, we calculated the Pearson's correlation
coefficients as a measure of similarity between the empirical $Z$-maps gained
from the localizer experiment and the predicted $Z$-maps.

% Cronbach's Alpha
Further, we calculating Cronbach's Alpha across the four runs of the localizer
as a measure of internal consistency (i.e.  reliability) and proxy for noise
ceiling of the visual localizer.
%
``We reasoned that across-subject variability cannot be expected to be lower
than within-subject variability over time (reproducibility)''
\citep{rosenke2021probabilistic}.


\subsection{Backup: alternative template creation}

\todo[inline]{imo, this part should be dropped but anyway...}

\todo[inline]{iirc, I projected all subjects' localizer time series through
model space into test subject voxel space; then, calculated the contrast
with these data}

\todo[inline]{s. scripts 'test/data\_denoise-vis.py' \& 'test/data\_srm-vis-to-ind.py'}

\todo[inline]{the problem was: if one wants to test the different transformation
matrices (I only did it with one; imo, based on alignment using the whole
audio-description) it gets totally messy \& computational intensive}

\todo[inline]{results: performance was the same if not slightly worse}



\section{Results}

\todo[inline]{as I see it, this section is (gonna be) pretty short...}

\todo[inline]{statistical test of differences for prediction from alignment via
localizer runs}

\todo[inline]{finalize 'statistics\_t-test-correlations.py' (!), and write the
text/numbers here; do not forget to mention that correlations were
Fisher-transformed (which Jiahu did not)}


Unthresholded $Z$-maps [in each subject's voxel space] can be found at
\href{https://identifiers.org/neurovault.collection:12340}{\url{neurovault.org/collections/12340}}.
%
Pearson correlation coefficients between empirical $Z$-maps (results of
localizer; y-axis) and estimated $Z$-maps (see Fig.~\ref{fig:stripplot}).



\begin{figure*}[tbp] \centering
    \includegraphics[width=\linewidth]{figures/stripplot.pdf} \caption{
    %
    \textbf{Correlations between empirical and predicted
    \textit{\textbf{Z}}-maps.}
    %
    Grey dots: A left-out subject's $Z$-map was estimated by projecting all
    other subjects ($N = 13$) $Z$-maps through the MNI152 space into the
    left-out subject space and averaging values across subject; correlations
    between empirical values from the localizer \& the predicted values using
    anatomical alignment.
    %
    Green dots: estimation from visual localizer.
    %
    Blue dots: transformation matrices computed based on an increasing number of
    segments of the audio-description; correlations between empirical values \&
    the predicted values using parts of the audio-description.
    %
    Red dots: transformation matrices computed based on an increasing number of
    segments of the movie; correlations between empirical values \& the
    predicted values using parts of the movie.
}
\label{fig:stripplot}
\end{figure*}


\subsection{Template(s) from from \citet{jiahui2020predicting}}

%
``After 2-step hyperalignment, the mean Pearson correlation values between
face-selectivity maps based on a participant's own localizer data and the
predicted map after hyperalignment were 0.55 (N = 15, S.D. = 0.08).
%
With surface alignment, the average Pearson correlation values across
participants were 0.40 (N = 15, S.D. = 0.08) in the studyforrest dataset (Fig.
3).
%
The difference between the hyperaligned and the surface-aligned mean correlation
values was highly significant (studyforrest: t(14) = 17.39, p < 0.001)''
\citep{jiahui2020predicting}.



\subsubsection{Cronbach's Alpha}

\todo[inline]{Cronbach's alpha could be plotted as dot per subject in the
stripplot (which is gonna be messy) or the average (Fisher's transformed?)
could be plotted as a horizontal line (s. Fig 2 in
\citet{jiahui2020predicting})}


\paragraph{Template from \citet{jiahui2020predicting}}
%
``We compared the correlations between maps estimated from a participant's own
data and maps estimated from other participants' data to the reliability of the
localizer.
%
We computed the reliability of the contrast maps with Cronbach's Alpha based on
variability across the four localizer runs for each set.
%
The mean Cronbach's Alpha between the four localizer runs was 0.60 (N = 15, S.D.
= 0.14)'' \citep{jiahui2020predicting}.

%
``These results mean that if we scan each participant for another 4 localizer
runs, and compute the correlation between the two maps (4 runs vs. 4 runs), the
correlation would be 0.60 on average in the studyforrest''
\citep{jiahui2020predicting}.
%
``Cronbach's alpha indicates that the predicted contrast map based on
hyperalignment is close to or as good as the real contrast map based on four
localizer runs (studyforrest: t(14) = 0.61, p = 0.55; Grand Budapest: t(20) =
3.02, p = 0.007)'' \citep{jiahui2020predicting}.

%
``The predicted contrast map based on hyperalignment was better than the
contrast map based on data from three out of four localizer runs in other
participants (t(14) = 2.36, p = 0.03) and in Grand Budapest, the predicted
contrast map was comparable to the contrast map based on three localizer runs in
other participants (t(20) = 0.48, p = 0.63)''
\citep{jiahui2020predicting}.\todo{what?}


\subsection{plot\_bland-altman.py}

\todo[inline]{I hate that script! Hence, it should not be included ;-).}


\subsection{Plots of brain slices?}

\todo[inline]{iirc, we agreed on that it's not necessary}





\section{Discussion}

\subsubsection{Just a template from \citet{weiner2018defining} with points
remember}


\citet{weiner2018defining} ``The identification of the PPA is complicated by
methodological considerations:

\begin{enumerate}

%
\item the PPA definition may depend on the type of experiment, task, and
        stimuli used.
%
\item The boundaries of the PPA may depend on the statistical threshold used
    [which we did not not do].
%
\item The spatial extent and localization of the PPA may vary if defined within
    the native brain space of an individual or based on a group analysis.
%
\item The size of the PPA may depend on data acquisition choices (e.g. large vs.
    small voxels) and data analysis choices (e.g. liberal smoothing vs. no
        spatial smoothing)'' \citep{weiner2018defining}.

\end{enumerate}


\subsection{Short Summary of...}

\subsubsection{Aims \& hypotheses}

\todo[inline]{s. general introduction and SRM-part introduction}


\subsubsection{Methods}



\subsubsection{Results}




\subsection{We created a common functional space}

%
Results indicate that we are able to use data from one group of 13 participants
to learn a 10-dimensional shared space for the fMRI data.
%
We have cross-subject, cross-experiment, and cross-scanner prediction; AV \& VIS
are from the same scanner but not from same session.

%
``Results suggest that our pROI of place selectivity provides a robust
prediction of the location of high place selectivity within medial VTC that is
generalizable across data collected with different scanners, participants,
images used for localization, data acquisition, and analysis methods''
\citep{weiner2018defining}.



\subsection{Prediction based on alignment via movie segments}

%
15 min of movie watching used for functional alignment outperform prediction
using anatomical alignment;
%
30 minutes of movie watching outperform 15 minutes of movie watching;
%
more than 30 minutes do not lead to a significantly improved prediction
performance.

%
Asymptotic ``performance curve'' might be different for another brain region
(temporal receptive fields?); retinotopic mapping vs. ``higher'' cognition  vs.
executive functions (prefrontal cortex)?


\subsubsection{Why partial alignment is awesome}


\todo[inline]{cf. general introduction \& SRM introduction}

%
Reduced costs.
%
There is a benefit of shared parts of naturalistic stimuli across datasets;
shared stimulus part is easier than shared subjects (e.g.
\citep{zhang2018transfer}).



\subsection{Prediction based on alignment via audio segments}

Did work out but did not work out "so well"...


\subsubsection{PPA study: model-driven; here: data-driven approach}
%
Findings from \citep{haeusler2022processing} indicating that "auditory PPA" is
restricted to anterior "visual PPA" need to be replicated.
%
Results could be influenced by paradigm and methodological choices.
%
For example, we might have modeled the time course of "spatial responses"
"insufficiently" in \citep{haeusler2022processing}.
%
However, the present study is model free.
%
``SRM will improve sensitivity for detecting a cognitive process of interest in
the test data if the training stimuli or trials strongly and variably engage
that process in a way that is reliable across participants''
\citep{cohen2017computational}.
%
Present results kind of support findings that responses in the PPA are different
in the audio-description compared to the movie.


\subsubsection{Auditory stimulus to localize visual area?}

\todo[inline]{cf. general introduction \& SRM introduction}

%
\citep{rosenke2021probabilistic}:
``congenitally blind [
    Mahon et al. 2009;
    Bedny et al. 2011;
    Striem-Amit, Cohen, et al. 2012a;
    van den Hurk et al. 2017
] or individuals with
%
visual agnosia/prosopagnosia [
    Schiltz and Rossion 2006;
    Steeves et al. 2006;
    Sorger et al. 2007;
    Barton 2008;
    Gilaie-Dotan et al. 2009;
    Susilo et al. 2015
]'' \citep{rosenke2021probabilistic}.




\subsection{Prediction based on alignment via localizer runs}

\subsubsection{Why we did it}

%
``The algorithm also can be applied to simpler, controlled experimental data,
but our previous results showed that the sampling of response vectors from these
experiments is impoverished and produces a model representational space that
does not generalize well to new stimuli in other experiments (Haxby et al.
2011)'' \citep{guntupalli2016model}.
%
``Estimating the parameters to transform high-dimensional spaces from individual
brains into a common high-dimensional space requires a rich set of data that
samples a wide variety of cortical patterns in order to generalize to novel
stimuli or tasks'' \citep{haxby2020hyperalignment}.

%
Hence, we also performed functional alignment based on a stimulation paradigm
using simplified stimuli [the localizer].
%
Our results show that is works not as good as using the transformation matrices
based on data from the naturalistic paradigms.


\subsubsection{Our results: in line with previous studies (focus on \ac{cfs})}
%
Results are in line with previous studies \citep{haxby2011common,
guntupalli2016model} that have shown that ``hyperalignment of data using a set
of stimuli that is less diverse than the movie is effective, but the resultant
common space has validity that is limited to a small subspace of the
representational space in VT cortex'' \citep{haxby2011common}, ``presumably
because such experiments sample a sparser range of brain states
\citep{guntupalli2016model}''.


\subsubsection{Our results: focus on validity of transformation matrices}

%
Our results provide evidence that transformation matrices calculated based
on data from naturalistic stimuli promise an increased validity of derived
transformation for functional alignment over transformation matrices based on
data (of the same!) paradigm based on simplified stimuli.

%
Compared to paradigms with simplified stimuli, naturalistic stimuli sample a
broad range of brain states \citep{guntupalli2016model, haxby2011common} that
reflect (confound) statistics of the natural environment, promising an increased
validity of transformations of functional alignment and enable investigation
of the acquired data for a variety of research questions to research
questions/domains/paradigms (e.g.  visual or auditory perception, spatial
cognition; emotion; music, speech or social perception).

%
Probably of higher generalizability to predict results from other localizers
(e.g.  visual or auditory perception, spatial cognition; emotion;
music, speech or social perception).








\subsection{Differences to studies creating probabilistic atlases}

\todo[inline]{This subsection is far too long, obviously; if discussed, quotes
can be converted into some sentences stating the gist of the quotes}

\subsubsection{we need fMRI not just MRI}

%
Compared to estimation procedures based on anatomical alignment (i.e.
\citep{weiner2018defining}), the current estimation procedure needs an
additional functional scan.





\paragraph{Our procedure}

%
We used the union of individual \ac{ppa} ROIs as an probabilistic functional
atlas in order to restrict the number of voxels to voxels that have shown to be
located in the \ac{ppa} \ac{roi} of at least one subject [Julian et al., 2012,
An algorithmic method (?)].

%
We have a little leakage of test data.
%
Especially at the borders of the ROI, we miss some voxels (of some participants)
cause the binary masks is based on a ``titrated threshold''
\citep{sengupta2016extension}

%
In the future, an independent probabilistic atlas should be used, the \ac{roi}
dilated, [and a separate model calculated for each hemisphere].


\subsubsection{No cherry picking of subjects}

%
Compared to other studies [which studies did it?], we did no cherry picking by
excluding subjects that did not provide functional ROIS in one or both
hemisphere in the functional localizer [or naturalistic stimulus paradigms]
before calculating the \ac{cfs}.



\subsubsection{Others: Input is based on binary decision (a.k.a. on threshold)}

%
``We identify and predict the most probable location of place-selective voxels
within medial VTC of an individual brain that is impervious to these
methodological decisions'' \citep{weiner2018defining}.
%
``Decisions such as the statistical threshold used, the precise contrast, or the
amount of spatial smoothing influence the spatial extent of the (p)ROI on the
cortical surface'' \citep{weiner2018defining}.
%
\citet{weiner2018defining} identified place-selective voxels ``within each
subject's native brain anatomy using a common threshold (t > 3, voxel-level) for
''.

%
\citet{rosenke2021probabilistic} ``selected a statistical threshold of t=3 for a
whole-brain map''


%
``In the outlined procedure the extent of identified clusters (and thus the
overlap calculation) depended on subjectively determined thresholds''
\citep{frost2012measuring}.


%
``Subject-specific activation image for faces versus objects (the statistical
image derived from the three-run fixed effect analysis providing information on
subject-specific activations) was thresholded with Z=2.3 (p=0.01, right tailed,
uncorrected) and then overlaid on the FSR spatial reference map''
\citep{zhen2015quantifying}.


%
``The choice of the threshold in localizing the FSRs inevitably influenced the
amount of variation in the location of the FSRs.
%
To avoid bias from a single arbitrary threshold, we also constructed the
probabilistic functional atlas using other commonly used Z thresholds such as
3.09 (i.e., p = 0.001, right tailed, uncorrected) and 3.71 (i.e., p = 0.0001,
right tailed, uncorrected) (Fig. S3),
%
The probabilistic atlas and maximum probability map derived at different
thresholds revealed similar patterns, indicating that our atlas is stable and
not sensitive to the choice of threshold'' \citep{zhen2015quantifying}.



\subsubsection{Others: ROI creation}

%
``ROIs where manually defined in individual subjects on their cortical surface
reconstruction in anatomically plausible locations''
\citep{rosenke2021probabilistic}.

%
``Functional areas of interest were determined by selecting the activity cluster
on the surface falling in the region reported in previous standard localizer
studies'' \citep{frost2012measuring}.


%
``We used the conventional approach of drawing are borders by hand.
%
At least 2 experimenters experienced in retinotopic mapping drew borders
independently using the same set of published criteria (detailed below) and
subsequently resolved any inconsistencies'' \citep{wang2015probabilistic}.


%
``Subject-specific SSRs were delineated manually in the parcel unit based on the
individual activation map from the contrast of scenes versus objects''
\citep{zhen2017quantifying}.

%
``The subject-specific activation image was first thresholded (Z>2.3,
uncorrected) and partitioned into many small parcels with the watershed
algorithm:
%
The algorithm partitions an image by analogous process of a landscape being
flooded by water in which water seeps in from every local minimum and the
landscape is finally divided into multiple regions separated by the watersheds
[Meyer, 1994].
%
Raters handpicked the parcels on the individual activation map to construct the
SSRs following a standard procedure:
%
1) gyri and sulci from MNI152 template were used as the anatomical landmarks to
locate the SSRs (PPA was located near the lateral lip of the collateral sulcus
and adjacent medial fusiform gyrus) coarsely [Nasr et al., 2011].
%
2) we used the SSR group labels (the functional landmark) as a spatial extent
reference (the major part of each candidate parcel overlapped with or neighbored
to the corresponding functional label).
%
3) From the parcels that showed good correspondence to both anatomical and
functional landmarks, we identified the one with the strongest scene-selective
activation as the center of a SSR, and iteratively merged the parcels which
connected with the selected parcels into the regions until no candidate parcels
met the criteria'' \citep{zhen2017quantifying}.


%
``Subject-specific FSR [face-selective regions] were delineated by seven raters
specializing in the ventral visual pathway.
%
Three maps were used in combination:
%
1) the subject-specific activation map
%
2) an FSR spatial reference (map of the high-probability parcels derived from
the probabilistic activation map for face recognition [Zhen et al.,
2013] providing functional landmarks for the location and extent), and
%
3) a macro-anatomical landmark reference (provided by the MNI152 T1 template
providing macro-anatomical landmarks for the location and extent)''
\citep{zhen2015quantifying}.

%
``Thresholded activation image was partitioned into many small parcels using the
watershed algorithm [Meyer, 1994].
%
Then, seven raters handpicked the small parcels from the watershed to construct
the target regions based simultaneously on the FSR spatial reference and the
macroanatomical landmark reference'' \citep{zhen2015quantifying}.





\subsubsection{Others: Atlas creation}


``We provide the likelihood that a given point would be classified as a part of
any region (full probability map) and the most probable region for any given
point (maximum probability map)'' \citep{wang2015probabilistic}.

``A full probability map (FPM) was generated for each ROI by dividing, at each
particular node, the number of times that location belonged to that ROI by the
number of subjects included for that ROI'' \citep{wang2015probabilistic}.

``The atlas accurately predicts the location [but just the location] of an
independent dataset of ventral temporal cortex ROIs''
\citep{rosenke2021probabilistic}.


``A probabilistic atlas (or map) was created for each SSR by calculating the
frequency of a respective SSR being present at a given position across all
subjects'' \citep{zhen2017quantifying}.
%
``The map coded the occurrence probability of each voxel being located in the
SSR, and provides a voxel-wise description for inter-individual variability in
the location and extent'' \citep{zhen2017quantifying}.


%
``A probabilistic atlas was constructed to characterize interindividual
variability of FSRs revealing that the FSRs were highly variable in location and
extent across subjects'' \citep{zhen2015quantifying}.

%
``For each FSR, a probabilistic map was created to characterize the likelihood
that a given voxel belonged to that FSR.
%
The subject-specific FSR delineated in individual brains were averaged in the
MNI152 space so that the value at any voxel coded the likelihood of the voxel
being located in the FSR, thus giving a measure of the variability in location
and extent of the FSR over subjects at voxel-level resolution''
\citep{zhen2015quantifying}.

%
``A probabilistic atlas of the FSRs was created by calculating the probability
of a respective FSR being present at a given position to characterize the
interindividual variability of the locations and extents (or borders) of the
FSRs.
%
The probabilistic atlas consists of a set of 12 probability maps [12 FSR] that
reflect the interindividual variability of the respective FSRs.
%
High interindividual variability was observed for all FSRs: no one voxel showed
a 100-percent chance of being in one of the FSRs across subjects.
%
Maximum probability that a voxel belonged to an FSR ranged from 0.24 (left aFFA)
to 0.74 (right pSTS) (Table 1)'' \citet{zhen2015quantifying}.



%
``We computed the overlap of functional areas across subjects for vertices
belonging to a POI of at least one subject using the formula: Nv/N.
%
Nv is the number of subjects whose functional area includes vertex v,
%
N is the number of subjects.
%
The obtained values for all relevant vertices constitute the probabilistic map
for a particular localized region-of-interest.
%
An overall probabilistic map is obtained by adding the resulting overlap vertex
values for all included POIs.
%
A threshold of N=10\% is applied to all probabilistic maps to avoid depicting
regions as "overlap" where only one subject has a functional area''
\citep{frost2012measuring}.


``Probabilistic maps were generated by summing the 12 fROIs [from 12
participants] at each point along the cortical surface of the FS average brain
and dividing by the number of participants.
%
Each vertex within the map reflects the proportion of participants exhibiting
place selectivity at that location on the cortical surface''
\citep{weiner2018defining}.





\subsubsection{Others: overlapping ROIs}

%
In the case of an activation cluster transitioning into an adjacent one of the
same visual category, we divided those clusters into separate ROIs by following
the spatial gradient of t-values and separating the two areas at the lowest
t-value'' \citep{rosenke2021probabilistic}.


%
``Probability maps determine the probability that each vertex belongs to a
given fROI.
%
However, it is possible that a point on the brain may belong to more than one
probabilistic fROI.
%
This overlap is more likely to occur along boundaries of neighboring functional
regions'' \citep{rosenke2021probabilistic}.

%
``We generated a maximum probability map (MPM) of each area in order to assign a
unique functional label to each vertex in the atlas.
%
A maximum probability map (MPM) was calculated for each node by comparing the
probabilities of all areas at that node and assigning the node to the area with
the highest probability.
%
Using the probabilistic fROIs, we determined which vertices were shared by more
than one probabilistic fROI and assigned these vertices to a single fROI based
on the area that showed the highest probability at that vertex''
\citep{rosenke2021probabilistic}.

%
``We established that a [probabilistic] group map threshold of 0.2 allows for
greatest predictability across regions by systematically varying the group map
threshold for predicting a left-out subject's fROI,
%
Using the 0.2 threshold, we generated a functional atlas of occipito-temporal
cortex by generating an MPM'' \citep{rosenke2021probabilistic}.



%
``Because the probabilistic maps of adjacent SSRs (e.g., PPA and RSC) overlapped
to some degree in the periphery, a maximum-probability map (MPM) was then
created to obtain an integrated, non-overlapping map for all SSRs''
\citep{zhen2017quantifying}.

%
``Maximum-probability maps define the most likely SSR to which each voxel
belonged.
%
Each MPM integrates the multiple probabilistic SSR maps into one map, and to
characterize the spatial relations among SSRs:
%
We compared each voxel's values from each probabilistic map, and assigned that
voxel to the SSR which showed the highest probability at the voxel.
%
If one voxel showed equal probabilities for multiple SSRs, it would be assigned
to the SSR, which owned the highest average probability in the 26 immediate
neighbors of the voxel.
%
The voxels with a maximal probability below 10\% were set to 0, indicating that
they most likely did not belong to any SSR'' \citep{zhen2017quantifying}.


``The MPM revealed a clear topographical relationship between these SSRs (Fig.
3B).
%
PPA was located on the lips of the collateral sulcus and the parahippocampal
gyrus, and abutted the medial fusiform gyrus.
%
RSC occupied the retrosplenial cortex, reaching to the PPA ventrally, and
extending superiorly along the parieto-occipital sulcus.
%
TOS occupied the lateral occipital gyrus and the transverse occipital sulcus''
\citep{zhen2017quantifying}.


%
``The probabilistic maps of adjacent FSRs showed overlaps to some extent in the
periphery.
%
An MPM was created to obtain a non-overlapping representation of the FSRs in
order to classify each voxel to the most likely region:
%
MPM represents multiple FSRs in one volume, which reveals a basic topographical
pattern of these FSRs (Fig. 4B)'' \citet{zhen2015quantifying}.

%
``A maximum-probability map (MPM) was constructed to summarize the probabilistic
maps of all FSRs into one volume because of the interindividual variability,
probabilistic maps from adjacent FSRs often showed some overlap.
%
MPM was constructed by comparing the probabilities for each FSR (i.e., the
overlapping frequency) in each voxel and assigning that voxel to the FSR to
which it had the highest probability of belonging.
%
If two FSRs showed equal probabilities, the problematic voxel was assigned to
the FSR with the higher average probability in the 26 immediately adjacent
voxels.
%
The voxels with a maximal probability smaller than 10\% were set to 0,
indicating that they most likely did not belong to any FSR.
%
Result: MPM defined the most likely FSR to which each voxel belonged and
represented all FSRs in a continuous, but non-overlapping manner in one
volume'' \citep{zhen2015quantifying}.


\subsubsection{Others: selectivity-map by \citet{weiner2018defining}}
%
``The question is whether this pROI captures the 'peak' voxels exhibiting the
highest place selectivity in medial VTC.
%
We generated an average map of selectivity in which vertices are assigned
continuous values of place selectivity rather than a binary distinction as in
the probability maps from the prior analyses.
%
We then visualized the group place selectivity map relative to the group pROI
from all 24 participants (Fig. 4).
%
The group map illustrates place selectivity within the CoS, LG, PHG, the
parietal occipital sulcus (POS), and retrosplenial cortex (RSC).
%
Weakly place-selective voxels (t-values greater than 0 and less than 2) extend
into the medial fusiform gyrus and more posteriorly along the CoS.
%
The locus ("hotspot") of peak place selectivity is near the medial lip of the
CoS in the right hemisphere and close to the center of our pROI near the fundus
of the CoS in the left hemisphere (Fig. 4A)'' \citep{weiner2018defining}.

``Examining the location of our pROI relative to the peak cluster of place
selectivity in individual participants shows that there are individual
differences in the location of voxels with highest place selectivity (Fig.
4B-C):
%
Voxels with the highest place selectivity are not always located within the same
exact location in the pROI for each participant and small clusters of high place
selectivity can also extend outside of the pROI.
%
Despite these individual differences, all participants have voxels with the
highest place selectivity within the pROI (Fig. 4BC)''
\citep{weiner2018defining}.

%
``There is a fundamental difference between the probability map of
place-selective ROIs and the selectivity maps (Figs. 4 and 5).
%
The map of pROIs across subjects is generated after assigning either a 1 (if the
ROI is present) or a 0 (if the ROI is not present) at vertices of the FS average
surface.
%
In the pROI case, there is a threshold and the group map does not reflect
selectivity and instead represents the percentage of overlap across subjects at
each vertex.
%
The selectivity map reflects a continuous metric in which a vertex is assigned a
selectivity value (a t-statistic) first for each subject and then averaged
across subjects.
%
[!] The selectivity map is not thresholded and the group map directly indicates
selectivity (each vertex reflects the average t-value across subjects)''
\citep{weiner2018defining}.



\subsubsection{Others: prediction via Dice}

\paragraph{Definition of Dice}

``We calculated the Dice coefficient to assess the correspondence between the
probabilistic ROI and individually-defined ROIs in independent participants''
\citep{weiner2018defining}.
%
``The Dice coefficient is a measure of similarity of two sample and calculated
with the following formula:
%
P is the surface area of the probabilistic ROI.
%
A is the surface area of the actual ROI in an individual subject.
%
Perfect alignment between the probabilistic prediction and the actual ROI in
individual subjects would result in a Dice coefficient of 1 (perfect
predictability) and complete misclassification would result in a Dice
coefficient of 0 (no predictability)'' \citep{weiner2018defining}.


\paragraph{Dice as performance measure}

\todo[inline]{others take a threshold for minimum of participants that have have
the PPA in a voxel / vertex}

%
``We calculated the Dice coefficient using different thresholds for the
probabilistic group map, ranging from a liberal unthreshold (one subject at a
given voxel/vertex is enough to assign it to the group map) map to a
conservative threshold where all N-1 subjects had to share a voxel/vertex to be
assigned to the group map'' \citet{rosenke2021probabilistic}.

%
``We compared Dice coefficients across the two alignment methods using a
repeated measures analysis of variance with individual regions as different
entries, alignment method (CBA vs. NVA) as within-subject factor, and hemisphere
as between-subject factor.
%
We ran this comparison on two different thresholds:
%
once on unthresholded group maps, and once on a threshold that produced - across
regions and methods - the highest predictability.
%
To determine this threshold, we averaged Dice coefficient values across
alignment methods, hemispheres, and ROIs, resulting in one Dice coefficient per
threshold level.
%
Comparison across thresholds revealed that a threshold of 0.2 produced the
highest predictability.
%
Additionally, we ran paired permutation tests within each region on Dice
coefficient results at threshold 0.2 to establish whether the specific region
showed a significant Dice coefficient for either alignment (NVA or CBA)''
\citep{rosenke2021probabilistic}.



%
``Probabilistic ROIs were generated using three different thresholds to test if
and how different threshold values influence the predictability of place
selectivity in a new group of participants.
%
(1) unthresholded,
%
(2) thresholded by 33\% overlapping participants, or
%
(3) thresholded by 66\% overlapping participants.
%
We used these three different thresholds to test if and how different threshold
values influence the predictability of place selectivity in a new group of
participants. Based on related work [Weiner et al., 2017], a threshold of 0.33
is sufficient for predicting functional ROIs in VTC''
\citep{weiner2018defining}.

%
``Since the 33\% thresholded pROI performed the best in the prior analyses
[Weiner, 2016?], we used this threshold for the present (and subsequent)
analyses.
%
Results revealed high predictability in the right and left hemisphere (about
0.70), which was not different than the ceiling performance (all ts < .7, all ps
> .5; Fig. 2D).
%
Cross-validated performance from 23 participants is not significantly different
than the ceiling performance.
%
This provides statistical evidence supporting that the structural-functional
predictability from our participants likely reflects a predictability that is
reflective of the general population'' \citep{weiner2018defining}.

%
``We used the Dice coefficient metric to quantify how well pROIs predict
functionally-defined ROIs in an independent group of participants [by
calculating] the amount of spatial correspondence between the two regions in
individual brains.
%
We measured cross-validation performance at three threshold levels (no
threshold, 33\%, and 66\%) using group pROIs from Study 1 and individual ROIs
from Study 2 and vice versa.
%
The ceiling Dice coefficient in our data is 0.73 in the left hemisphere and 0.72
the right hemisphere'' \citep{weiner2018defining}.

``Results of the cross-validation analysis reveal that our pROI predicts
individual ROIs with high accuracy across hemispheres.
%
The unthresholded ROI had the lowest predictability (about 0.56 left and right)
and the 66\% thresholded ROI had an intermediate predictability (about 0.60 left
and right); all were significantly lower than the ceiling performance (all ts >
4.5, all ps < 10-4)
%
At a threshold of 33\%, the Dice coefficient is 0.70 +/- 0.03 in the right
hemisphere and 0.65 +/- 0.03 in the left'' \citep{weiner2018defining}.



\subsubsection{We predict $Z$-maps}

\todo[inline]{We predict $Z$-maps that is way richer; what could you do with
that except just say that the location is here: classification etc.?}

\todo[inline]{probabilistic atlas only allow binary classification of voxels}

\todo[inline]{probabilistic atlases are problematic when regions overlap}

``Future studies may generate more sophisticated atlases, which contain not only
a unique tiling of cortical regions but also allow for multiple functional
clusters to occupy overlapping areas and indicate probabilities for multiple
categories at each voxel'' \citep{rosenke2021probabilistic}.








\subsection{Prediction of auditory PPA (via movie or audio-description)}


\subsubsection{Reliability of visual PPA}

% usually, visual PPA works pretty well
The visual \ac{ppa} can be reliably localized using a localizer.
%
For example, \citet{zhen2017quantifying} successfully delineated the left- and
right hemispheric \acp{ppa} in 97.5\% of 202 subjects.

% localizer data
\citet{sengupta2016extension} successfully delineated the left-hemispheric
\ac{ppa} in X of X subjects and right-hemispheric \ac{ppa} in X of X subjects
based on localizer data

% movie
\citet{haeusler2022processing} successfully delineated the left-hemispheric
\ac{ppa} in X of X subjects and right-hemispheric \ac{ppa} in X of X subjects
based on movie data.
%
But the modeling was adventurously in the first place and a proof of concept.


\subsubsection{Reliability of auditory PPA in \citet{haeusler2022processing}}

\todo[inline]{check: in those subjects who do not have an "auditory PPA" in the
(specific) modeled contrast: is prediction performance of not just the auditory
but also visual PPA worse? Is the response pattern simply not there or just
poorly modeled poorly in \citet{haeusler2022processing}}

% audio-description
Using the audio-description's data, \citet{haeusler2022processing} successfully
delineated the left-hemispheric \ac{ppa} in X of X subjects and
right-hemispheric \ac{ppa} in X of X subjects.


\subsubsection{Results of auditory PPA}

Our results revealed that...


\subsubsection{Discussion of auditory PPA}

\todo[inline]{the text regarding individual differences in brain
activation possibly correlating with behavior is in the general discussion where
PPA is recapitulated (a.k.a "grasping of verbal way descriptions")}

%
Response in PPA during AO might (actually / reliably) be different (and not just
a result that depends on the paradigm and the hilarious modeling approach in
\citet{haeusler2022processing}).

%
If the response pattern is simply not occurring in these subjects then
individual differences in brain patterns might reflect differences in behavior
%
Do the subjects simply do not give a shit about auditory spatial information?
%
Are they simply not attending to it? Or are they simply incapable to process it?


\subsection{In all cases: tacit assumption that localizer = ground truth}

\todo[inline]{essentially issues of reliability \& validity}

%
``The localized set of voxels may not correspond well to those being tested in
the main experimental run, decreasing sensitivity and increasing both false
positives and false negatives'' \citep{duncan2009consistency}.
%
Even with the same stimuli / task, ``the tacit assumption is that the same task
in the same subject will identify essentially the same set of voxels despite
various sources of physiological and scanner noise [Aguirre et al., 1998;
Handwerker et al., 2004; Kruger and Glover, 2001] \citep{duncan2009consistency}.


\paragraph{More robust localizer that uses video snippets?}

% take a more robust dynamic localizer using short videos
``The dynamic localizer (in Grand Budapest data set) was significantly more
reliable than the static localizer (in studyforrest data set) (t(34) = 3.76, p <
0.001) despite its shorter length (four 234s runs versus four 312s runs,
respectively)'' \citep{jiahui2020predicting}.
%
``Dynamic videos of faces and control categories to localize face-selective
topographies provides more reliable maps and better estimate the extent of
face-selective regions than do localizers with still image stimuli [Fox et al.,
2009; Pitcher et al., 2011]'' \citep{jiahui2020predicting}.


\subsection{Shared responses are problematic in case of atypical organization /
outliers}

\todo[inline]{We: matrices for individual mapping; but onto shared responses}

\todo[inline]{Fits in here or in "future question" regarding "other functional
alignment algorithms". In any case, it's a nice transition from "shortcomings"
to "future questions"}

\todo[inline]{\citet{turek2018capturing}: SRM capturing shared \& individual
component; is there a "real" paper that has been using that model already?}

\todo[inline]{on the other hand: we get a pattern of "what it should look like
if the person was an average person"?}



``The flip side of focusing on shared responses is to focus on responses that
are idiosyncratic to individuals'' \citep{cohen2017computational}.
%
``Although these idiosyncratic responses are excluded in SRM, they are not
necessarily noise and may in fact be highly reliable within participants''
\citep{cohen2017computational}.
%
``SRM can be used to isolate participant-unique responses by examining the
residuals after removing shared group responses, or it can be applied
hierarchically to the residuals to identify subgroups [\citet{chen2017shared}]
'' \citep{cohen2017computational}.
%
``In cases where each subject's unique response is of more interest than the
shared signal, SRM can be used to factor out the shared component thereby
isolating the idiosyncratic response for each subject
[\citep{chen2015reduced}]'' \citep{kumar2020brainiak}.

%
``Recognizing that signal exists beyond the average or shared response of a
group, such studies exploit idiosyncratic but stable responses to account for
previously unexplained variance in brain function, behavioral performance and
clinical measures [e.g., Finn (2015). Functional fingerprinting (based on
connectivity)]'' \citep{cohen2017computational}.


``We developed using data from a small subset of the population (eight
subjects).
%
It is unclear how our method would cope with subjects whose retinotopic
organizations are much different than those that are typically assumed in vision
science.
%
Such edge-case subjects could include members of clinical populations, such as
individuals lacking an optic chiasm [Hoffmann et al., 2012; Bao et al., 2015;
Olman et al., 2018], or healthy individuals whose retinotopic boundaries are
merely unusual [Van Essen and Glasser, 2018]'' \citep{benson2018bayesian}.

``Variability was observed from a cohort of homogeneous young adults with a
narrow age range, which limits the generalization of the variability observed
here to people with different ages, especially children and the elderly.
%
Future studies are needed to characterize how the different aspects of
variability in SSRs change with ages'' \citet{zhen2017quantifying}.



\subsection{Future questions}



\todo[inline]{cf. \citet{bazeille2021template}'s dissertation}



\subsubsection{Volume- vs surface-based}

\todo[inline]{imo, should not be a problem}

\todo[inline]{might even be "better": we are nearer on the raw data 'cause we
work with voxels (not vertices), and both our anatomical and functional
alignment use voxels as input (i.e. it is not mixed)}

We compare volume-based [non-linear] anatomical alignment to volume-based
functional alignment.
%
Future work could compare surface-based alignment that respects cortical folding
structure -- that out-performs predictions based on [affine] volume-based
anatomical alignment \citep{weiner2018defining} -- to surface-based functional
alignment.



\subsubsection{ROI vs. whole-brain (i.e. searchlight)}

\todo[inline]{searchlight SRM \citep{zhang2016searchlight}}

\todo[inline]{negative: more parameters to vary}


``Searchlight functional alignment [give refs] learn local transformations and
aggregate them into a single large-scale alignment.
%
The searchlight scheme [Kriegeskorte et al., 2006], popular in brain imaging
[Guntupalli et al., 2018; 2016], has been used as a way to divide the cortex
into small overlapping spheres of a field radius.
%
This method allows researchers to remain agnostic as to the location of
functional or anatomical boundaries, such as those suggested by
parcellation-based approaches.
%
A local transform can then be learned in each sphere and the full alignment is
obtained by aggregating [e.g. summing as in Guntupalli et al., 2016 or
averaging] across overlapping transforms.
%
The aggregated transformation produced is no longer guaranteed to bear the type
of regularity (e.g orthogonality, isometry, or diffeomorphicity enforced during
the local neighborhood fit)'' \citep{bazeille2021empirical}.
%
``In the case of searchlight Procrustes, we selected searchlight parameters to
match those used in Guntupalli et al. (2016):
%
each searchlight had 5 voxel radius, with a 3 voxel distance between searchlight
centers'' \citep{bazeille2021empirical}.


\subsubsection{Time series vs connectivity-based}

\todo[inline]{kind of a killer cause you do not need intersection of
time series}

\todo[inline]{wtf did \citep{nastase2019leveraging} do?}

``Hyperalignment projects cortical pattern vectors into a common,
high-dimensional information space [Haxby et al., 2020].
%
Derivation of this common space can be based on either neural response profiles
(e.g. data collected during tasks, such as movie viewing (Haxby et al., 2011))
or functional connectivity profiles files [Guntupalli et al., 2018]''
\citep{busch2021hybrid}.

%
``For connectivity hyperalignment, the sampling of connectivity vector space is
defined by the selection of connectivity targets, but the richness and
reliability of connectivity estimates depends on the variety of brain states
over which connectivity is estimated'' \citep{haxby2020hyperalignment}.

% Kumar on Nastase's ugly mofo paper
``Estimating the SRM from functional connectivity data rather than
response time series circumvents the need for a single shared stimulus across
subjects; connectivity SRM allows us to derive a single shared response space
across different stimuli with a shared connectivity profile
\citep{nastase2019leveraging}'' \citep{kumar2020brainiak}.

%
``Both CHA and RHA increased ISCs and bsMVPC classification
accuracies significantly over anatomy-based alignment, but each algorithm
achieves better alignment for the information that it uses to derive a common
model, namely connectivity profiles and patterns of response, respectively''
\citep{guntupalli2018computational}.

% project proposal
``The number of voxels that can be considered simultaneously for functional BOLD
response time series alignment is limited by the number of timepoints in the
calibration scan (about 300-400 voxels for a 15min scan with a 2s TR,
corresponding to a local cortical neighborhood of about 1cm in diameter for a
standard resolution).
%
This limitation does not exist in this form for a functional alignment that is
based on connectivity vectors.
%
Comparable prediction performance can be achieved by using functional
connectivity patterns (correlation of a voxel's time series with reference
regions in the same brain).
%
The length of these connectivity vectors is determined by the number of
reference (or seed) regions in the brain'' [from project proposal].



\subsubsection{Studyforrest dataset: other localizer t-contrasts}

\todo[inline]{in audio-description, the condition ``faces'' was especially hard
to model; good for a master student's project (with an additional twist?)}

The studyforrest dataset's visual localizer \citep{sengupta2016extension} offers
other contrasts (and thus \acp{roi} masks) aimed at localizing the \ac{ffa} and
\ac{ofa} that are associated with face perception \citep{kanwisher1997ffa,
pitcher2011occipitalfacearea}, the \ac{eba} that  is associated with the
perception of human bodies \citep{downing2001bodyarea}, and the \ac{loc} that is
associated with the perception of (small) objects (like tools or toys)
\citep{malach1995loc}.



\subsubsection{New dataset}

\paragraph{Sample size}

\todo[inline]{cf. variability of the \ac{cfs}}

\todo[inline]{can/should that variability somehow be quantified?}

% what is the case
The correlations of shared responses within the \acp{cfs} created from $N-1$
training subjects varied across the folds of the cross-validation.
% interpretation
That means, a change of 1/13 of the data for every subject's analysis is causing
the estimates to vary (how much?)
% conclusion
Future studies, should create a \ac{cfs} based on data from more subjects and
investigate the relationship between number of participants, variability of
parameters, estimation performance.


\paragraph{Shared stimulus}

%
We demonstrated that 15 to 30 minutes of naturalistic stimulation is sufficient
to estimate $Z$-maps of a localizer paradigm.
%
A future study of a larger sample size could use a just a part of the movie or
audio-description..
%
Stimuli can more conveniently be shared across studies than participants across
studies \citep[cf.][an extension of the \ac{srm} for shared subjects
across datasets]{zhang2018transfer}.



\subsubsection{New dataset: other localizers / t-contrasts}

What is the limit of what we can estimate reliably?
%
Retinotopy, language, executive functions (from low-level perception to higher
cognition which might not even be sampled by a movie).

``Results show that the computational principles underlying this common
model have broad general validity for representational spaces in occipital,
temporal, parietal, and frontal cortices'' \citep{guntupalli2016model}.




\paragraph{Functional-anatomical correspondence is different across ROIs}

% Zhen 2017
``Scene-selective regions showed larger interindividual variability [after
non-linear volume-based alignment] than the face-selective regions in both
spatial topography and functional selectivity'' \citet{zhen2017quantifying}.


% category-specific areas
Similar to nonlinear volume-based alignment , similarity across person after CBA
is higher ``for retinotopically defined regions, with character-selective
regions showing the lowest consistency for both alignments, closely followed by
mFus- and IOG-faces'' \citep{rosenke2021probabilistic}.
%
``Future studies may generate more sophisticated atlases, which contain not only
a unique tiling of cortical regions but also allow for multiple functional
clusters to occupy overlapping areas and indicate probabilities for multiple
categories at each voxel'' \citep{rosenke2021probabilistic}.

%
``We localized 13 widely studied functional areas and found a large variability
in the degree to which functional areas respect macro-anatomical boundaries
across the cortex'' \citep{frost2012measuring}.
%
``The percent gain in overlap [after surface-based alignment] differed greatly
across the different functional regions throughout the cortex''
\citep{frost2012measuring}.
%
``CBA is able to separate functional regions which are more prone to blur
together if individual anatomical curvature patterns are not accounted for''
\citep{frost2012measuring}.
%
''There is a strong structural-functional correspondence in some areas whilst in
others the spatial location of the functional area varies greatly across
subjects within a cortical area'' \citep{frost2012measuring}.
%
``There is a surprising amount of variability in that not all functional areas
are tightly bound to anatomical landmarks'' \citep{frost2012measuring}.
%
``Some areas, such as the frontal eye fields (FEF) are strongly bound to a
macro-anatomical location.
%
``Both the sensory and motor hand areas (bank of the central sulcus) were much
better aligned after CBA'' \citep{frost2012measuring}.
%
``The area which shows the most gain in overlap of these regions is V5 / hMT+
with 70.9\% gain in the left hemisphere and 55.6\% gain in the right
hemisphere'' \citep{frost2012measuring}.
%
``Area LOC also showed increased overlap after CBA with a 62.7\% gain in the
left hemisphere and 38.4\% on the right'' \citep{frost2012measuring}.
%
Finally PPA exhibit more gain in the right hemisphere with 27.7\% gain, than on
the left with 17.6\%'' \citep{frost2012measuring}.
%
``Fusiform face area (FFA) on the other hand, varies in its location along the
length of the fusiform gyrus even though the gyri themselves are well aligned
across subjects'' \citep{frost2012measuring}.
%
``The FFA did not exhibit the same strong structural-functional correspondence
and saw more modest increases in overlap after macro-anatomical alignment with
44.1\% and 12\% gain for the left and right hemispheres''
\citep{frost2012measuring}.
%
``Language areas were found to vary greatly across subjects whilst a high degree
of overlap was observed in sensory and motor areas'' \citep{frost2012measuring}.



\subsection{Vision: functional atlas}

\todo[inline]{mih: this chapter does not need its own outlook; outlook will
be in the general discussion anyway (and is more interesting there)}

\todo[inline]{a smallish text should be sufficient here; shift most stuff into
general discussion (and write intro in general intro)}

\todo[inline]{cf. general introduction; SRM introduction; general discussion}

\todo[inline]{check discussion of \citet{jiahui2020predicting} as last resource}


``Because of great intersubject variability in anatomy and structural-functional
correspondence, the anatomical atlases are not sufficient to allow researchers
to infer the location and extent of functional regions and their variability
across individual brains [Frost and Goebel, 2012]'' \citep{zhen2015quantifying}.


\subsubsection{Time, money, questionable compliance / capability}

``Identifying all of the currently known topographic regions of the human visual
system requires multiple scanning sessions.
%
Given the expense and availability of fMRI, this is not always practical''.
%
``For example, time-limitations and subject-fatigue both potentially limit the
time researchers may be able to spend with patients suffering from neurological
or neuropsychological disorders, or with implanted subdural or deep electrodes
(e.g., ECoG)'' \citep{wang2015probabilistic}.

%
``A probabilistic atlas can be used under conditions in which collecting the
data to define maps in individual subjects is impractical or not feasible''
\citep{wang2015probabilistic}.


%
Atlases ``may prove especially useful for predicting an ROI when no localizer
data is available, saving scanning time and expenses, or
%
patient populations, such as patients who have
%
a) a brain lesion [Schiltz and Rossion 2006; Steeves et al. 2006; Sorger et al.
2007; Barton 2008; Gilaie-Dotan et al. 2009; de Heering and Rossion 2015] or are
%
b) are blind [Mahon et al. 2009; Bedny et al. 2011; Striem-Amit, Dakwar, et al.
2012b; van den Hurk et al. 2017]'' \citep{rosenke2021probabilistic}.

Probabilistic atlases will be ``particularly useful in
%
a) patient populations [e.g.  blind individuals; Amedi et al., 2007; He et al.,
2013; Mahon et al., 2009; Wolbers et al., 2011] and,
%
b) intracranial studies [e.g. Bastin et al., 2013; Davidesco et al., 2013;
Engell and McCarthy, 2010; Jacques et al., 2015; Megevand et al., 2014; Murphey
et al., 2009; Rangarajan et al., 2014] in which it may not be possible to obtain
fMRI data, but high resolution anatomical MRI data are typically obtained''
\citep{weiner2018defining}.





\subsubsection{Previously: anatomical alignment}
%
Previous studies used anatomical alignment in order to project data from
probabilistic functional atlases (aligned to a \ac{cas}) onto individual
subjects in order to predict the location of functional areas in new/unknown
subjects.



\paragraph{Probabilistic atlas: use cases}
%
``One way to address limitations [of conducting many localizers] is to create an
atlas in a standard space that links individual points in that space with
functionally defined regions.
%
Given the anatomical and functional variability across subjects, this atlas
should be "probabilistic": it defines the likelihood of a given coordinate being
associated with a given functional region. [our functional alignment procedure
can improve these atlases by providing $z$-values]
%
Such an atlas could be used to infer the topographic location in the visual
system for the results obtained from any independent dataset once transformed
into the same standard space as the atlas'' \citep{wang2015probabilistic}.

%
``Individual \acp{roi} and associated features could serve as a database of the
\acp{roi} in a healthy population.
%
The accumulated data in the atlas could be used as a norm to quantify the degree
of deviation of the FSRs in a new subject and thereby have the potential to
detect deficits in patients'' \citep{zhen2015quantifying}.


%
``A probabilistic functional atlas could serve as a complement to the anatomical
atlases, the atlas supplies a quantitative spatial reference system in which
information from multiple sources can be integrated and compared
\citep{zhen2015quantifying}.
%
By integrating with other atlases, the probabilistic functional atlas would
identify patterns of structural, connectional, and molecular variations in the
functional regions and provide a deeper understanding of the relationship
between brain structure and function'' \citep{zhen2015quantifying}.


\paragraph{Existing atlases}

``Cortical atlases have been developed, which allow localization of visual areas
in new subjects by leveraging ROI data from an independent set of typical
participants [Frost and Goebel 2012; ventral temporal cortex (VTC) category
selectivity: Julian et al. 2012; Zhen et al.  2017; Weiner et al. 2018; visual
field maps: Benson et al. 2012; Benson and Winawer 2018; Wang et al. 2015]''
\citep{rosenke2021probabilistic}.




\subsubsection{Now: functional alignment}

%
Anatomical alignment (used to create the probabilistic atlases above) relies on
data of an anatomical MRI scan that performed as an standard routine
before/after functional brain scans using fMRI.
%
Our procedure relies on data of a functional scan session during naturalistic
stimulation.
%
But...


\paragraph{We do not just provide binary decision}

\todo[inline]{Why is estimation of pattern better than just estimation of ROI
yes vs. no?}

%
We provide patterns that allow more than just localization but e.g.,
classification and...?


\paragraph{Partial alignment would lower scanning time}
%
A \textit{calibration scan} could be used to align a subject to a fixed \ac{cfs}
based on extensive scans and analyses of other subjects' data serving as a
reference / functional atlas.
%
Similar to the standard procedure of a anatomical scan, additional 15 minutes
functional scanning using an engaging naturalistic stimuli  could provide
sufficient data to perform a functional alignment to a functional atlas.


\subsubsection{fMRI scan session using naturalistic stimulus could substitute
multiple localizers (in case a functional atlas existed)}

%
A naturalistic stimulus like a move or audio-description could be used to map a
variety $Z$-maps created from a variety of $t$-contrast from a normative
reference group onto an individual subjects and thus potentially substitute a
variety of localizers.


%
``Compared with functional localizers, naturalistic stimuli provide several
advantages such as stronger and widespread brain activation, greater engagement,
and increased subject compliance'' \citep{jiahui2020predicting}.
%
``Movies are more engaging and result in better compliance
\citep{vanderwal2015inscapes}.
%
Movie viewing can also be used in subject populations, such as children
\citep{richardson2018development} or patients, that may have trouble maintaining
attention during repetitions of a tedious localizer task''
\citep{jiahui2020predicting}.

%
On the one hand, an engaging naturalistic stimulus before the main experiment
would have the benefit of putting a study participant at ease and letting the
subject accommodate to the scanner environment).
%
On the other hand, an engaging naturalistic stimulus after the main experiment
would not suffer less from fatigue than a one localizer or even a localizer
battery demanding voluntary attention and handling a repetitive task.


%
Naturalistic stimuli ``engage in parallel multiple neural systems for vision,
audition, language, person perception, social cognition, and other functions''
\citep{jiahui2020predicting} and offer higher generalizability [and provide
higher validity?] of transformations matrices.
%
``Consequently, movies have the potential to estimate selective topographies in
all of these domains'' \citep{jiahui2020predicting}.
% from Jiahu
``From a single movie dataset multiple functional topographies can be estimated
\citep{guntupalli2016model}, whereas different localizers are typically required
to map different functional topographies, making a thorough mapping of selective
topographies time-consuming and inefficient'' \citep{jiahui2020predicting}.


%
We need a normative reference (group) and lots of, e.g., localizers.
%
``Such a tool would require a database of data for movies and a range of
functional localizers in a normative group of subjects''
\citep{jiahui2020predicting}.
%
That reference would enable an qualitative and quantitative description of an
individual's brain function with respect to such a norm, and consequently
progress the field towards neuroimaging studies of individual differences that
more closely resemble their psychological counterparts.


%
``Findings lay the foundation for developing an efficient tool for mapping
functional topographies from a database containing a wide range of perceptual
and cognitive functions to new subjects based only on fMRI data collected while
watching an engaging, naturalistic stimulus and other subjects' localizer data
from a normative sample'' \citep{jiahui2020predicting}.

%
Once a valid alignment is established, known functional properties of the
(normative) reference can then be projected into the respective individual voxel
space (s. Fig. 1 in \citep{nishimoto2016lining}).
%
``A new subject's functional topographies could be estimated based only on that
subject's movie data and other subjects' localizer data from the normative
database that could be projected into that subject's cortical anatomy using
hyperalignment transformation matrices derived from movie data and could replace
tedious functional localizers with an engaging movie''
\citep{jiahui2020predicting}.



\subsubsection{Clinical Application}

\todo[inline]{cf. general introduction}

``To be useful for clinical diagnostics and prognostics, fMRI data must be
interpretable on the level of the individual case \citep{dubois2016building}.
%
Because in group studies idiosyncratic activity patterns can be obscured by
averaging, the precise mapping of brain function in a single person has become a
vanguard of fMRI research [\citet{laumann2015functional, huth2016natural,
gordon2017precision}]'' \citep{wegrzyn2018thought}.
%
``Functional localization has proven to be of direct practical use [Bunzl
(2010). An Exchange about Localism. In: Foundational Issues in Human Brain
Mapping, p. 4954; Szaflarski (2017). Practice guideline summary: Use of fMRI in
the presurgical evaluation of patients with epilepsy. Neurology].
%
In the clinical context, fMRI plays an important role for planning surgery in
patients with tumors or epilepsies, as it aids the understanding of which parts
of the brain need to be spared in order to preserve sensory, motor or cognitive
abilities [Stippich (2017). Introduction to Presurgical Functional MRI. In:
Clinical Functional MRI, p. 17.]'' \citep{wegrzyn2018thought}.





\subsection{Conclusion}

``We have cross-validated our pROI across participants and studies collected
with different voxel resolutions, stimuli, tasks, scanners, and analysis
methods.
%
Thus, our result is generalizable across many different methodological decisions
spanning experimental design, as well as fMRI data acquisition and analyses''
\citep{weiner2018defining}.


\section{Data Availability}

\todo[inline]{all from PPA-Paper but with new GIN link leading to an empty repo}

% \href{https://gin.g-node.org/chaeusler/studyforrest-ppa-analysis}{\url{gin.g-node.org/chaeusler/studyforrest-ppa-analysis}}

% new; PPA analysis
All fMRI data and results are available as Datalad \citep{halchenko2021datalad}
datasets, published to or linked from the \emph{G-Node GIN} repository
(\href{https://gin.g-node.org/chaeusler/studyforrest-ppa-srm}{\url{gin.g-node.org/chaeusler/studyforrest-ppa-srm}}).
% original
Raw data of the audio-description, movie and visual localizer were originally
published on the \emph{OpenfMRI} portal
(\url{https://legacy.openfmri.org/dataset/ds000113}; \citep{Hanke2014ds000113},
\space \url{https://legacy.openfmri.org/dataset/ds000113d};
\citep{hanke2016ds000113d}).
% visual localizer
Results from the localization of higher visual areas are available as Datalad
datasets at \emph{GitHub}
(\href{https://github.com/psychoinformatics-de/studyforrest-data-visualrois}{\url{github.com/psychoinformatics-de/studyforrest-data-visualrois}}).
% raw data
The realigned participant-specific time series that were used in the current
analyses were derived from the raw data releases and are available as Datalad
datasets at \emph{GitHub}
(\href{https://github.com/psychoinformatics-de/studyforrest-data-aligned}{\url{github.com/psychoinformatics-de/studyforrest-data-aligned}}).
% OpenNeuro
The same data are available in a modified and merged form on OpenNeuro at
\url{https://openneuro.org/datasets/ds000113}.
% NeuroVault for z-maps of SRM
Unthresholded $Z$-maps of all contrasts can be found at
\href{https://identifiers.org/neurovault.collection:12340}{\url{neurovault.org/collections/12340}}.


\section*{Code Availability}

Scripts to generate the results as Datalad \citep{halchenko2021datalad} datasets
are available in a \emph{G-Node GIN} repository
(\href{https://gin.g-node.org/chaeusler/studyforrest-ppa-srm}{\url{gin.g-node.org/chaeusler/studyforrest-ppa-srm}}).
