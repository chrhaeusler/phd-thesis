\todo[inline]{add stuff about "auditory PPA" (yes, I am in trouble)}

\todo[inline]{which parts are supposed to be dropped (esp. "deadlocks", i.e.
stuff that I just tried)? imo, "alternative template creation" (cf. end of
methods)}

\todo[inline]{align subject to common model space via first run of localizer;
imo, not necessary}

\todo[inline]{do not speak of ``topography'' but of "values in a ROI"??? don't
know how to phrase it; maybe papers on anatomical alignment might be helpful}

\todo[inline]{Have a figure, define such labels (e.g., "training subjects") in
that figure an refer to it. Without a clear central definition, this quickly
gets confusing}

\todo[inline]{imo, not necessary to explain; but why did we use SRM?; nicely
implemented in BrainIAK; cf. general intro on reproducibility); we do not use
the fastSRM algo, but it's probably still computationally less demanding than
hyperalignment; cf. also evaluation of algos in \citet{chen2015reduced,
bazeille2021empirical}; i.e. ``computational efficiency, as the latter is an
important consideration for scientists who may not have access to specialized
hardware''}


\section{Introduction}

% higher visual areas higher visual areas
In the domain of higher-visual perception, functionally defined,
category-selective brain regions like the \ac{ppa} \citep{epstein1998ppa}, the
\ac{ffa} \citep{kanwisher1997ffa}, or \ac{eba} \citep{downing2001bodyarea}
exhibit significantly increased \ac{bold} activity correlated with a
``preferred'' \citep{debeck2008interpreting} stimulus class.


\todo[inline]{cite paper here that do not (just) investigate PPA
\citep{frost2012measuring, rosenke2021probabilistic, wang2015probabilistic,
zhen2015quantifying}}

% example: higher functional areas
The ``topographies of these category-selective areas are mostly distributed
similarly across individuals, but great individual variability exists in the
locus, the size, and the shape of the category-selective areas
[\citep{zhen2015quantifying, zhen2017quantifying}]'' [still similar phrasing
to\citep{jiahui2020predicting}].
% localizer
In order to identify functional areas in individual persons, block-design
\textit{functional localizer} paradigms are traditionally used that contrast
regressors representing modeled hemodynamic responses to presented
stimulus classes (i.e. landscapes, faces or bodies).
% PPA as example
For example, \citep{rosenke2021probabilistic, weiner2018defining,
zhen2017quantifying} have shown that the awesome \ac{ppa}...

\todo[inline]{cite papers here that only investigate variability of PPA}

\paragraph{Problem: domain-specific and fucking boring}


% problem: one localizer for one domain
However, functional localizers are designed to maximize detection power and thus
dedicated to map just one domain of brain functions, for example,
scene-selective regions, theory of mind \citep{spunt2014validating}, or
semantic processes \citep{fernandez2001language}.
% which gets messy
Consequently, if one wants to map a variety of domains, the approach ``one
paradigm for one domain of functions'' gets time-consuming and inefficient.

\todo[inline]{maybe cut part on localizer batteries 'cause it's in the general
intro already}

% localizer batteries: intro
Researchers have tried to tackle that issue by creating time-efficient
multi-functional \textit{localizer batteries} \citep[e.g.,][]{barch2013function,
drobyshevsky2006rapid, pinel2007fast}.

% task based = shit
Nevertheless, the diagnostic quality of localizer batteries relies heavily on
a participant's comprehension of the task instructions and general compliance,
a criterion that can be difficult to meet in clinical or pediatric populations.


\paragraph{what we have done in study 1 \& 2}

\todo[inline]{phrasing (too) similar to general intro \& smooth it}
%
In study 2 \citep{haeusler2022processing}, we have shown that a functionally
defined region, such as the \ac{ppa}, can be localized using a model-driven
\ac{glm} analysis that is based on the annotated temporal structure of a
two-hour long naturalistic stimulus.
%
Results also suggest that a naturally engaging, purely auditory paradigm like an
audio-description could, in principle, substitute a visual localizer as a
diagnostic procedure to assess brain functions in visually impaired individuals
\citep{haeusler2022processing}.
%
However, a two-hour long paradigm is unsuitable for a clinical application due
to practical and monetary reasons.


\subsection{Therefore: estimate that shit}

% solution: predict from reference
An approach to reduce time and costs of individual diagnostics is to identify a
functional area in an individual person based on data collected from an
independent sample of different persons (i.e. a \textit{reference group}).

\todo[inline]{check (anatomical) estimation papers for terminology}


\subsubsection{Anatomical alignment}

\todo[inline]{cite just the best paper that did it}
%
A traditional procedure \citep{frost2012measuring, weiner2018defining,
zhen2017quantifying, zhen2015quantifying, rosenke2021probabilistic,
wang2015probabilistic} to estimate the most probable location of a functional
area in a person's anatomy from a reference group performs --- in order to
resolve anatomical variability across persons --- an \textit{anatomical
alignment}:
%
functional data from persons in the reference group are aligned to (i.e.
projected into) a \textit{common anatomical space}, and then projected from the
common anatomical space into the individual person's brain anatomy.
% volume-based
Volume-based anatomical alignment \citep[s.][for a review]{klein2009evaluation}
aligns voxel-wise data of individuals to a three-dimensional brain template
\citep[e.g., MNI152 template;][]{fonov2011unbiased}.
% surface-based
Surface-based anatomical alignment \citep{fischl1999cortical} aligns vertex-wise
data of individuals to a two-dimensional template \citep[e.g., FreeSurfer
fsaverage template;][]{fischl1999high}.


\paragraph{studies that estimated functional areas using anatomical alignment}

\todo[inline]{give 1-2 examples}

\todo[inline]{key point: check if studies did binary estimation using an
arbitrary threshold per subject to yield "nice results"}

For example, \citep{frost2012measuring, weiner2018defining,
zhen2017quantifying, zhen2015quantifying, rosenke2021probabilistic,
wang2015probabilistic} have shown that ...


\paragraph{Functional-anatomical correspondence}

\todo[inline]{cite just the most relevant}

% definition: functional-anatomical correspondence
However, location, size and shape of category-selective regions can differ
across individuals by millimeters or centimeters [\citep{zhen2017quantifying,
zhen2015quantifying}] \citep{feilong2018reliable}.
%
Current surface-based alignment strategies that respect cortical foldings
\citep{fischl1999cortical, fischl2012freesurfer, yeo2009spherical} can reduce
but not eliminate the variability in \textit{functional--anatomical
correspondence}, ``the mismatch between brain function and anatomy''
\citep{feilong2018reliable}, across persons
\citep{klein2010evaluation, frost2012measuring, duncan2009consistency,
weiner2018defining, weiner2014mid} [but see \citep{langers2014assessment}].

\todo[inline]{maybe cut sentence on better performance with low-level areas;
\citet{saxe2006divide} is considering probably procedures not state-of-the-art
anymore}
%
``These systems provide better alignment across subjects for retinotopic visual
areas [\citep{fischl1999high}], but they do not do much better than Talairach
co-ordinates for category-selective regions in the temporal lobe
[\citep{spiridon2006location}]'' \citep{saxe2006divide}.


\subsubsection{Functional alignment}

\todo[inline]{stream line phrasing}

% intro
Since anatomical alignment addresses the issue of anatomical variability but
does not resolve the issue of functional-anatomical variability across subjects,
algorithms --- like \textit{hyperalignment} \citep{haxby2011common,
guntupalli2016model} or the \textit{shared response model}
\citep{chen2015reduced, zhang2016searchlight} --- have been developed that
perform a \textit{functional alignment} to a \textit{\ac{cfs}}.
%
Functional alignment does not align voxels (or surface vertices) that share the
same anatomical location but voxels that share similar functional properties in
order to preserve functional idiosyncrasies across persons.
%
In general, functional alignment algorithms are usually used to construct both a
\ac{cfs} (serving as ``a high-dimensional, functional brain template'') as well
as subject-specific transformation matrices.
%
A subject's transformation matrix can be used to project functional data from a
subject's anatomical space into the \ac{cfs}, or to project data from the
\ac{cfs} into a subject's anatomical space \citep{haxby2020hyperalignment}.
%
The construction of the \ac{cfs} and transformation matrix can be created (i.e.
\textit{trained}) based on the maximization of the inter-subject similarity of
\ac{bold} response time series correlating with a time-locked external
stimulation \citep{haxby2011common, chen2015reduced, sabuncu2010function}, or
based on the inter-subject similarity of connectivity profiles
\citep{feilong2018reliable, guntupalli2018computational, nastase2019leveraging}.
%
Functional alignment algorithms can be applied to \ac{fmri} data from paradigms
employing simplified stimuli.
%
However, it has been shown that data from naturalistic stimuli provide increased
validity of the \ac{cfs} and increased generalizability of transformation
matrices to novel stimuli or tasks, presumably because naturalistic stimuli
sample a broader range of brain states \citep{haxby2011common,
guntupalli2016model}.


\subsubsection{Estimation via functional alignment}

%
Hence, a more recent procedure to estimate the most probable location of a
functional area in a person's anatomy from a reference group performs --- in
order to resolve functional-anatomical variability across persons --- an
functional alignment:
%
functional data from persons in the reference group are aligned to (i.e.
projected into) a \ac{cfs}, and then projected from the \ac{cfs} into the
individual person's brain anatomy.


\paragraph{studies that estimated functional areas using functional alignment}

% intro
Previous studies \citep{jiahui2020predicting, guntupalli2016model,
haxby2011common} that employed hyperalignment have shown that a subject's
idiosyncratic retinotopy of occipital areas and functional topography of
category-selective areas in the ventral temporal cortex can be estimated by
projecting data of a reference group through a \ac{cfs} into that subject's
cortical anatomy.
% used stimuli and length
For example, \citep{jiahui2020predicting} constructed a \ac{cfs} and
transformation matrices based on data from a) the movie ``Grand Budapest Hotel''
($\sim$\unit[50]{m}; \ac{tr}=\unit[1]{s}), and b) ``Forrest Gump''
($\sim$\unit[120]{m}; \ac{tr}=\unit[2]{s}).
% summary of results
Results revealed that the empirical results of a statistical contrasts aimed to
localize the \ac{ffa} correlate more highly with maps that were estimated from
other subjects' data based on hyperalignment than with maps that were estimated
based on surface-based, anatomical alignment \citep{jiahui2020predicting}.


\subsection{Here, we... (includes SRM now)}


\paragraph{Intro}

% summary in one sentence
Here, we focus on the \ac{ppa} as an example of a functional area, and estimate
results (statistical $Z$-maps) of a visual localizer's $t$-contrast in one
subject (i.e. the \textit{test subject}) based on data from other subjects (i.e.
the \textit{training subjects}).
%
Results of our previous study \citep{haeusler2022processing} suggest that not
just the dedicated visual localizer \citep{sengupta2016extension} but also the
audio-visual movie Forrest Gump \citep{hanke2016simultaneous} and the movie's
audio-description \citep{hanke2014audiomovie} sample the response vector space
of hemodynamic responses to ``spatial information'' in a time-locked manner
across subjects.
%
Hence, following a k-fold leave-one-subject-out cross-validation [correct? give
citation?] we employed both a procedure using a volume-based, anatomical
alignment as well as a procedure using a volume-based, functional alignment in
order to predict $z$-values within a \ac{roi}.

\paragraph{SRM}

%
In case of the functional alignment procedure, we first applied the \ac{srm}
algorithm \citep{chen2015reduced, richard2019fast} to the training subjects'
\ac{bold} \ac{fmri} time series of the visual localizer and naturalistic
stimulus paradigms in order to derive a \ac{cfs} and subject-specific
transformation matrices.
%
The \ac{srm} is an unsupervised probabilistic latent-factor model that
decomposes \ac{bold} \ac{fmri} responses time series of participants
experiencing the same stimulus into a lower-dimensional space of shared features
(i.e. the \ac{cfs}) and subject-specific orthogonal topographic transformation
matrices \citep{kumar2020brainiak, cohen2017computational}.
%
The dimensions of the shared feature space do not correspond to individual
voxels but \textit{shared features} that can be understood as a weighted sum of
many voxels distributed across the full voxel space of each subject
\citep{kumar2020brainiak}.
%
In contrast to hyperalignment, the number of dimensions of the shared feature
space is not set by the number of voxels (or surface vertices) but is
pre-specified by the researcher, a procedure that also filters out noise and
reduces overfitting \citep{chen2015reduced}.

\todo[inline]{rephrase to better match our case}
% project into CFS
Second, we used the subject-specific transformation matrices in order to perform
a mapping of the visual localizer's results (i.e. the training subjects'
\textit{empirical $Z$-maps}) from each training subject's voxel space into the
\ac{cfs} (i.e. shared feature space).
% align test subject
Third, we use time series data from the naturalistic stimuli to align the test
subject to the \ac{cfs} (that was derived from the training subjects' data) in
order to acquire the test subject's transformation matrix.
% project from CFS into test subject
Last, the transpose of the test subject's transformation matrix is used to
project the training subjects' functional localizer results from the \ac{cfs}
into the test subject's voxel space serving as an estimation (hence, a
\textit{predicted $Z$-map}) of the test subject's localizer results (i.e. the
test subject's empirical $Z$-map).


\paragraph{partial alignment}

Given that a two-hour long stimulation is unsuitable for a clinical setting, we
critically also assess the relationship between the length of the naturalistic
stimulus used for alignment of the test subject to the fixed \ac{cfs} and the
subsequent estimation performance.
%
Therefore, we use an increasing number of segments of the naturalistic stimuli
(each lasting $\sim$\unit[15]{m}) to align the test subject to the corresponding
segments' time points within the \ac{cfs}.


\subsection{Hypotheses}

\todo[inline]{draft; s. also general introduction}
%
We hypothesized that an increased quantity of data used to calculate the
transformation matrices of the test subjects would lead to an increasing
prediction performance.
%
Further, we hypothesized that functional alignment procedure would eventually
outperform an estimation based on anatomical alignment.


\subsection{Summary of results}

\todo[inline]{mih: Seems like a strange position for such a section. If
anywhere, prior Hypotheses. No?}

\todo[inline]{coh: usually, papers provide a overview of
methods, results, and often also a conclusion in the intro (as Jiahu et al. did,
too; s. below)}

%
Template from \citet{jiahui2020predicting}: ``Results show strong correlations
of face-selectivity topographic maps derived from a subject's own localizer data
with maps derived from other subjects' localizer data projected into that
subject's cortical anatomy. Both the two-step algorithm and the new one-step
algorithm, which we introduce here, produce high-fidelity, individualized
topographic maps, but the new one-step algorithm maps were superior''
\citep{jiahui2020predicting}.


\paragraph{model validation; within experiment estimation}

\todo[inline]{imo, it's too much to mention to here}
\todo[inline]{in general: it's interesting but not super necessary to test}
\todo[inline]{is it supposed to be mentioned in method, results, discussion?}
\todo[inline]{if, then adjust scripts for computation and plotting!}

%
``Between-subject models with SRM can, in some cases, exceed the performance of
within-subject models because (a) the reduced-dimension shared space can
highlight stimulus-related variance by filtering out noisy or
non-stimulus-related features, and (b) the between-subject model can effectively
leverage a larger volume of data after functional alignment than is available
for any single subject'' \citep{kumar2020brainiak}.
%
Hence, we also test alignment based on the first run (\unit[312]{s};
\unit[5.2]{m}) of data from
the visual localizer to acquire the transformation matrices and perform a
cross-subject-prediction (vs. cross-subject-cross-experiment-prediction)


\subsection{Vision}

\todo[inline]{cf. general introduction}

\todo[inline]{smallish text should be enough here}

Our results suggest that it is possible to ``scan once, estimate many''...

%
Template from \citet{jiahui2020predicting}'s introduction: ``Movies engage
multiple brain systems in parallel. From a single movie dataset multiple
functional topographies can be estimated \citep{guntupalli2016model}, whereas
different localizers are typically required to map different functional
topographies, making a thorough mapping of selective topographies time-consuming
and inefficient. Movies also simulate better the statistics of natural viewing
and listening and may provide more ecologically valid maps. [...] Naturalistic
stimuli may better sample the full range of responses to faces and other stimuli
that contribute to face-selective topographies'' \citep{jiahui2020predicting}.
%
``These results lay a foundation for building a computational tool with a
database that could allow others to map multiple functional topographies in new
subjects using only data collected during movie viewing. Functional localizers
are inefficient because they only estimate one or a few topographies for each
localizer. Movies, by contrast, engage in parallel multiple neural systems for
vision, audition, language, person perception, social cognition, and other
functions. Consequently, movies have the potential to estimate selective
topographies in all of these domains. Such a tool would require a database of
data for movies and a range of functional localizers in a normative group of
subjects. A new subject's functional topographies could be estimated based only
on that subject's movie data and other subjects' localizer data from the
normative database that could be projected into that subject's cortical anatomy
using hyperalignment transformation matrices derived from movie data. Such a
resource would be more efficient and replace tedious functional localizers with
an engaging movie and could enable mapping of multiple functional topographies
with data from a single fMRI using a naturalistic stimulus''
\citet{jiahui2020predicting}.


\section{Methods}

\todo[inline]{it's pretty rigorously shortened now; I hope it's okay and
nothing that should urgently be mentioned is missing}

% we get the data from the naturalistic PPA paper (its subdataset)
% datalad get -n inputs/studyforrest-ppa-analysis/inputs/studyforrest-data-aligned
% datalad get inputs/studyforrest-ppa-analysis/inputs/studyforrest-data-aligned/sub-??/in\_bold3Tp2/sub-??\_task-a?movie\_run-?\_bold*.*

% reference to PPA-Paper
For the current study, we used the same subset of the studyforrest dataset
(\href{http://www.studyforrest.org}{\url{studyforrest.org}}) that was used in
study 2 \citep{haeusler2022processing}:
%
the same fourteen subjects were
% VIS
a) participating in a dedicated six-category block-design visual localizer
\citep{sengupta2016extension},
% AV
b) watching the audio-visual movie ``Forrest Gump''
\citep{hanke2016simultaneous}, and
% AD
c) listening to the movie's audio-description \citep{hanke2014audiomovie}.
% see corresponding papers for details
An exhaustive description of participants, stimulus creation, procedure,
stimulation setup, and fMRI acquisition can be found in the corresponding
publications, whereas a summary is provided in \citet{haeusler2022processing}.


\subsection{Preprocessing}

% data sources
The current analyses were carried out on the same preprocessed fMRI data (s.
\href{https://github.com/psychoinformatics-de/studyforrest-data-aligned
}{\url{github.com/psychoinformatics-de/studyforrest-data-aligned}}) that were
used for
%
a) the technical validation of the dataset \citep{hanke2016simultaneous},
%
b) the localization of higher-visual areas \citep{sengupta2016extension}, and
%
c) the investigation of responses of the \ac{ppa} correlating with naturalistic
spatial information in study 2 \citep{haeusler2022processing}.

%
We reran the preprocessing and analyses steps performed in
\citet{sengupta2016extension} and \citet{haeusler2022processing} using FEAT
v6.00 \citep[FMRI Expert Analysis Tool;][]{woolrich2001autocorr} as shipped with
FSL v5.0.9 \citep[\href{https://www.fmrib.ox.ac.uk/fsl}{FMRIB's Software
Library;}][]{smith2004fsl} in order to reproduce both the time series data that
served as final input for the statistical analyses in the two previous studies
as well as their results (i.e. statistical $Z$-maps).
% temporal filtering
In summary, high-pass temporal filtering was applied using a Gaussian-weighted
least-squares straight line to every run of the visual localizer (cutoff period
of \unit[100]{s}; sigma= \unit[100]{s}/2)[???], and every segment of the movie
and audio-description (\unit[150]{s}; sigma=\unit[75.0]{s}).
% brain extraction
Brains were extracted from surrounding tissues using BET \citep{smith2002bet}.
% spatial smoothing
As in the previous studies, data from all three paradigms were spatially
smoothed (Gaussian kernel with full width at half maximum of \unit[4.0]{mm}).
A grand-mean intensity normalization was applied to each run of the functional
localizer and each segment of the naturalistic stimuli.

\todo[inline]{can't remember: is grand mean per run/across runs?; imo per run}


\subsection{Modeling of a shared feature space}

On these reproduced time series data, we then performed further analyses steps
via Python scripts that relied on
%
NiBabel v3.2.1 (\href{https://nipy.org}{\url{nipy.org}}),
%
NumPy v1.20.2 (\href{https://numpy.org}{\url{numpy.org}}),
%
Pandas v1.2.3 (\href{https://pandas.pydata.org}{\url{pandas.pydata.org}}),
%
Scipy v1.6.2 (\href{https://scipy.org}{\url{scipy.org}}),
%
scikit-learn v1.0 (\href{https://scikit-learn.org}{\url{scikit-learn.org}}),
%
BrainIAK v0.11 (\href{https://brainiak.org}{\url{brainiak.org}}),
%
Matplotlib v3.4.0 (\href{https://matplotlib.org}{\url{matplotlib.org}}),
%
seaborn v0.11.2 (\href{https://seaborn.pydata.org}{\url{seaborn.pydata.org}}),
%
and calling command line functions of FSL.

%\paragraph{Fixing FSL output}

% grand_mean_for_4d.py (formerly: data_normalize_4d.py):
% is not necessary anymore: FSL has applied grand mean scaling to
% 'filtered_func_data.nii.gz'

% input: 'sub-*/run-?.feat/filtered_func_data.nii.gz' (of VIS, AO & AV)
% output: saved to 'sub-??_task-*_run-?_bold_filtered.nii.gz'

% FSL adds back the mean value for each voxel's time course at the end of the
% preprocessing;
% hence, the script substracts that mean again but multiplies it by 10000
% (like FSL does it, too)

% definition of grand mean scaling for 4d data:
% voxel values in every image are divided by the average global mean
% intensity of the whole session. This effectively removes any mean global
% differences in intensity between sessions.

% FSL User Guide:
% filtered_func_data will normally have been temporally high-pass filtered,
% it is not zero mean; the mean value for each voxel's time course has been
% added back in for various practical reasons.
% When FILM begins the linear modeling, it starts by removing this mean.


\paragraph{Getting the data in shape}

% masks-from-mni-to-bold3Tp2.py:
% - merges unilateral ROIs overlaps (already in MNI) to bilateral ROI
% - output: 'masks/in_mni/PPA_overlap_prob.nii.gz'
% - warps union of ROIs from MNI into each subjects space
% output: 'sub-*/masks/in_bold3Tp2/grp_PPA_bin.nii.gz' + audio_fov.nii.gz dilate
% the ROI masks by 1 voxel; output: 'grp_PPA_bin_dil.nii.gz'

% masks-from-mni-to-bold3Tp2.py:
% warp MNI masks into individual bold3Tp2 spaces

% masks-from-t1w-to-bold3Tp2.py:
% transforms 'inputs/tnt/sub-*/t1w/brain_seg*.nii.gz'
% into individual's bold3Tp2
% output: 'sub-*/masks/in_bold3Tp2/brain_seg*.nii.gz'

% mask-builder-voxel-counter.py:
% builds different individual masks by dilating, merging other masks
% creates a FoV of AO stimulus for every subject from 4d time-series of AO run
% output: sub-*/masks/in_bold3Tp2/audio_fov.nii.gz'
% counts the voxels
% long story short: we cannot used all gyri that contain PPA to some degree
% even if the mask by FoV of AO stimulus and individual gray matter mask

% data_mask_concat_runs.py:
% masks are not dilated and not masked with subject-specific gray matter mask
% outputs:
% 'sub-*_task_aomovie-avmovie_run-1-8_bold-filtered.npy
% 'sub-*_task_visloc_run-1-4_bold-filtered.npy'

\todo[inline]{problem 1: grpPPA contains N=14 subject, not N-1 subjects}

\todo[inline]{problem 2: there are voxels outside of PPA-mask; probably, because
of the warping procedures}

\todo[inline]{how to explain in one sentence that we need reduction of voxels?}

% reason why we do it
The \ac{srm} requires that the number of samples (the number of \acp{tr}) exceed
the number of features (the number of voxels) in order to train a reliable
model.
% union of PPA masks
Hence, we warped the union of individual \acp{ppa}
\citep[s.][]{haeusler2022processing} [via non-linear transformation x degrees of
freedom] from MNI space into each subjects' voxel space, and applied it as a
mask to each subjects' time series data.
% AO FoV
Then, data were further masked with the subject-specific \ac{fov} of the
audio-description.
%
The number of remaining voxels for each subject can be seen in Table
\ref{tab:ppamaskvoxels}.

\todo[inline]{show table or just report range, mean \& SD?}

% normalization
Data of every run were independently normalized ($z$-scored) to a mean of zero
and a standard deviation of one ($\mu=0$, $\sigma=1$).
%
The last 75 \acp{tr} of the audio-description were missing in subject-04 due to
an image reconstruction problem \citep[s.][]{hanke2014audiomovie}.
%
The \ac{srm} allows the number of voxels to be different across subjects but the
number of samples must be the same.
%
Hence, we removed the last 75 \acp{tr} of the audio-description from the other
subjects' time series.
% summary; AO + AV = 7123 TRs (not 7198 TRs anymore); localizer has 4 x 156 TRs
As a result, the data to fit the \ac{srm} in the following step comprised 3599
\acp{tr} of the movie, 3524 \acp{tr} of the audio-description, and 624 \acp{tr}
of the visual localizer experiment.

\todo[inline]{yeah, well, probably I should have cut the last 75TRs of AO first,
and then z-scored the last segment but anyway...; does not make much difference}

\begin{table*}[btp]
    \caption{Number of remaining voxels after time series data of each paradigm
    and subject were masked with the union of individual \acp{ppa} that was
    warped from MNI space into each individual's subjects-space and the
    subject-specific field of view of audio-description.}

\label{tab:ppamaskvoxels}
\begin{tabular}{ll}
\toprule
\textbf{Subject} & \textbf{no. of voxels} \\
\midrule
sub-01 & 1665 \tabularnewline
sub-02 & 1732 \tabularnewline
sub-03 & 1400 \tabularnewline
sub-04 & 1575 \tabularnewline
sub-05 & 1664 \tabularnewline
sub-06 & 1951 \tabularnewline
sub-14 & 1376 \tabularnewline
sub-09 & 1383 \tabularnewline
sub-15 & 1683 \tabularnewline
sub-16 & 1887 \tabularnewline
sub-17 & 1441 \tabularnewline
sub-18 & 1729 \tabularnewline
sub-19 & 1369 \tabularnewline
sub-20 & 1437 \tabularnewline
\bottomrule
\end{tabular}
\end{table*}


\paragraph{Fitting of shared response model: intro}

\todo[inline]{mention that just 'ao \& av' as input were also tested?}

We used the probabilistic \ac{srm} algorithm that approximates the \ac{srm}
based the Expectation Maximization (EM) algorithm proposed by
\citep{chen2015reduced}, optimized by \citet{anderson2016enabling}, and
implemented in BrainIAK v.11 \citep[Brain Imaging Analysis
Kit;][]{kumar2020brainiak, kumar2020brainiaktutorial} in order to compute the
\ac{cfs} and the transformation matrices for the training subjects.


\paragraph{Cross-validation stuff}

\todo[inline]{streamline with overview in introduction}

%
In order to avoid data leakage, we followed a leave-one-subject-out folding
scheme:
%
for every subject $n$, we used the other subjects' ($N-1$) \ac{bold} \ac{fmri}
responses to the functional localizer, movie, and audio-description as training
set to compute the shared feature space and transformation matrices for $N-1$
subjects.
% concatenate and z-score
The time series of all three paradigms were concatenated and z-scored.

\todo[inline]{yes, I performed a second z-scoring but across all runs/paradigms}


\paragraph{number of dimensions}

% iterations:
% The number of iterations for the algorithm to minimize the error was set to 30

% features
We chose a value of $k=10$ for the number of features (i.e. the shared
responses) to be computed considering the temporal and spatial resolution of our
data (\ac{tr} = \unit[2]{s}; \unit[2.5 $\times$ 2.5 $\times$ 2.5]{mm}), the
average number of voxels per \ac{roi}, and findings from \citet{haxby2011common}
%
\citet{haxby2011common} first used hyperalignment to create a \ac{cfs} on 1,000 dimensions based of functional data (\ac{tr} = \unit[3]{s}) of
voxels (\unit[3 $\times$ 3 $\times$ 3]{mm}) located in the ventral temporal
cortex.
%
Then, \citet{haxby2011common} reduced the dimensionality of the common space by
applying a \ac{pca} in order to determine the subspace that is sufficient to
capture the full range of response-pattern distinctions.
%
Results revealed that approximately 35 principal components (i.e. dimensions)
were sufficient to represent the information content of the one-hour movie from
which the \ac{cfs} was derived.
%
Results also showed that the cortical topographies of category-selective brain
regions was preserved in the 35-dimensional common space
\citep{haxby2011common}.
%
In the current study, we also explored \acp{cfs} of $k=5, 20, 30,
40, 50$, but the results barely varied from a 10-dimensional common space.

% ``The effect of number of PCs on BSC was similar for models that were based
% only on Princeton (n = 10) or Dartmouth (n = 11) data, suggesting that this
% estimate of dimensionality is robust across differences in scanning hardware
% and scanning parameters'' \citep{haxby2011common}.
%
% ``These dimensionality estimates are a function of the spatial and temporal
% resolution of fMRI and the number and variety of response vectors used to
% derive the common space'' \citep{guntupalli2016model}.
%
% ``The true dimensionality of representation in human cortex surely involves
% vastly more distinct tuning functions. Estimates of the dimensionality of
% cortical representation, therefore, will almost certainly be much higher as
% data with higher spatial and temporal resolution for larger and more varied
% samples of response vectors are used to build new common models''
% \citep{guntupalli2016model}.


\paragraph{the math shit}

%
During model fitting, the algorithm computes the shared feature space $S$ ($k$
features by $t$ time points) and calculates subject-specific, orthogonal
transformation matrices $W_{n}$ ($v$ voxel by $k$ features).
%
These transformation matrices (or weight matrices) reflect the loadings of
voxels onto features (i.e. subject-specific functional topographies), and allow
to project responses of voxels within each subjects' \ac{roi}(s) from anatomical
space into the $k$-dimensional shared feature space, and thus functionally align
subjects.


\paragraph{the other math shit (previously in intro)}
%
More specifically, ``the brain data for each participant $i$ are represented as
an \textbf{$n$} voxel by $t$ time matrix  $X_{i}$. A pre-specified number of
features are used to learn a $k$ feature by  $t$ time shared space $S$ and a
participant-specific $n$ voxel by $k$  feature matrix $W_{i}$. This weight
matrix, reflecting the loading of voxels onto features, is randomly initialized
then fit over iterations to minimize the error in explaining participant data.
At the same time, the time course of the features in the shared space is
learned'' (s.
\href{https://brainiak.org/tutorials/11-SRM/}{brainiak.org/tutorials/11-SRM}).

%
``SRM learns $N$ maps $W_{i}$ with orthogonal columns such that
$||X_{i}-W_{i}S||_{F}$ is minimized over $\left\{ W_{i}\right\} _{i=1}^{N},S$,
where $X_{i}\in\mathbb{R}^{v\times{T}}$ is the $i^{th}$ subject's fMRI response
($v$ voxels by $T$ repetition times) and $S\in\mathbb{R}^{k\times{T}}$ is a
feature time-series in a $k$-dimensional shared space''
\citep{vodrahalli2018mapping}.


\paragraph{negative control}

\todo[inline]{report it? if, then correct script; plot it (all 0's?!), too?}

\todo[inline]{I need to check the code; probably, wrong indices are still used}

% shuffled data
As negative control, we shuffled the order of runs of audio-description and
movie [but not yet of visual localizer!] before fitting a shared response model
to the time series [in order to assess the correlation between regressors of the
experiments and the computed shared responses in the corresponding \acp{tr}]


\subsection{Alignment of left-out subjects}

% AO: 0-451, 0-892, 0-1330, 0-1818, 0-2280, 0-2719, 0-3261, 0-3524
% AV: 3524-3975, 3524-4416, 3524-4854, 3524-5342, 3524-5804, 3524-6243,
%     3524-6785, 3524-7123
% AO+AV: 0-7123

\todo[inline]{how is it done? srm.transform\_subject calls np.linalg.svd()}

\todo[inline]{in-code documentation says: ``Solve the Procrustes problem''}

\todo[inline]{also perform alignment with TRs of first run of localizer for mere
cross-subject-prediction? -> kind of model validation, ceiling ...}

\todo[inline]{is text graspable? It makes sense in my head}

%
To obtain the transformation matrix for the test subject, we then aligned
test subject's data to the \ac{cfs} that was trained on the
other subjects' data:
%
the algorithm learns a mapping $W_{n}$ of the left-out subject's anatomical
voxel space into the shared space $S$ that is kept fixed.
%
In order evaluate the relationship between the length of the naturalistic
stimulus used to align the test subject to the \ac{cfs} and the
subsequent functional alignment's prediction/estimation performance, we based
the computation of the transformation matrix on different quantity of data:
%
For each naturalistic stimulus, we used 1 up to 8 (all) segments to let the
algorithm learn an orthogonal mapping to the corresponding \acs{tr} of the
shared space:
%
each matrix has a size of $v$ voxels by $k$ features but is based on a different
quantity of data used to calculate the mapping (i.e. subject-specific functional
topographies).
%
As a result, we obtained 8 different transformation matrices per subject and per
naturalistic stimulus.


\subsection{Estimation of scene-selective topography}


\todo[inline]{functional \& anatomical alignment procedure: mean was computed
after warping into subject-specific anatomical space}

\todo[inline]{I also tested averaging data in common space: similar results}

\todo[inline]{what I did not do in case of anatomical alignment: averaging data
in MNI152 space}

\subsubsection{short overview}
%
We then estimated each test subject's (masked) statistical $Z$-map / values in
\acp{roi} [???] by projecting all other participants' $Z$-maps from their voxel
space trough the template (i.e. the shared space in case of functional
alignment; the MNI space in case of anatomical alignment) into the test
subject's voxel space.

%
First, we masked the \ac{glm} univariate contrast maps that we acquired by
rerunning the analysis performed by \citet{hanke2016simultaneous}:
%
as applied to the time series data, $Z$-maps were masked with the union of the
individual \acp{ppa} \citep[s.][]{haeusler2022processing} that was warped from
group space into each subjects' space, and the subject-specific \ac{fov} of the
audio-description.

\subsubsection{Prediction/estimation using functional alignment}

% into shared space: calling srm.transform(masked\_zmaps))
In the case of estimation via functional alignment, we used the transformation
matrices that were derived during training of the \ac{srm} in order to project
the data from each training subject into the shared space.
% into shared space
We then used the transpose of the transformation matrix that we acquired during
the alignment of the test subject in order to project the data from the shared
space into the test subject's voxel space.
% into subject
The average of these 13 projected $Z$-maps served as the \textit{predicted
$Z$-map} estimating the test subject's \textit{empirical $Z$-map}.


\subsubsection{Prediction using anatomical alignment}

\todo[inline]{tell more about how transformation matrices were created?
Potential reviewer's question: your anatomical alignment might have been shitty,
linear etc. ? -> check TNT github/gin repo; what is the corresponding paper?}

\todo[inline]{``warp'' = non-linear registration with [?] degrees of freedom}

\todo[inline]{check scripts again!}

\todo[inline]{were data masked before or after projection?}

\todo[inline]{shorten and just state what was different to functional alignment}

% into MNI space
In case of estimation via anatomical alignment, we used transformation matrices
provided by the studyforrest project [LINK here] in order to project the data
from each training subject into the MNI space.
%
We then used the transpose of the transformation matrix [did I? or was it
another matrix?] in order to project the data from MNI space into the test
subject's voxel space.
%
The average of these 13 projected $Z$-maps served as an \textit{predicted
$Z$-map} estimating the test subject's \textit{empirical $Z$-map}


\subsection{Quantifying the performance (Pearson + Cronbach's)}

%
In order to quantify the performance of our two different estimation procedures
we calculated the Pearson's correlation coefficients as a measure of similarity
between the empirical $Z$-maps gained from the localizer experiment and the
estimated $Z$-maps.
%
Further, we compare the prediction performance to the internal consistency (i.e.
reliability) of the visual localizer by calculating Cronbach's Alpha across the
four runs of the localizer.

\todo[inline]{s. 'studyforrest-srm-movies/test/statistics\_cronbachs.py'}

\todo[inline]{was the last script that I have written; need to take a look}


\subsection{backup: alternative template creation}

\todo[inline]{is this supposed to be reported? imo, it should be dropped!}

\todo[inline]{I need to take a look in the scripts (in the draft directory); I
do not understand the scripts anymore (on a Sunday evening)}

\todo[inline]{s. 'test/data\_denoise-vis.py' \& 'test/data\_srm-vis-to-ind.py'}

\todo[inline]{I think I projected all subjects' localizer time series through
model space into the test subject voxel space; then, calculated the contrast
with these data}

\todo[inline]{in general, the problem was: it gets totally messy \&
computational intensive if one wants to test the different transformation
matrices (I only did it with one; imo, based on alignment using the whole
audio-description?}

\todo[inline]{results: performance was the same if not slightly worse}


\section{Results}

Unthresholded $Z$-maps [in each subject's voxel space] can be found at
\href{https://identifiers.org/neurovault.collection:12340}{\url{neurovault.org/collections/12340}}.


\subsection{Model-related}

\subsubsection{plot\_srm.py}

\todo[inline]{imo, plots are not very informative}

\todo[inline]{time series plot of features [first 800 TRs of SRM]}

\todo[inline]{distance matrix of time-points in shared space}


\subsubsection{plot\_corr-of-glm-and-srm.py}

\todo[inline]{plots correlation matrix between regressors (=model) in the
experiments and the shared responses that were calculated from the TRs of
corresponding experiment}

\todo[inline]{possible plots:
correlate AO regressors (PPA-paper) with AO TRs;
correlate AV regressors (PPA-paper) with AV TRs;
correlate VIS regressors with VIS TRs;
add combi of regressors that were used on the positive side of contrasts}

\todo[inline]{if we shuffle of every subject before training the model on it, we
get correlations of 0 between regressors and (non-existing) ``shared''
responses}


\begin{figure*}[tbp]
\centering
    \includegraphics[width=\linewidth]{figures/corr_ao-regressors-vs-shared-resp}
    \caption{Pearson correlation coefficients of regressors used in the analysis
    of audio-description to model responses correlating with nouns spoken by the
    narrator and features of the \ac{srm} (i.e. shared responses).
    \texttt{geo\&groom} \texttt{geo\&groom\&furn} are combination of regressors
    (as used on the positive side of contrasts). The
    time series of the \ac{srm} were sliced to match the TRs of the
    audio-description.
      }
\label{fig:reg-corr}
\end{figure*}


\subsection{Prediction-related}

\subsubsection{Template(s) from from \citet{jiahui2020predicting}}

1-step hyperalignment: ``We correlated the whole-cortex contrast map
(faces-vs-all) based on a participant's own data with the maps estimated from
other participants' data.  After 1-step hyperalignment, the mean Pearson
correlation values across participants were 0.58 (N = 15, S.D. = 0.08)''
\citep{jiahui2020predicting}.
%
``Hyperalignment greatly improved the prediction performance compared with
anatomical surface alignment. With surface alignment, the average Pearson
correlation values across participants were 0.40 (N = 15, S.D. = 0.08) in the
studyforrest dataset (Fig. 3). The difference between the hyperaligned and the
surface-aligned mean correlation values was highly significant (studyforrest:
t(14) = 17.39, p < 0.001)'' \citep{jiahui2020predicting}.

%
classic hyperalignment: ``We found similar but slightly weaker results. The mean
Pearson correlation values between face-selectivity maps based on a
participant's own localizer data and the predicted map after hyperalignment were
0.55 (N = 15, S.D. = 0.08). These correlations after hyperalignment were
significantly better than the correlations after surface alignment (t(14) =
15.78, p < 0.001)'' \citep{jiahui2020predicting}.


\subsubsection{My prediction results}

\todo[inline]{Similar text to \citep{jiahui2020predicting} here}

\todo[inline]{predict\_ppa.py also outputs the Pearson correlations!}


\subsubsection{statistics\_t-test-correlations.py}

Tests whether differences between prediction using anatomy and prediction using
\ac{srm} is significant;
%
We test correlations that are Fisher-transformed (which Jiahu did not)


\subsubsection{Cronbach's Alpha of localizer}

\todo[inline]{s. 'studyforrest-srm-movies/test/statistics\_cronbachs.py'}

\todo[inline]{is Fig 2 in \citet{jiahui2020predicting} any good?}

Template from \citet{jiahui2020predicting}: ``We compared the correlations
between maps estimated from a participant's own data and maps estimated from
other participants' data to the reliability of the localizer. We computed the
reliability of the contrast maps with Cronbach's Alpha based on variability
across the four localizer runs for each set. The mean Cronbach's Alpha between
the four localizer runs was 0.60 (N = 15, S.D. = 0.14)''.
%
``These results mean that if we scan each participant for another 4 localizer
runs, and compute the correlation between the two maps (4 runs vs. 4 runs), the
correlation would be 0.60 on average in the studyforrest''.
%
``Cronbach's alpha indicates that the predicted contrast map based on
hyperalignment is close to or as good as the real contrast map based on four
localizer runs (studyforrest: t(14) = 0.61, p = 0.55; Grand Budapest: t(20) =
3.02, p = 0.007)''.
%
``The predicted contrast map based on hyperalignment was better than the
contrast map based on data from three out of four localizer runs in other
participants (t(14) = 2.36, p = 0.03) and in Grand Budapest, the predicted
contrast map was comparable to the contrast map based on three localizer runs in
other participants (t(20) = 0.48, p = 0.63)''.\todo{what?}
%
``A scatterplot of the individual correlation values with hyperalignment and
with surface alignment (Fig 3), shows that predicted maps based on
hyperalignment were more accurate than those based on surface alignment in every
participant''.


\subsubsection{Auditory PPA stuff}

\todo[inline]{Is not considered in any text at all yet}


\subsubsection{Estimation of localizer from localizer TRs}

\todo[inline]{Is not considered in any text (AND SCRIPTS) yet}

\todo[inline]{is mere "cross-subject" prediction}


\subsection{Plots}

\subsubsection{plot\_stripplot.py}

%
Pearson correlation coefficients between empirical $Z$-maps (results of
localizer; y-axis) and estimated $Z$-maps.
%
Green dots: A left-out subject's $Z$-map was estimated by projecting all other
subjects ($N = 13$) $Z$-maps through the MNI152 space into the left-out subject
space and averaging values across subject; correlations between empirical values
from the localizer \& the predicted values using anatomical alignment

%
Blue dots: transformation matrices computed based on an increasing number of
segments of the audio-description; correlations between empirical values \& the
predicted values using parts of the audio-description

%
Orange dots: transformation matrices computed based on an increasing number of
segments of the movie; correlations between empirical values \& the predicted
values using parts of the movie


\subsubsection{Plots of brain slices?}

\todo[inline]{talk during seminar showed (quick screenshot in FSL) from sub-04
as an example}

\todo[inline]{I guess, I could adjust script that plots the brain slices for the
PPA-paper (without losing my mind?); but script expects standard brain in MNI
space; transformation of prediction into MNI (again?); and it is just about the
ROI not about the whole brain; standard space could be substituted with (nice
blurry) subject-specific functional template}

%% sub-04: z-maps are threshold at a value of bigger than 2.3
% red: z-map from the localizer experiment across the whole brain,
% white: the region of interest
% blue: predicted values
% anatomical alignment & prediction using 15 minutes of movie data, corr ~.7
% prediction using 15 minutes of the audio-description correlates ~0


\subsubsection{plot\_bland-altman.py}

\todo[inline]{I hate that script}

% corrstats.py; not necessary anymore; calculates the statistical significant
% differences between two dependent or independent correlation coefficients


\section{Discussion}


\subsection{Short Summary}

\subsubsection{Aim}

\subsubsection{Methods}

\subsubsection{Results}


\subsection{Discussion of current results}

\todo[inline]{key point: check if (anatomical alignment) studies did binary
estimation using an arbitrary threshold per subject to yield "nice results"}

We have cross-subject, cross-experiment, and cross-scanner prediction; but:
AV \& VIS are from the same scanner, if not same session?

\subsubsection{Model Space}
%
Results indicate that we are able to use multiple subjects to learn a
10-dimensional shared space for the fMRI data that increases performance on our
experiments.

%
Asymptotic ``performance curve'' might be different for another brain region
(temporal receptive fields?); retinotopic mapping vs. ``higher'' cognition  vs.
executive functions (prefrontal cortex)?


\subsubsection{Partial Alignment}
%
15 min of movie watching used for functional alignment outperform prediction
using anatomical alignment;
%
30 minutes of movie watching outperform 15 minutes of movie watching;
%
more than 30 minutes do not lead to a significantly improved prediction
performance.


\paragraph{what partial alignment might be good for}
%
Reduced costs.
%
There is a benefit of shared parts of naturalistic stimuli across datasets;
shared stimulus part is easier than shared subjects (e.g.
\citep{zhang2018transfer}).


\subsubsection{Audio PPA}

%
Response in PPA during AO might be different (cf. study in chapter 4).
%
Why do some people do not have a AO PPA? Do simply do not give a shit
about spatial information in AO due to missing task?
%
check: is it different in these persons in AV?


\subsubsection{Inter-individual differences}

%
Problem: we have a couple of subjects seem to simply do not give a fuck about
spatial information in audio-description.

\citet{eickhoff2018imaging} on inter-individual variability: ``An important
consideration for building a general representation of brain organization
pertains to inter-subject variability, which is encountered at all spatial
levels and in all neurobiological properties, from histology [6,17,94] to
large-scale networks [95,96]. Group-based parcellation schemes generally capture
the main aspects of organization evident across individuals, whereas the size,
shape and position of areas and networks can vary substantially between
individuals [5,18,19,76,97] (Fig. 3). Furthermore, divergent patterns of brain
organization from the most common pattern (that is, changes in the spatial
arrangement of cortical regions) can be observed in approximately 5–10\% of the
healthy population [16,19], and care should therefore be taken to avoid the
undue influence of such outliers. Notwithstanding their non-conformation to a
theoretically universal map of the brain, such topological outliers, if they do
not result from artefacts, can also be considered to be interesting cases of
inter-individual variability to understand brain–phenotype relationships [98].
Indeed, recent studies have suggested that the topography (location and size) of
individual-specific brain parcellations is predictive of individual differences
in demographics, cognition, emotion and personality [3,5,99]. In this context,
we would argue that the quest to understand robust patterns of brain topography
across different markers and the investigation of inter-individual differences
are closely intertwined challenges. Only by understanding the generic
characteristic of topographic organization can we start to appreciate
idiosyncrasies and their relationships to socio-demographic, cognitive or
affective profiles'' \citep{eickhoff2018imaging}.




\subsection{Self-critique \& short comings}


\subsubsection{ROI creation procedure}

We have a little leakage of test data
%
Especially at the borders of the ROI, we miss some voxels (of some participants)
cause the binary masks is based on a ``titrated threshold''
\citep{sengupta2016extension}

\todo[inline]{check paper regarding ``probabilistic functional atlases''; these
data are independent but they used masks based on visual inspection and manual
thresholding (mostly), too}

%
From \citep{weiner2018defining}: ``the identification of the PPA is complicated
by (at least) four methodological considerations.
%
First, the PPA definition may depend on the type of experiment, task, and
stimuli used [s. also ``localizer as ground truth below''].
%
Second, the boundaries of the PPA may depend on the statistical threshold used.
%
Third, the spatial extent and localization of the PPA may vary if defined within
the native brain space of an individual or based on a group analysis.
%
Fourth, the size of the PPA may depend on data acquisition choices (e.g. large
vs. small voxels) and data analysis choices (e.g. liberal smoothing vs. no
spatial smoothing).
%
The present study aims to identify and to predict the most probable location of
place-selective voxels within medial VTC of an individual brain that is
impervious to these methodological decisions'' \citep{weiner2018defining}.





\subsubsection{Localizer is ``ground truth''}

\todo[inline]{essentially issues of reliability and validity}

%
``The dynamic localizer (in Grand Budapest data set) was significantly more
reliable than the static localizer (in studyforrest data set) (t(34) = 3.76, p <
0.001) despite its shorter length (four 234s runs versus four 312s runs,
respectively)'' \citep{jiahui2020predicting}.

%
\citet{lilienfeld2015fifty} on ``gold standard'' (in psychiatry):
%
``In the domains of psychological and psychiatric assessment, there are precious
few, if any, genuine "gold standards".
%
Essentially all measures, even those with high levels of validity for their
intended purposes, are necessarily fallible indicators of their respective
constructs [Cronbach and Meehl, 1955; Faraone and Tsuang, 1994].''
\citep{lilienfeld2015fifty}

%
\citet{scheinost2019ten} in context of phenotypic measures:
%
``Predictive models based on neuroimaging data will only ever account for a
fraction of the variance.
%
Neuroimaging studies are limited by how much information the signal can capture
about the measure of interest.
%
At the same time, these studies are also limited by the chosen phenotypic
measure used.
%
While the success of a model is evaluated by how well it predicts a phenotypic
measure (and these phenotypic measures have to be treated as gold standards), it
is well known that such measures are not always the ground truth but themselves
suffer from confounds and noise.
%
When studying brain-behavior associations, one must keep in mind how
extraordinary it is that neuroimaging data can be distilled to approximate
phenotypic measures that reflect a simplification of multiple complex features.
%
Thus, even modest results are reasonable and remarkable.
%
For a discussion on the reliability of phenotypic measures in the context of
predictive modeling, we point the interested reader to: [Dubois et al., 2018a,
2018b; Gignac and Bates, 2017]'' \citep{scheinost2019ten}.




\subsubsection{Volume-based registration vs. surface-based normalization}

\todo[inline]{Is not a real problem because we compare volume-based anatomical
alignment to volume-based functional alignment}

\todo[inline]{paper that prepare volume to surface-based procedures; e.g.
\citep{desai2005volumetric}; check the directory with the last papers that need
to be checked; e.g. \citet{weiner2018defining} who compare PPA-prediction using
cortex-based alignment \citep{fischl1999high} with volume-based (Talairach)
alignment.}

%
Sengupta published results of analyses that were compared in voxel space.
%
``Opportunity costs'': I could have run the analyses/contrasts on the surface
but that needs time.
%
Is also a ``problem'' of data sharing: you save time and money (especially if
you do not collect the data yourself) but you have to trust that the data are
``good'' and start at some point to reach goals that you would not accomplished
if you would have done all from scratch (i.e. preprocessing).



\subsubsection{Sample size}

``Most studies that use small samples are likely to exhibit highly variable
estimates. This finding suggests that many of the claims of predictive accuracy
in the neuroimaging literature may be exaggerated and/or not valid''
\citep{poldrack2019establishment}.

\todo[inline]{of course, replication, bigger sample, and stuff! Which is
transition to ``Future questions''}




\subsection{Future questions}


\subsubsection{Predict other t-contrasts of our localizer}

\todo[inline]{especially, condition ``faces'' was hard to model in the
audio-description''; master student's project (with an additional twist?)}

%
The \ac{ffa}, and \ac{eba}  which are associated with face perception
\citep{kanwisher1997ffa, pitcher2011occipitalfacearea}, and the perception of
human bodies \citep{downing2001bodyarea}, respectively.




\subsubsection{Common model space based on other study's data}

\todo[inline]{a.k.a. ``more subjects''}
%
Create a \ac{cfs} from another experiment's data, using another
scanner and, of fucking course, more subjects (obviously, "movie's study"
[a.k.a. ``my precious'' ;-)].
%
In case of an alignment of time series, that experiment needs, at least, a part
of Forrest Gump as an intersection.
%
But: shared stimulus across datasets is easier to accomplish than shared
subjects across datasets \citep[s.][]{zhang2018transfer}.



\subsubsection{Other localizers, i.e. brain functions}

%
What is the limit of what we can estimate reliably?
%
Retinotopy, language, executive functions (from low-level perception to higher
cognition which might not even be sampled by a movie).


``First, our brains directly process exogenous information about the external
environment by transducing physical phenomena (e.g., changes in energy,
molecular concentrations, etc.) into sensory perceptions that allow us to
generate and maintain a sense of what is happening around us (1, 2). Mental
representations that are directly driven by the external world are likely to be
highly similar across individuals who share the same sensory experience. Second,
our brains also process endogenous information that reflects our current
internal homeostatic states, past experiences, and future goals (3). The
integration of exogenous and endogenous information allows us to meaningfully
interpret our surroundings, prioritize information that is relevant to our
goals, and develop action plans (4). Given the same input information,
individuals may have unique interpretations, feelings, and plans, often leading
endogenous representations to be idiosyncratic across individuals''
\citep{chang2021endogenous}.

``Human brains have much in common with one another. Similarities exist not only
at the anatomical level, but also in terms of functional organization. Given the
same stimulus—an expanding ring, for example—regions of the brain that process
sensory (visual) stimuli will respond in a highly predictable and similar manner
across different individuals. This predictability is not limited to sensory
systems: shared activity across people has also been observed in higher-order
brain regions (for example, the default mode network [6], or DMN) during the
processing of semantically complex real-life stimuli such as movies and
stories [7–13]. Notably, shared responses in these high-order areas seem to be
associated with narrative content and not with the physical form used to convey
it [11,14,15]. It is unknown, at any level of the cortical hierarchy, to what
extent the similarity of human brains during shared perception is recapitulated
during shared recollection. This prospect is made especially challenging when
recall is spontaneous and spoken, and the selection of details is left up to
the rememberer (rather than the experimenter), as is often the case in real
life'' \citep{chen2017shared}.




\subsubsection{Other functional alignment algorithms}

\todo[inline]{kind of obvious and a little ``for the sake of it''}

\todo[inline]{cf. \citet{bazeille2021empirical} and his dissertation}

\todo[inline]{what is "Multimodal Surface Matching"; Robinson et al. 2014?}

From \citet{bazeille2021empirical}: ``As we use inter-subject decoding to
compare functional alignment methods, we only consider methods that meet the
following two criteria.
%
First, the alignment transformations should be learned on activations evoked
during temporally synchronized (i.e., co-occuring) task data, or on contrasts
matched across individuals.
%
Second, the learned transformations must be invertible or almost invertible
linear mappings and applicable as-is on unseen data with a different task
structure.
%
These two criteria exclude several methods currently used in the literature such
as regularized canonical correlation analysis (rCCA; Bilenko and Gallant, 2016),
gradient hyperalignment (Xu et al., 2018), connectivity hyperalignment
(Guntupalli et al., 2018), and methods based on Laplacian embeddings (Langs et
al., 2014)'' \citep{bazeille2021empirical}.

%
``Nonetheless, it remains unclear how researchers should choose among the
available functional alignment methods for a given research application''
\citep{bazeille2021empirical}.




\paragraph{ROI vs. whole-brain (i.e. searchlight)}

\todo[inline]{searchlight SRM \citep{zhang2016searchlight}}

%
Similarly: influence of voxel count vs. performance (a.k.a. the more training
data, the better; it not just number of participants;
%
In case of search light: how big should it be? PPA seems to vary by centimeters.

% Guntupalli's searchlight
From project proposal: ``\citet{guntupalli2016model} showed that hyperalignment
can be extended to predict functional organization across large proportions of
the cortical surface, for example to predict the represented visual field
coordinate in visual cortex based on retinotopic mapping scans of other
individuals.

%
``Applying SRM to a large swath of the brain means that all voxels within the
region contribute to the final derived metric. This can conflict with the goal
of associating spatially local activity with specific cognitive functions. To
address such issues, SRM can be applied in small overlapping searchlights to
obtain localized metrics of shared information [\citep{guntupalli2016model,
zhang2016searchlight}'' \citep{cohen2017computational}.

%
From \citet{bazeille2021empirical}: ``As piecewise alignment is learned within a
parcellation, an important question is: which brain atlas should be used for
piecewise alignment? In Supplementary Figure S2 we compare results from the
Schaefer et al. (2018) atlases to those from parcellations derived directly on
the alignment data. By default, the results presented piecewise alignment is
learned within a parcellation, an important question is: which brain atlas
should be used for piecewise alignment?  In Supplementary Figure S2 we compare
results from the Schaefer et al. (2018) atlases to those from parcellations
derived directly on the alignment data. By default, the results presented below
are derived with the 300 ROI parcellation of the Schaefer atlas unless noted
otherwise. In the case of searchlight Procrustes, we selected searchlight
parameters to match those used in Guntupalli et al. (2016); that is, each
searchlight had 5 voxel radius, with a 3 voxel distance between searchlight
centers. All searchlight analyses were implemented using PyMVPA [Hanke et al.,
2009].ted below are derived with the 300 ROI parcellation of the Schaefer atlas
unless noted otherwise. In the case of searchlight Procrustes, we selected
searchlight parameters to match those used in Guntupalli et al. (2016); that is,
each searchlight had 5 voxel radius, with a 3 voxel distance between search-
light centers. All searchlight analyses were implemented using PyMVPA [Hanke et
al., 2009]'' \citep{bazeille2021empirical}.

\citet{bazeille2021empirical}: ``An alternative scheme, piecewise alignment
[Bazeille et al., 2019], uses non-overlapping neighborhoods either learnt from
the data using a parcellation method—such as k-means—or derived from an a priori
functional or anatomical atlas. Local transforms are derived in each
neighborhood and concatenated to yield a single large-scale transformation.
Unlike searchlight, this returns a transformation matrix with the desired
regularities. This framework might induce staircase effects or other
functionally-irrelevant discontinuities in the final transformation due to the
underlying boundaries'' \citep{bazeille2021empirical}.

\citet{bazeille2021empirical}: ``To align the entire cortex across subjects, two
main frameworks have been proposed: searchlight and piecewise aggregation
schemes. Each of these frameworks use functional alignment methods to learn
local transformations and aggregate them into a single large-scale alignment;
however, search- light and piecewise differ in how they aggregate transforms, as
illustrated in Figure 2.  The searchlight scheme [Kriegeskorte et al., 2006],
popular in brain imaging [Guntupalli et al., 2018; 2016], has been used as a way
to divide the cortex into small overlapping spheres of a fied radius. This
method allows researchers to remain agnostic as to the lo- cation of functional
or anatomical boundaries, such as those suggested by parcellation-based
approaches. A local transform can then be learnt in each sphere and the full
alignment is obtained by aggregating [e.g. summing as in Guntupalli et al., 2016
or averaging] across overlapping transforms. Importantly, the aggregated
transformation produced is no longer guaranteed to bear the type of regularity
(e.g orthogonality, isometry, or diffeomorphicity enforced during the local
neighborhood fit'' \citep{bazeille2021empirical}.




\paragraph{Time series vs connectivity-based}

\todo[inline]{kind of a killer cause you do not need intersection of
time series; but s. Guntupalli's paper: time series hyperalignment outperforms
connectivity-based hyperalignment (?)}

\todo[inline]{cf. uncutted part on functional alignment}


\todo[inline]{wtf did \citep{nastase2019leveraging} do?}


%
From \citet{busch2021hybrid}:``Hyperalignment models shared information that is
embedded in idiosyncratic cortical patterns across brains. Modeling shared
information makes it possible to compare functional anatomy across brains at a
fine spatial scale.
%
Hyperalignment projects cortical pattern vectors into a common, high-dimensional
information space [Haxby et al., 2020].
%
Derivation of this common space can be based on either neural response profiles
(e.g. data collected during tasks, such as movie viewing (Haxby et al., 2011))
or functional connectivity profiles files [Guntupalli et al., 2018]''
\citep{busch2021hybrid}.


% Nastase's ugly mofo paper
``Finally, estimating the SRM from functional connectivity data rather than
response time series circumvents the need for a single shared stimulus across
subjects; connectivity SRM allows us to derive a single shared response space
across different stimuli with a shared connectivity profile
\citep{nastase2019leveraging}'' \citep{kumar2020brainiak}.


From \citet{haxby2020hyperalignment}: ``Estimating the parameters to transform
high-dimensional spaces from individual brains into a common high-dimensional
space requires a rich set of data that samples a wide variety of cortical
patterns in order to generalize to novel stimuli or tasks.
%
For response hyperalignment, a rich variety of stimuli or conditions are
necessary to sample the response vector space.
%
For connectivity hyperalignment, the sampling of connectivity vector space is
defined by the selection of connectivity targets, but the richness and
reliability of connectivity estimates depends on the variety of brain states
over which connectivity is estimated'' \citep{haxby2020hyperalignment}.

%
From \citet{guntupalli2018computational}: ``Results showed that both CHA and RHA
increased ISCs and bsMVPC classification accuracies significantly over
anatomy-based alignment, but each algorithm achieves better alignment for the
information that it uses to derive a common model, namely connectivity profiles
and patterns of response, respectively.
%
ISCs of connectivity profiles are
significantly higher in a common model based on CHA than in a common model based
on RHA (ROI mean ISCs = 0.67 and 0.575, respectively; CHA-RHA difference = 0.095
[0.081, 0.112])(S1 Fig).
%
By contrast, RHA marginally but significantly
outperforms CHA on some validations based on response tuning functions, namely
ISCs of representational geometry (ROI means = 0.322 and 0.308, respectively;
RHA-CHA difference = 0.014 [0.007, 0.019])(S2 Fig), and bsMVPC of movie segments
(ROI mean accuracies = 13.65\% and 10.37\%, respectively; RHA-CHA difference =
3.28\% [2.76\%, 3.78\%])(S3 Fig) \citep{guntupalli2018computational}.

% from project proposal
From project proposal: ``In his doctoral thesis, recently submitted to the
Faculty of Natural Sciences in Magdeburg, Falko Kaule showed that congruent
time-locked BOLD responses across subjects (i.e. all subjects watching the exact
same full-length movie) as used by Haxby and colleagues are not required to
derive a valid alignment of individuals with a common representational space
\citep{kaule2017examination}.
%
Comparable prediction performance can be achieved by using functional
connectivity patterns (correlation of a voxel's time series with reference
regions in the same brain).
%
It should be noted that the number of voxels that can be considered
simultaneously for functional BOLD response time series alignment is limited by
the number of timepoints in the calibration scan (about 300-400 voxels for a
15min scan with a 2s TR, corresponding to a local cortical neighborhood of about
1cm in diameter for a standard resolution).
%
This limitation does not exist in this form for a functional alignment that is
based on connectivity vectors.
%
The length of these connectivity vectors is determined by the number of
reference (or seed) regions in the brain'' [from project proposal].



\subsubsection{Individual residuals?}

\todo[inline]{We have transformation matrices for individual mapping; but just
onto shared responses}

\todo[inline]{but extension of SRM: ``Capturing Shared and Individual
Information in fMRI Data'' \citep{turek2018capturing} [read it!]; is there
any "real" paper that has been using that model already?}


%
From \citep{cohen2017computational}: ``The flip side of focusing on shared
responses is to focus on responses that are idiosyncratic to individuals.
Although these responses are excluded in SRM, they are not necessarily noise and
may in fact be highly reliable within participants.
%
SRM can be used to isolate participant-unique responses by examining the
residuals after removing shared group responses, or it can be applied
hierarchically to the residuals to identify subgroups [\citet{chen2017shared};
this is another "Chen"?!].
%
More generally, there is a growing trend toward investigating individual
differences as another source of meaningful variance in fMRI
[\citep{dubois2016building}].
%
Recognizing that signal exists beyond the average or shared response of a group,
such studies exploit idiosyncratic but stable responses to account for
previously unexplained variance in brain function, behavioral performance and
clinical measures [Finn (2015). Functional fingerprinting (based on
connectivity); Rosenberg (2016). A neuromarker of sustained attention]''
\citep{cohen2017computational}.


%
``Furthermore, in cases where each subject's unique response is of more interest
than the shared signal, SRM can be used to factor out the shared component
thereby isolating the idiosyncratic response for each subject
[\citep{chen2015reduced}]'' \citep{kumar2020brainiak}.





\subsection{Vision}

\todo[inline]{mih: das Kapitel braucht aus meiner Sicht keinen eigenen
"Outlook"; kommt eh direkt danach für die ganze Arbeit \&  ist da viel
interessanter}

``These findings lay the foundation for developing an
efficient tool for mapping functional topographies for a wide range of
perceptual and cognitive functions in new subjects based only on fMRI data
collected while watching an engaging, naturalistic stimulus and other subjects'
localizer data from a normative sample'' \citep{jiahui2020predicting}.


\subsubsection{Multiple localizer}

``Calibration scan'' to align to \ac{cms} and atlas of reference group.
%
From project proposal: ``Once a valid alignment is established, known functional
properties of a (normative) reference, derived from extensive scans and analysis
of other subjects, can then be projected into the respective individual voxel
space (s.  Fig. 1 in \citep{nishimoto2016lining})''.

%
``Movies engage multiple brain systems in parallel. From a single movie dataset
multiple functional topographies can be estimated [Guntupalli et al., 2016],
whereas different localizers are typically required to map different functional
topographies, making a thorough mapping of selective topographies time-consuming
and inefficient'' \citep{jiahui2020predicting}.

\todo[inline]{cf. general introduction}

\paragraph{Validity \& generalizability}

\todo[inline]{generalizability: scan once, estimate many}
% from project proposal
Naturalistic stimuli promise an ``increased validity of derived transformation
for functional alignment by sampling a more diverse set of mental states that
reflect (confound) statistics of the natural environment, and enable
investigation of the acquired data for a variety of research questions (e.g.
visual or auditory perception, spatial cognition; emotion; music, speech or
social perception)'' [project proposal].

% from Haxby 2020
``Estimating the parameters to transform high-dimensional spaces from individual
brains into a common high-dimensional space requires a rich set of data that
samples a wide variety of cortical patterns in order to generalize to novel
stimuli or tasks. For response hyperalignment, a rich variety of stimuli or
conditions are necessary to sample the response vector space. For connectivity
hyperalignment, the sampling of connectivity vector space is defined by the
selection of connectivity targets, but the richness and reliability of
connectivity estimates depends on the variety of brain states over which
connectivity is estimated'' \citep{haxby2020hyperalignment}.


\paragraph{additional benefit: compliance}
%
``As a rule of thumb, SRM will improve sensitivity for detecting a cognitive
process of interest in the test data if the training stimuli or trials strongly
and variably engage that process in a way that is reliable across participants''
\citep{cohen2017computational}.

%
``Movies are more engaging and result in better compliance
\citep{vanderwal2015inscapes}. Movie viewing can also be used in subject
populations, such as children \citep{richardson2018development} or patients,
that may have trouble maintaining attention during repetitions of a tedious
localizer task'' \citep{jiahui2020predicting}.

%
``Movies engage multiple brain systems in parallel. From a single movie dataset
multiple functional topographies can be estimated (Guntupalli et al., 2016),
whereas different localizers are typically required to map different functional
topographies, making a thorough mapping of selective topographies
time-consuming and inefficient. Movies also simulate better the statistics of
natural viewing and listening and may provide more ecologically valid maps.
Analogously, the introduction of dynamic videos of faces and control categories
to localize face-selective topographies provides more reliable maps and better
estimate the extent of face-selective regions than do localizers with still
image stimuli (Fox et al., 2009; Pitcher et al., 2011). Similarly, naturalistic
stimuli may better sample the full range of responses to faces and other stimuli
that contribute to face-selective topographies'' \citep{jiahui2020predicting}.

\paragraph{in general}

Last paragraph of \citet{jiahui2020predicting}'s introduction: ``These results
lay a foundation for building a computational tool with a database that could
allow others to map multiple functional topographies in new subjects using only
data collected during movie viewing. Functional localizers are inefficient
because they only estimate one or a few topographies for each localizer. Movies,
by contrast, engage in parallel multiple neural systems for vision, audition,
language, person perception, social cognition, and other functions.
Consequently, movies have the potential to estimate selective topographies in
all of these do- mains. Such a tool would require a database of data for movies
and a range of functional localizers in a normative group of subjects. A new
subject’s functional topographies could be estimated based only on that
subject’s movie data and other subjects’ localizer data from the normative
database that could be projected into that subject’s cortical anatomy using
hyperalignment transformation matrices derived from movie data. Such a resource
would be more efficient and replace tedious functional localizers with an
engaging movie and could enable mapping of multiple functional topographies with
data from a single fMRI using a naturalistic stimulus''
\citet{jiahui2020predicting}.

``The algorithm also can be applied to simpler, con- trolled experimental data,
but our previous results showed that the sampling of response vectors from these
experiments is impoverished and produces a model representational space that
does not generalize well to new stimuli in other experiments (Haxby et al.
2011). Results show that the computational principles underlying this common
model have broad general validity for representational spaces in occipital,
temporal, parietal, and frontal cortices'' \citep{guntupalli2016model}.



\subsubsection{Functional atlas}

\todo[inline]{see also \citep{bazeille2019local}; who is quoting him?}


%
``While the functional alignment can also be applied to fMRI data from
stimulation paradigms with simplified stimuli, the transformations for
functional alignment have greatly diminished general validity
\citep{haxby2011common}, presumably because such experiments sample a sparser
range of brain states \citep{guntupalli2016model}'' [project proposal].

%
Moreover, naturalistic stimuli sample a broader range of brain states paradigms
with simplified stimuli \citep{guntupalli2016model, haxby2011common} promising
an increased validity of transformations of functional alignment and increased
generalizability to [research questions/domains/paradigms].

%
Naturalistic stimuli promise an ``increased validity of derived transformation
for functional alignment by sampling a more diverse set of mental states that
reflect (confound) statistics of the natural environment, and enable
investigation of the acquired data for a variety of research questions (e.g.
visual or auditory perception, spatial cognition; emotion; music, speech or
social perception)'' [project proposal].

``This result suggests that the validity for a model of a specific subspace may
be enhanced by designing a stimulus paradigm that samples the brain states in
that subspace more extensively'' \citep{haxby2011common}.

``hyperalignment of data using a set of stimuli that is less diverse than the
movie is effective, but the resultant common space has validity that is limited
to a small subspace of the representational space in VT cortex''
\citep{haxby2011common}.

``Initially, the common space produced with hyperalignment has the same number
of dimensions as the number of voxels in each individual’s native space. We
asked how many distinct common response-tuning functions are needed to contain
the information that affords the full range of fine-grained distinctions among
complex, visual stimuli. We tested the sufficiency of lower-dimensional
subspaces and found that BSC accuracies continued to increase with more than 20
common response- tuning functions. We present a 35-dimensional common model
space that afforded BSC for all three experiments at levels of accuracy that
were equivalent to BSC with all 1,000 hyperaligned dimensions or WSC with 1,000
voxels. Ten dimensions were sufficient within the limited stimulus domains of
each category perception experiment, but these sets of ten dimensions did not
afford high levels of BSC for the other experiment or for the movie. Thus, these
lower-dimensional models are subspaces of the full model and are valid only for
more limited stimulus domains'' \citep{haxby2011common}.


``Estimating the parameters to transform high-dimensional spaces from individual
brains into a common high-dimensional space requires a rich set of data that
samples a wide variety of cortical patterns in order to generalize to novel
stimuli or tasks. For response hyperalignment, a rich variety of stimuli or
conditions are necessary to sample the response vector space. For connectivity
hyperalignment, the sampling of connectivity vector space is defined by the
selection of connectivity targets, but the richness and reliability of
connectivity estimates depends on the variety of brain states over which
connectivity is estimated'' \citep{haxby2020hyperalignment}.

%
From project proposal: ``Moreover, beyond the scope of this project the targeted
homogenization of acquisition procedures will further the goal of large scale
data collection for the purpose of producing a normative reference of brain
function as measured by fMRI''.

%
From project proposal: ``The availability of such a reference would enable
quantitative and qualitative description of an individual's brain function with
respect to such a norm, and consequently progress the field towards neuroimaging
studies of individual differences that more closely resemble their psychological
counterparts''.

%
From talk at INM-7 seminar: ``Imagine you scan a new, unknown subject for just
15 minutes more, and you additionally get results from a whole variety of other
paradigms mapped onto that brain: results from localizers of low-level
perceptual processes, but also higher-level cognitive processes like language,
memory, emotions and so on. And kinda ``adventurous'': If you have different
common model spaces for different subgroups, you can investigate which alignment
onto which ``subgroup common model space'' results in less error, that lets you
classify to which subgroup your new subject might belong''.

%
From \citep{jiahui2020predicting}: ``results lay a foundation for building a
computational tool with a database that could allow others to map multiple
functional topographies in new subjects using only data collected during movie
viewing. Functional localizers are inefficient because they only estimate one or
a few topographies for each localizer. Movies, by contrast, engage in parallel
multiple neural systems for vision, audition, language, person perception,
social cognition, and other functions. Consequently, movies have the potential
to estimate selective topographies in all of these domains. Such a tool would
require a database of data for movies and a range of functional localizers in a
normative group of subjects. A new subject's functional topographies could be
estimated based only on that subject's movie data and other subjects’ localizer
data from the normative database that could be projected into that subject’s
cortical anatomy using hyperalignment transformation matrices derived from movie
data. Such a resource would be more efficient and replace tedious functional
localizers with an engaging movie and could enable mapping of multiple
functional topographies with data from a single fMRI using a naturalistic
stimulus'' \citep{jiahui2020predicting}.

``Characterizing this functional variability, particularly when considering the
genetic level, ideally requires acquiring functional imaging data from hundreds
of sub- jects and organizing these data into a large-scale database, together
with genetic, behavioral and biomorphological data. Databasing and analysis of
structural magnetic reso- nance images has already resulted in probabilistic
ana- tomical atlases [Toga, 2001, Probabilistic approaches; Van Essen, 2002,
Windows on the brain]. However, a similar large scale description of
functional networks is still lacking'' \citep{pinel2007fast}.




\subsection{Conclusion}

Ceterum censeo Carthaginem esse delendam.


\section{Data Availability}

\todo[inline]{all from PPA-Paper but with new GIN link leading to an empty repo}

% \href{https://gin.g-node.org/chaeusler/studyforrest-ppa-analysis}{\url{gin.g-node.org/chaeusler/studyforrest-ppa-analysis}}

% new; PPA analysis
All fMRI data and results are available as Datalad \citep{halchenko2021datalad}
datasets, published to or linked from the \emph{G-Node GIN} repository
(\href{https://gin.g-node.org/chaeusler/studyforrest-ppa-srm}{\url{gin.g-node.org/chaeusler/studyforrest-ppa-srm}}).
% original
Raw data of the audio-description, movie and visual localizer were originally
published on the \emph{OpenfMRI} portal
(\url{https://legacy.openfmri.org/dataset/ds000113}; \citep{Hanke2014ds000113},
\space \url{https://legacy.openfmri.org/dataset/ds000113d};
\citep{hanke2016ds000113d}).
% visual localizer
Results from the localization of higher visual areas are available as Datalad
datasets at \emph{GitHub}
(\href{https://github.com/psychoinformatics-de/studyforrest-data-visualrois}{\url{github.com/psychoinformatics-de/studyforrest-data-visualrois}}).
% raw data
The realigned participant-specific time series that were used in the current
analyses were derived from the raw data releases and are available as Datalad
datasets at \emph{GitHub}
(\href{https://github.com/psychoinformatics-de/studyforrest-data-aligned}{\url{github.com/psychoinformatics-de/studyforrest-data-aligned}}).
% OpenNeuro
The same data are available in a modified and merged form on OpenNeuro at
\url{https://openneuro.org/datasets/ds000113}.
% NeuroVault for z-maps of SRM
Unthresholded $Z$-maps of all contrasts can be found at
\href{https://identifiers.org/neurovault.collection:12340}{\url{neurovault.org/collections/12340}}.


\section*{Code Availability}

Scripts to generate the results as Datalad \citep{halchenko2021datalad} datasets
are available in a \emph{G-Node GIN} repository
(\href{https://gin.g-node.org/chaeusler/studyforrest-ppa-srm}{\url{gin.g-node.org/chaeusler/studyforrest-ppa-srm}}).
