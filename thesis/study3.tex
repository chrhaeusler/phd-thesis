\section{Abstract}
%
In order to map perceptual or cognitive functions onto brain areas of study
participants, researchers usually conduct dedicated experiments often
accompanied with a task (so called ``functional localizer'').
%
Nevertheless, the approach ``one paradigm, one brain function'' becomes
unfeasible if one wants to map a variety of functions in a time-efficient
manner.
%
We explored a way to project brain mapping data (statistical z-maps) from a
reference group onto individual brains of study participants after performing a
functional aligning of participants with a common model space.
%
Data were obtained from conducting a functional localizer paradigm and two
paradigms using naturalistic stimulation during functional magnetic resonance
imaging (fMRI):
%
participants took part in a task-based, block-design visual localizer, and
participants were watching an audio-visual movie and listening to the movie's
audio-description, both paradigms free of any task.
%
Based on these data, we created a common model space employing a \ac{srm}
\citep{chen2015reduced}.
%
On the one hand, the common model space allows denoising data from individuals
that were used to create the common model space.
%
On the other hand, data from left-out subjects can be aligned with the common
model space by using a (preferably short) segment of a naturalistic stimulus as
a ``diagnostic run'', a process that provides a subject-specific transformation
matrices.
%
The inverse of the acquired transformation matrices can then be used to project
data from other paradigms aligned in common space onto the brain of the left-out
subjects.
%
The general goal of the project is to assess the required length of the
diagnostic run, and to compare empirical z-maps with z-maps that were predicted
from other participants' data.
%
We present preliminary results of predicted z-maps gained from the same paradigm
as the diagnostic run as well as across paradigms.


\section{Introduction}


\todo[inline]{vgl.bash-history}

% brain mapping
topographic brain mapping maps brain functions, perceptual or cognitive
processes, onto brain areas.
% localizer
Usually, this is done by letting study participants perform a task during a so
called ``functional localizer''.
% problem: one localizer for one domain
The second problem is: you usually need one localizer for one domain of brain
functions
% which gets messy
Which means: if you want to map a variety of domains, you need a variety of
localizers, and then the whole approach gets time-consuming and inefficient
(localizer batteries; e.g. Thirion's work)
% problem: compliance
Even more severe in a clinical population: they mostly need the participants to
perform a task, and they are just plain boring which often leads to a diminished
compliance.


\subsection{Our approach}
% main idea
The main idead ist to predict location, size, and shape of a functional area in
an individual person based on location, size, and shape of the same functional
area in persons of a reference group.
%
Based on a prediction of a reference group's data, the diagnostic procedure
could be more reliable and valid but also more time-efficient and thus more
affordable.
%
We can do this in basically two ways:
a) we do this by performing an anatomical alignment, or
%
which is a new a approach:
%
b) we can do this by performing a functional alignment
%

but when we want to predict functional areas from anatomically aligned brains,
we are running into the problem of poor
functional-anatomical correspondence.

Poor functional-anatomical correspondence means:
even if we assume that two persons have anatomically identical brains, still,
the location, size \& shape of the functional area is probably different.


\subsubsection{anatomical alignment}

% anatomical alignment
In general, a individual's diagnostic could be based on a prediction based on
the anatomical location of the functional area in the reference group (e.g.
\citet{weiner2018defining}.
%
- anatomical alignment aligns vertices in 2-dimensional space or voxels in
3-dimensional anatomical space
%
we transform the shape of an individual brain into the shape of an average,
standard brain


\paragraph{procedure}
%
\begin{itemize}
    \item conduct the localizer experiment to get the brain responses in the
    reference group
    \item align the brains in that reference group anatomically to the standard
    brain
    \item also align your left-out subject to the standard brain, which gives
    you a transformation matrix
    \item then you use the inverse of that transformation matrix to project the
    data
    \item from the reference group into the anatomy of the left-out subject,
    which is essentially the prediction
\end{itemize}


\paragraph{functional-anatomical correspondence}
% shitty
The approach relying on merely anatomical alignment is shitty because of modest
functional-anatomical correspondence.
% explain functional-anatomical correspondence
A modest functional-anatomical correspondence means that even if one would assume
two persons had an identically shaped brain anatomy the location, size, and
shape of a functional area would still not be indetical.

% PPA example
Here, as an example the location of the ``PPA'', the Parahippocampal Place Area.
which is more active when we look at pictures of scenes or landscapes.
%
location, shape, size of the PPA in 14 subjects,
%
the brighter the voxel the more subjects have their PPA in that location.
%
location is roughly similar across persons, but still, the plot shows that there
is individual variation.


\paragraph{individual differences}
%
do you find differences in individual brain patterns or do differences stem from
differences in functional-anatomical correspondence?
%
vice versa: we might find no differences because of poor functional-anatomical
correspondence


\subsubsection{functional alignment}
%
given that we do not want to predict brain anatomy but predict an accurate
mapping of brain functions onto the brain anatomy:
%
wouldn't it make more sense to not perform an anatomical alignment but a
functional alignment?
%
Functional alignment aligns cortical patterns (time-series or connectivity
profiles) in a multi-dimensional function space.
% reference
The reference is not an average brain anatomy but a so called \ac{cms}.


\paragraph{Hyperalignment}
%
There are two algorithms dominating the field: hyperalignment and \ac{srm}


\paragraph{Shared response model}
%
\todo[inline]{why did we chose SRM?}


\paragraph{procedure}
%
You let study participants watch a naturalistic stimulus like a movie or an
audio-book...  ...which are continuous, naturally engaging, and are triggering a
wide variety of time-locked brain functions
%
From that stimuli, you get the time-series per voxel and per subject, and what
the algorithm essentially does is: it learns responses that are shared across
participants (which is the common model space)
%
but more importantly, the algorithm also learns individual transformation
matrices.
%
These transformation matrices can be used to project data into and out of the
Common Model Space.
For the prediction through a common model space, we first needed to create it
%
We let participants watch the movie and audio-description of Forrest Gump,
assuming that the naturalistic stimuli trigger, among others, brain responses
that a similar to those triggered by the functional localizer
%
Usually when aligning brain responses (and not connectivity profiles) you would
let the left-out subject watch the same and the whole stimuli that were used to
create the Common Model Space to get the transformation matrices.



\subsubsection{our current study: overview, blabla}
%
focussing on the domain of so called ``higher-visual, category-selective
areas''
%
How do you usually map these category-selective areas onto brains of individual
study participants?
%
You conduct a functional localizer experiments, lasting about 20 minutes,
%
You let the participants watch pictures of different categories, while also
letting them perform a task to force them to pay attention to picture, after
picture, after picture
%
After having collecting the data you do some statistics, and as a result you
get statistical maps, t- or z-map, that essentially tell you where the
higher-visual areas are located
%
If we need about 20 minutes for just one domain, why don’t we predict the
location of a functional area in one person from the location that we found in
other persons?


\subsubsection{our questions}
% questions of current study
In the current study, we asked ourselves two questions:
%
1) does functional alignment based on a the \ac{srm} improve the prediction
compared to a prediction based on merely anatomical alignment?
%
2) how much data do we need to align an individual subject to a/the \ac{cms} and
outperform a prediction based on anatomical alignment? Is a short diagnostic run
``sufficient''?
%
We wanted to predict the location of the PPA based on data from a reference
group
%
And we wanted to compare the prediction performance based on anatomical
alignment \& functional alignment
%
- goal: align left-out subject to model space using varying amount of data of
movie or audiobook - transform localizer results into left-out subject
%
Hence, the real question that we asked yourselves was: How many minutes of a
naturalistic stimulus are necessary to perform what we call a „partial
alignment“.
%
So, we only used parts of the naturalistic stimuli to let the algorithm learn
the transformation matrices for the left-out subject
%
and we tested which amount of data is needed to do an alignment to the common
model space that provides transformation matrices that outperform a prediction
using just an anatomical alignment.


\section{Methods}


\subsection{Participants}
- 14 participants, 3 experiments with 3 tesla, TR = 2 sec


\subsection{Experiments, i.e. data}
% functional localizer
- functional localizer of higher visual areas
%
4 runs; 650 TRs;
%
ground truth
% natural stimulation
- movie \& audiobook (2x8 runs; > 7200 TRs) for model space


\subsection{localizer as ground truth; ceiling}
%
how do we calculate the reliability of the localizer as kind of a „ceiling“


\subsection{Shared response model and common model space}
% cms
\citep{chen2015reduced}
%
- model space: shared response model (Chen et. al 2015)
%
let the algorithm learn the shared responses which is the common model space,
and it also learns the transformation matrices.

\subsection{template}
%

\subsubsection{alternative template creation}
%
lastly, we currently apply another method to get the „z-map template“ on which
the prediction is based


\subsection{ROI}
%
limited to voxels within ROIs based on other subjects' data
%
Given that each brain has far more than 7500 voxels,
we needed to restrict our analysis to voxels within a region of interest
that we defined anatomically


\section{Results}
%
For every subject, we see the correlation of z-maps that tell us the, quote
``real'' unquote, PPA and predicted PPA
%
In green, we see the correlations between empirical values from the localizer \&
the predicted values using anatomical alignment
%
In orange, we see the correlations between empirical values \& the predicted
values using parts of the movie
%
In blue, we see the correlations between empirical values \& the predicted
values using parts of the audio-description
%
I marked subject 4, because I want to show you how results look like in a
horizontal slice of the brain of subject 4
%
We have these nice blurry EPI-images and all z-maps are threshold at a value of
bigger than 2.3.
%
always in red, we can see the z-map from the localizer experiment across the
whole brain,
%
the region of interest that we used is white and the predicted values, are blue
%
The prediction using anatomical alignment and the prediction using 15 minutes of
movie data show a correlation of about .7
%
the prediction using 15 minutes of the audio-description correlates about 0 with
the empirical z-map
%
The last one is the extreme case, but it can give you an idea of how the z-maps
look in a slice of the brain



\section{Discussion}


\subsection{Discussion of current results}
%
15 min of movie watching used for functional alignment outperform prediction
using anatomical alignment
%
30 minutes of movie watching outperform 15 minutes of movie watching
%
more than 30 minutes do not lead to a significantly improved prediction
performance.
%
assumption: visual localizer = ``ground truth''


\subsection{Future questions}
%

\subsubsection{Proof of concept}
%

\subsubsection{ROI vs. whole brain}
%
more (?) data vs. searchlight algorithm


\subsubsection{predict other t-contrasts of localizer}


\subsubsection{predict other localizers}
%
e.g. retinotopy, language areas


\subsubsection{create CMS from other study}
%
we currently have a cross-subject and cross-experiment prediction,
but we do not have a (real) cross-scanner prediction
%
create a CMS from another experiment’s data,
using another scanner and hopefully more subjects
%
In case of an alignment of time-series,
that experiment needs, at least, a part of Forrest Gump as an intersection


\subsection{the vision}
%
functional atlas
%
Imagine you scan a new, unknown subject for just 15 minutes more, and you
additionally get results from a whole variety of other paradigms mapped onto
that brain
%
Results from localizers of low-level perceptual processes, but also higher-level
cognitive processes like language, memory, emotions and so on
%
And I did not write that onto the slides because it is just a vague idea:
%
If you have different common model spaces for different subgroups, you can
investigate which alignment onto which ``subgroup common model space'' results
in less error, that lets you classify to which subgroup your new subject might
belong.


\section{Conclusion}
